{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Turbo Results:\n",
      "\n",
      "Dataset: GSM8K\n",
      "Model: gpt-3.5-turbo\n",
      "  Framework: Authoritarian, Test Statistic: 2.0, p-value: 0.75\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "Model: claude-sonnet\n",
      "  Framework: Authoritarian, Test Statistic: 0.0, p-value: 0.25\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.25\n",
      "\n",
      "Dataset: SST-2\n",
      "Model: gpt-3.5-turbo\n",
      "  Framework: Authoritarian, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.15729920705028505\n",
      "Model: claude-sonnet\n",
      "  Framework: Authoritarian, Test cannot be performed (all differences are zero)\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.25\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "\n",
      "Dataset: HumanEval\n",
      "Model: gpt-3.5-turbo\n",
      "  Framework: Authoritarian, Test Statistic: 0.0, p-value: 0.31731050786291415\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.25\n",
      "  Framework: Hierarchical, Test Statistic: 1.0, p-value: 0.5\n",
      "Model: claude-sonnet\n",
      "  Framework: Authoritarian, Test Statistic: 3.0, p-value: 1.0\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.15729920705028505\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.15729920705028505\n",
      "\n",
      "Llama-3.1 Results:\n",
      "\n",
      "Dataset: GSM8K\n",
      "Model: gpt-3.5-turbo\n",
      "  Framework: Authoritarian, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.31731050786291415\n",
      "Model: claude-sonnet\n",
      "  Framework: Authoritarian, Test Statistic: 1.0, p-value: 0.5\n",
      "  Framework: Market, Test Statistic: 1.0, p-value: 0.5\n",
      "  Framework: Hierarchical, Test Statistic: 1.0, p-value: 0.6547208460185769\n",
      "\n",
      "Dataset: SST-2\n",
      "Model: gpt-3.5-turbo\n",
      "  Framework: Authoritarian, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.31731050786291415\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.25\n",
      "Model: claude-sonnet\n",
      "  Framework: Authoritarian, Test Statistic: 3.0, p-value: 1.0\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.25\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.15729920705028505\n",
      "\n",
      "Dataset: HumanEval\n",
      "Model: gpt-3.5-turbo\n",
      "  Framework: Authoritarian, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "  Framework: Market, Test Statistic: 2.5, p-value: 1.0\n",
      "  Framework: Hierarchical, Test Statistic: 2.0, p-value: 0.75\n",
      "Model: claude-sonnet\n",
      "  Framework: Authoritarian, Test Statistic: 0.0, p-value: 0.25\n",
      "  Framework: Market, Test Statistic: 1.0, p-value: 0.6547208460185769\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.31731050786291415\n",
      "\n",
      "Mistral Results:\n",
      "\n",
      "Dataset: GSM8K\n",
      "Model: gpt-3.5-turbo\n",
      "  Framework: Authoritarian, Test Statistic: 2.5, p-value: 1.0\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.25\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.25\n",
      "Model: claude-sonnet\n",
      "  Framework: Authoritarian, Test Statistic: 2.0, p-value: 0.75\n",
      "  Framework: Market, Test Statistic: 2.0, p-value: 0.75\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.15729920705028505\n",
      "\n",
      "Dataset: SST-2\n",
      "Model: gpt-3.5-turbo\n",
      "  Framework: Authoritarian, Test Statistic: 0.0, p-value: 0.25\n",
      "  Framework: Market, Test Statistic: 2.0, p-value: 0.75\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "Model: claude-sonnet\n",
      "  Framework: Authoritarian, Test Statistic: 1.0, p-value: 0.5\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "  Framework: Hierarchical, Test Statistic: 1.0, p-value: 0.6547208460185769\n",
      "\n",
      "Dataset: HumanEval\n",
      "Model: gpt-3.5-turbo\n",
      "  Framework: Authoritarian, Test Statistic: 3.0, p-value: 1.0\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "Model: claude-sonnet\n",
      "  Framework: Authoritarian, Test Statistic: 0.0, p-value: 0.25\n",
      "  Framework: Market, Test Statistic: 0.0, p-value: 0.17971249487899976\n",
      "  Framework: Hierarchical, Test Statistic: 0.0, p-value: 0.31731050786291415\n",
      "\n",
      "GPT-3.5-Turbo Results Interpretation:\n",
      "\n",
      "Dataset: GSM8K\n",
      "Model: gpt-3.5-turbo\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.75)\n",
      "  Market framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "Model: claude-sonnet\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.25)\n",
      "  Market framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.25)\n",
      "\n",
      "Dataset: SST-2\n",
      "Model: gpt-3.5-turbo\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "  Market framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.15729920705028505)\n",
      "Model: claude-sonnet\n",
      "  Authoritarian framework: Test cannot be performed (all differences are zero)\n",
      "  Market framework does not show significant improvement (p-value: 0.25)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "\n",
      "Dataset: HumanEval\n",
      "Model: gpt-3.5-turbo\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.31731050786291415)\n",
      "  Market framework does not show significant improvement (p-value: 0.25)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.5)\n",
      "Model: claude-sonnet\n",
      "  Authoritarian framework does not show significant improvement (p-value: 1.0)\n",
      "  Market framework does not show significant improvement (p-value: 0.15729920705028505)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.15729920705028505)\n",
      "\n",
      "Llama-3.1 Results Interpretation:\n",
      "\n",
      "Dataset: GSM8K\n",
      "Model: gpt-3.5-turbo\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "  Market framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.31731050786291415)\n",
      "Model: claude-sonnet\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.5)\n",
      "  Market framework does not show significant improvement (p-value: 0.5)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.6547208460185769)\n",
      "\n",
      "Dataset: SST-2\n",
      "Model: gpt-3.5-turbo\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "  Market framework does not show significant improvement (p-value: 0.31731050786291415)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.25)\n",
      "Model: claude-sonnet\n",
      "  Authoritarian framework does not show significant improvement (p-value: 1.0)\n",
      "  Market framework does not show significant improvement (p-value: 0.25)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.15729920705028505)\n",
      "\n",
      "Dataset: HumanEval\n",
      "Model: gpt-3.5-turbo\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "  Market framework does not show significant improvement (p-value: 1.0)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.75)\n",
      "Model: claude-sonnet\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.25)\n",
      "  Market framework does not show significant improvement (p-value: 0.6547208460185769)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.31731050786291415)\n",
      "\n",
      "Mistral Results Interpretation:\n",
      "\n",
      "Dataset: GSM8K\n",
      "Model: gpt-3.5-turbo\n",
      "  Authoritarian framework does not show significant improvement (p-value: 1.0)\n",
      "  Market framework does not show significant improvement (p-value: 0.25)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.25)\n",
      "Model: claude-sonnet\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.75)\n",
      "  Market framework does not show significant improvement (p-value: 0.75)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.15729920705028505)\n",
      "\n",
      "Dataset: SST-2\n",
      "Model: gpt-3.5-turbo\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.25)\n",
      "  Market framework does not show significant improvement (p-value: 0.75)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "Model: claude-sonnet\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.5)\n",
      "  Market framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.6547208460185769)\n",
      "\n",
      "Dataset: HumanEval\n",
      "Model: gpt-3.5-turbo\n",
      "  Authoritarian framework does not show significant improvement (p-value: 1.0)\n",
      "  Market framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "Model: claude-sonnet\n",
      "  Authoritarian framework does not show significant improvement (p-value: 0.25)\n",
      "  Market framework does not show significant improvement (p-value: 0.17971249487899976)\n",
      "  Hierarchical framework does not show significant improvement (p-value: 0.31731050786291415)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Data for GPT-3.5-Turbo\n",
    "gpt_data = {\n",
    "    'GSM8K': {\n",
    "        'baseline': [0.867, 0.800, 0.900],\n",
    "        # 'CoT': [0.633, 0.667, 0.600],\n",
    "        # 'Emotive': [0.767, 0.767, 0.700],\n",
    "        'gpt-3.5-turbo': {\n",
    "            'Authoritarian': [0.833, 0.867, 0.367],\n",
    "            'Market': [0.800, 0.800, 0.600],\n",
    "            'Hierarchical': [0.733, 0.767, 0.900]\n",
    "        },\n",
    "        'claude-sonnet': {\n",
    "            'Authoritarian': [0.767, 0.667, 0.767],\n",
    "            'Market': [0.733, 0.800, 0.000],\n",
    "            'Hierarchical': [0.100, 0.500, 0.767]\n",
    "        }\n",
    "    },\n",
    "    'SST-2': {\n",
    "        'baseline': [0.967, 0.967, 0.967],\n",
    "        # 'CoT': [0.633, 0.600, 0.633],\n",
    "        # 'Emotive': [0.967, 0.967, 0.967],\n",
    "        'gpt-3.5-turbo': {\n",
    "            'Authoritarian': [0.933, 0.900, 0.967],\n",
    "            'Market': [0.900, 0.967, 0.933],\n",
    "            'Hierarchical': [0.933, 0.967, 0.933]\n",
    "        },\n",
    "        'claude-sonnet': {\n",
    "            'Authoritarian': [0.967, 0.967, 0.967],\n",
    "            'Market': [0.767, 0.867, 0.800],\n",
    "            'Hierarchical': [0.967, 0.900, 0.933]\n",
    "        }\n",
    "    },\n",
    "    'HumanEval': {\n",
    "        'baseline': [0.800, 0.800, 0.800],\n",
    "        # 'CoT': [0.867],\n",
    "        # 'Emotive': [0.767],\n",
    "        'gpt-3.5-turbo': {\n",
    "            'Authoritarian': [0.800, 0.833, 0.800],\n",
    "            'Market': [0.767, 0.700, 0.767],\n",
    "            'Hierarchical': [0.767, 0.633, 0.833]\n",
    "        },\n",
    "        'claude-sonnet': {\n",
    "            'Authoritarian': [0.833, 0.467, 0.867],\n",
    "            'Market': [0.767, 0.767, 0.800],\n",
    "            'Hierarchical': [0.833, 0.833, 0.800]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Data for Llama-3.1\n",
    "llama_data = {\n",
    "    'GSM8K': {\n",
    "        'baseline': [0.033, 0.033, 0.033],\n",
    "        # 'CoT': [0.100, 0.100, 0.100],\n",
    "        # 'Emotive': [0.067, 0.067, 0.067],\n",
    "        'gpt-3.5-turbo': {\n",
    "            'Authoritarian': [0.667, 0.300, 0.033],\n",
    "            'Market': [0.133, 0.433, 0.033],\n",
    "            'Hierarchical': [0.033, 0.033, 0.067]\n",
    "        },\n",
    "        'claude-sonnet': {\n",
    "            'Authoritarian': [0.000, 0.267, 0.567],\n",
    "            'Market': [0.133, 0.167, 0.000],\n",
    "            'Hierarchical': [0.000, 0.033, 0.267]\n",
    "        }\n",
    "    },\n",
    "    'SST-2': {\n",
    "        'baseline': [0.800, 0.800, 0.800],\n",
    "        # 'CoT': [0.800, 0.800, 0.833],\n",
    "        # 'Emotive': [0.800, 0.800, 0.800],\n",
    "        'gpt-3.5-turbo': {\n",
    "            'Authoritarian': [0.800, 0.900, 0.967],\n",
    "            'Market': [0.800, 0.967, 0.800],\n",
    "            'Hierarchical': [0.967, 0.967, 0.867]\n",
    "        },\n",
    "        'claude-sonnet': {\n",
    "            'Authoritarian': [0.567, 0.967, 0.867],\n",
    "            'Market': [0.667, 0.067, 0.233],\n",
    "            'Hierarchical': [0.800, 0.900, 0.900]\n",
    "        }\n",
    "    },\n",
    "    'HumanEval': {\n",
    "        'baseline': [0.600, 0.600, 0.600],\n",
    "        # 'CoT': [0.667],\n",
    "        # 'Emotive': [0.667],\n",
    "        'gpt-3.5-turbo': {\n",
    "            'Authoritarian': [0.167, 0.233, 0.600],\n",
    "            'Market': [0.666, 0.700, 0.500],\n",
    "            'Hierarchical': [0.733, 0.433, 0.567]\n",
    "        },\n",
    "        'claude-sonnet': {\n",
    "            'Authoritarian': [0.400, 0.167, 0.467],\n",
    "            'Market': [0.600, 0.667, 0.567],\n",
    "            'Hierarchical': [0.600, 0.467, 0.600]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Data for Mistral\n",
    "mistral_data = {\n",
    "    'GSM8K': {\n",
    "        'baseline': [0.200, 0.200, 0.200],\n",
    "        # 'CoT': [0.267, 0.267, 0.267],\n",
    "        # 'Emotive': [0.067, 0.067, 0.067],\n",
    "        'gpt-3.5-turbo': {\n",
    "            'Authoritarian': [0.400, 0.000, 0.033],\n",
    "            'Market': [0.533, 0.333, 0.433],\n",
    "            'Hierarchical': [0.233, 0.467, 0.400]\n",
    "        },\n",
    "        'claude-sonnet': {\n",
    "            'Authoritarian': [0.000, 0.533, 0.300],\n",
    "            'Market': [0.233, 0.467, 0.000],\n",
    "            'Hierarchical': [0.000, 0.000, 0.200]\n",
    "        }\n",
    "    },\n",
    "    'SST-2': {\n",
    "        'baseline': [0.667, 0.667, 0.667],\n",
    "        # 'CoT': [0.700, 0.700, 0.700],\n",
    "        # 'Emotive': [0.700, 0.733, 0.700],\n",
    "        'gpt-3.5-turbo': {\n",
    "            'Authoritarian': [0.833, 0.867, 0.900],\n",
    "            'Market': [0.567, 0.833, 0.733],\n",
    "            'Hierarchical': [0.833, 0.933, 0.667]\n",
    "        },\n",
    "        'claude-sonnet': {\n",
    "            'Authoritarian': [0.133, 0.800, 0.533],\n",
    "            'Market': [0.667, 0.600, 0.033],\n",
    "            'Hierarchical': [0.633, 0.667, 0.800]\n",
    "        }\n",
    "    },\n",
    "    'HumanEval': {\n",
    "        'baseline': [0.467, 0.467, 0.467],\n",
    "        # 'CoT': [0.433],\n",
    "        # 'Emotive': [0.467],\n",
    "        'gpt-3.5-turbo': {\n",
    "            'Authoritarian': [0.333, 0.533, 0.500],\n",
    "            'Market': [0.200, 0.467, 0.400],\n",
    "            'Hierarchical': [0.367, 0.333, 0.467]\n",
    "        },\n",
    "        'claude-sonnet': {\n",
    "            'Authoritarian': [0.400, 0.133, 0.233],\n",
    "            'Market': [0.400, 0.467, 0.300],\n",
    "            'Hierarchical': [0.467, 0.333, 0.467]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform Wilcoxon Signed-Rank Test\n",
    "def perform_wilcoxon_test(baseline, framework_scores):\n",
    "    differences = np.array(baseline) - np.array(framework_scores)\n",
    "    if np.all(differences == 0):\n",
    "        return None, None\n",
    "    stat, p_value = wilcoxon(baseline, framework_scores)\n",
    "    return stat, p_value\n",
    "\n",
    "# General function to process data and perform tests\n",
    "def process_and_test(data):\n",
    "    results = {}\n",
    "    for dataset, models in data.items():\n",
    "        results[dataset] = {}\n",
    "        for model in models.keys():\n",
    "            if model == 'baseline':\n",
    "                continue\n",
    "            results[dataset][model] = {}\n",
    "            for framework in models[model].keys():\n",
    "                stat, p_value = perform_wilcoxon_test(models['baseline'], models[model][framework])\n",
    "                results[dataset][model][framework] = {'stat': stat, 'p_value': p_value}\n",
    "    return results\n",
    "\n",
    "# Process and test all data\n",
    "results = process_and_test(gpt_data)\n",
    "llama_results = process_and_test(llama_data)\n",
    "mistral_results = process_and_test(mistral_data)\n",
    "\n",
    "# Print results function\n",
    "def print_results(title, results):\n",
    "    print(title)\n",
    "    for dataset, models in results.items():\n",
    "        print(f\"\\nDataset: {dataset}\")\n",
    "        for model, frameworks in models.items():\n",
    "            print(f\"Model: {model}\")\n",
    "            for framework, result in frameworks.items():\n",
    "                if result['stat'] is None:\n",
    "                    print(f\"  Framework: {framework}, Test cannot be performed (all differences are zero)\")\n",
    "                else:\n",
    "                    print(f\"  Framework: {framework}, Test Statistic: {result['stat']}, p-value: {result['p_value']}\")\n",
    "\n",
    "# Print all results\n",
    "print_results(\"GPT-3.5-Turbo Results:\", results)\n",
    "print_results(\"\\nLlama-3.1 Results:\", llama_results)\n",
    "print_results(\"\\nMistral Results:\", mistral_results)\n",
    "\n",
    "# Interpretation of results function\n",
    "def interpret_results(title, results, alpha=0.05):\n",
    "    print(title)\n",
    "    for dataset, models in results.items():\n",
    "        print(f\"\\nDataset: {dataset}\")\n",
    "        for model, frameworks in models.items():\n",
    "            print(f\"Model: {model}\")\n",
    "            for framework, result in frameworks.items():\n",
    "                if result['stat'] is None:\n",
    "                    print(f\"  {framework} framework: Test cannot be performed (all differences are zero)\")\n",
    "                elif result['p_value'] < alpha:\n",
    "                    print(f\"  {framework} framework shows significant improvement (p-value: {result['p_value']})\")\n",
    "                else:\n",
    "                    print(f\"  {framework} framework does not show significant improvement (p-value: {result['p_value']})\")\n",
    "\n",
    "# Interpret all results\n",
    "interpret_results(\"\\nGPT-3.5-Turbo Results Interpretation:\", results)\n",
    "interpret_results(\"\\nLlama-3.1 Results Interpretation:\", llama_results)\n",
    "interpret_results(\"\\nMistral Results Interpretation:\", mistral_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authoritarian Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.prompts.chat import SystemMessage, _convert_to_message\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, ValidationError\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.output_parsers import JsonOutputToolsParser, JsonOutputParser\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_ollama import ChatOllama\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions, parse_response\n",
    "\n",
    "from langgraph.graph import END, StateGraph, MessageGraph\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import List, Sequence, TypedDict, Annotated, Dict, Any, Optional\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = \"Authoritarian Optimisation\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import Client\n",
    "\n",
    "# client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorePrinciples:\n",
    "    def __init__(self, core_principles: List[str]):\n",
    "        self.core_principles = core_principles\n",
    "    \n",
    "    def add_principle(self, principle: str):\n",
    "        \"\"\"\n",
    "        Adds a principle to the core principles list.\n",
    "        \n",
    "        :param principle: The principle to be added.\n",
    "        \"\"\"\n",
    "        self.core_principles.append(principle)\n",
    "        \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation of the core principles, each principle is listed on a new line with a preceding dash.\n",
    "        \n",
    "        Example:\n",
    "        - principle 1\n",
    "        - principle 2\n",
    "        ...\n",
    "        \"\"\"\n",
    "        return \"\\n\".join([f\"- {principle}\" for principle in self.core_principles])\n",
    "\n",
    "\n",
    "class AdvisorAgent:\n",
    "    \"\"\"\n",
    "    Advisor Agent class defining agents that provide feedback on prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, position: str, core_principles: CorePrinciples, llm):\n",
    "        self.position = position\n",
    "        self.core_principles = str(core_principles)\n",
    "        self.system_message = f\"\"\"You are an experienced: {self.position}. Your core principles are:\n",
    "{self.core_principles}\"\"\"\n",
    "        self.llm = llm\n",
    "\n",
    "        assert isinstance(self.llm, ChatOpenAI) or isinstance(self.llm, ChatAnthropic), \"The LLM must be an instance of ChatOpenAI or ChatAnthropic.\"\n",
    "\n",
    "    def review_prompt(self, state: Sequence[BaseMessage], criteria: str):\n",
    "        \"\"\"\n",
    "        Generates a review of the prompt.\n",
    "        \"\"\"\n",
    "        # if isinstance(self.llm, ChatOpenAI):\n",
    "        prompt_text = f\"\"\"Your task is to provide feedback on the prompt in the conversation above in light of your core princples.\n",
    "Always think outside the box and consider unconventional ideas.\n",
    "\n",
    "The success criteria for the updated prompt are as follows:\n",
    "{criteria}\n",
    "You must use this information to inform your feedback.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt as an experienced: {self.position}. Understand it's content and intent.\n",
    "2. Explain how you think the prompt can be improved in light of your core principles.\n",
    "3. Submit your feedback.\"\"\"\n",
    "        if isinstance(self.llm, ChatOpenAI):\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_message),\n",
    "                    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                    (\"system\", prompt_text),\n",
    "                ]\n",
    "            )\n",
    "        elif isinstance(self.llm, ChatAnthropic):\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_message),\n",
    "                    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                    (\"user\", prompt_text),\n",
    "                ]\n",
    "            )\n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"messages\": state})\n",
    "        return {\"messages\": [HumanMessage(content=result.content, name=self.position)]}\n",
    "        \n",
    "    def approval(self, state: Sequence[BaseMessage]):\n",
    "        \"\"\"\n",
    "        Agent to approve or reject the prompt.\n",
    "        \"\"\"\n",
    "        prompt_text = f\"\"\"Your task is to decide if the prompt in the conversation above is optimal in light of your core principles.\n",
    "\n",
    "If you think the prompt is optimal and does not require improvements in light of your core principles, return True.\n",
    "If you think the prompt needs improvements in light of your core principles, return False.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt as an experienced: {self.position}. Understand it's content and intent.\n",
    "2. Determine whether the prompt is optimal in light of your core principles.\n",
    "3. Submit your decision.\"\"\"\n",
    "        function_def = {\n",
    "            \"name\": \"approval\",\n",
    "            \"description\": \"Get approval decision of advisor.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"advisor\": {\"type\": \"string\", \"enum\": [self.position]},\n",
    "                    \"decision\": {\"type\": \"string\", \"enum\": [\"True\", \"False\"]},\n",
    "                },\n",
    "                \"required\": [\"decision\", \"advisor\"],\n",
    "            },\n",
    "        }\n",
    "        if isinstance(self.llm, ChatOpenAI):\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_message),\n",
    "                    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                    (\"system\", prompt_text),\n",
    "                ]\n",
    "            )\n",
    "            chain = (\n",
    "                prompt \n",
    "                | self.llm.bind_functions(functions=[function_def], function_call=\"approval\")\n",
    "                | JsonOutputFunctionsParser()\n",
    "            )\n",
    "            result = chain.invoke({\"messages\": state})\n",
    "            return result\n",
    "        elif isinstance(self.llm, ChatAnthropic):\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_message),\n",
    "                    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                    (\"user\", prompt_text),\n",
    "                ]\n",
    "            )\n",
    "            chain = (\n",
    "                prompt \n",
    "                | self.llm.bind_tools(tools=[function_def])\n",
    "            )\n",
    "            result = chain.invoke({\"messages\": state})\n",
    "            # print(result)\n",
    "            if \"text\" in result.content[0]:\n",
    "                return result.content[1][\"input\"]\n",
    "            else:\n",
    "                return result.content[0][\"input\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeaderAgent:\n",
    "    \"\"\"\n",
    "    LeaderAgent class defining an agent that generates and communicates with advisor agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_prompt: str, criteria: str, advisors: List[AdvisorAgent], llm):\n",
    "        self.base_prompt = base_prompt\n",
    "        self.criteria = criteria\n",
    "        self.system_message = f\"\"\"You are an experienced: Lead AI Prompt Engineer. Your core principles are:\n",
    "- Always pay attention to detail when designing prompts\n",
    "- Always make informed decisions when designing prompts\n",
    "- Always be open to new ideas when designing prompts\"\"\"\n",
    "        self.llm = llm\n",
    "        self.advisors = advisors\n",
    "        self.iterations = 0\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the iterations counter to 0.\n",
    "        \"\"\"\n",
    "        self.iterations = 0\n",
    "    \n",
    "    def run_approval(self, state: Sequence[BaseMessage]) -> List[bool]:\n",
    "        \"\"\"\n",
    "        Run the approval process for the prompt. Run concurrently\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(advisor.approval, state) for advisor in self.advisors]\n",
    "            results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "        return results\n",
    "    \n",
    "    def leader_decision(self, state: Sequence[BaseMessage]):\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next advisor or to finish.\n",
    "        \"\"\"\n",
    "        self.iterations += 1\n",
    "        approval_results = self.run_approval(state)\n",
    "        # print(\"Approval results:\", approval_results)\n",
    "        # Extract decisions from the results\n",
    "        if all(str(approval_result['decision']) == \"True\" for approval_result in approval_results) or self.iterations >= 6:\n",
    "            self.reset()\n",
    "            return \"FINISH\"\n",
    "        else:\n",
    "            # Only ask for advise from advisors that disapproved the prompt\n",
    "            disapproved_advisors = [approval_result['advisor'] for approval_result in approval_results if str(approval_result['decision']) == \"False\"]\n",
    "            disapproved_advisors_details = \"\\n\".join([f\"{advisor.position}: {advisor.core_principles}\" for advisor in self.advisors if advisor.position in disapproved_advisors])\n",
    "            # shuffle the options to avoid positional bias\n",
    "            random.shuffle(disapproved_advisors)\n",
    "            # options = [\"FINISH\"] + positions\n",
    "            prompt_text = f\"\"\"Your task is to select the next advisor to provide feedback on the prompt in the conversation above.\n",
    "Think carefully about which advisor will provide the most valuable feedback to make improvements.\n",
    "            \n",
    "The success criteria for the prompt are as follows:\n",
    "{self.criteria}\n",
    "\n",
    "Select one of the below advisors that disapproved of the previous prompt to provide feedback on how to improve it: \n",
    "{disapproved_advisors}\n",
    "\n",
    "The details of all disapproving advisors and their core principles are as follows: \n",
    "{disapproved_advisors_details}\n",
    "\n",
    "Your selection process should be as follows:\n",
    "1. Read the prompt as an experienced: Lead AI Prompt Engineer. Understand it's content and intent.\n",
    "2. Explicitly detail how you think the prompt can be improved. Assume the prompt always needs improvement.\n",
    "3. Select which disapproving advisor you think will provide the most valuable feedback to make improvements.\n",
    "4. Submit your selection for the next advisor.\"\"\"\n",
    "            function_def = {\n",
    "                \"name\": \"next\",\n",
    "                \"description\": \"Get the next role.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"next\": {\"type\": \"string\", \"enum\": disapproved_advisors},\n",
    "                    },\n",
    "                    \"required\": [\"next\"],\n",
    "                },\n",
    "            }\n",
    "            if type(self.llm) == ChatOpenAI:\n",
    "                prompt = ChatPromptTemplate.from_messages(\n",
    "                    [\n",
    "                        (\"system\", self.system_message),\n",
    "                        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                        (\"system\", prompt_text),\n",
    "                    ]\n",
    "                )\n",
    "                chain = (\n",
    "                    prompt\n",
    "                    | self.llm.bind_functions(functions=[function_def], function_call=\"next\")\n",
    "                    | JsonOutputFunctionsParser()\n",
    "                )\n",
    "                result = chain.invoke({\"messages\": state})\n",
    "                return result[\"next\"]\n",
    "            elif isinstance(self.llm, ChatAnthropic):\n",
    "                prompt = ChatPromptTemplate.from_messages(\n",
    "                    [\n",
    "                        (\"system\", self.system_message),\n",
    "                        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                        (\"user\", prompt_text),\n",
    "                    ]\n",
    "                )\n",
    "                # fail safe to avoid errors when the model is not able to generate the next advisor\n",
    "                try: \n",
    "                    chain = (\n",
    "                        prompt \n",
    "                        | self.llm.bind_tools(tools=[function_def])\n",
    "                    )\n",
    "                    result = chain.invoke({\"messages\": state})\n",
    "                    print(result)\n",
    "                    if \"text\" in result.content[0]:\n",
    "                        return result.content[1][\"input\"][\"next\"]\n",
    "                    else:\n",
    "                        return result.content[0][\"input\"][\"next\"]\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    # return random advisor if the model is not able to generate the next advisor\n",
    "                    return random.choice(disapproved_advisors)\n",
    "\n",
    "    def update_prompt(self, state: Sequence[BaseMessage]) -> str:\n",
    "        \"\"\"\n",
    "        Updates the prompt with the feedback from the advisor agent.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(state) == 1:\n",
    "            return {\"next\": self.leader_decision(state)}\n",
    "        \n",
    "        prompt_text = f\"\"\"Your task is to improve the prompt in the conversation above in light of your core principles.\n",
    "If you recieve feedback and recommendations for the prompt, respond with a revised version of your previous attempts actioning the feedback.\n",
    "\n",
    "The success criteria for the prompt are as follows:\n",
    "{self.criteria}\n",
    "You will be penalized if the prompt does not meet this criteria.\n",
    "\n",
    "Below are strict guidelines that you MUST follow if making changes to the prompt:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces. If you wish to use curly braces in your response, use double curly braces to avoid confusion with placeholders.\n",
    "- ALWAYS treat placeholders as the actual content.\n",
    "You will be penalized if you do not follow these guidelines.\n",
    "\n",
    "Your update process should be as follows:\n",
    "1. Read the prompt as an experienced: Head AI Engineer. Understand it's content and intent.\n",
    "2. Think carefully about how you can implement the most recent feedback and revise the prompt.\n",
    "3. Explcitly go through each success criteria and ensure the prompt meets them. If not, revise the prompt to make sure it does.\n",
    "4. Explicitly go through each guideline and ensure the changes adhere to them. If not, revise the prompt to make sure it does.\n",
    "5. Submit your revised prompt.\"\"\"\n",
    "        if isinstance(self.llm, ChatOpenAI):\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_message),\n",
    "                    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                    (\"system\", prompt_text),\n",
    "                ]\n",
    "            )\n",
    "        elif isinstance(self.llm, ChatAnthropic):\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_message),\n",
    "                    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                    (\"user\", prompt_text),\n",
    "                ]\n",
    "            )\n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"messages\": state})\n",
    "        next = self.leader_decision(state)\n",
    "        print(next)\n",
    "        # print(result)\n",
    "        return {\"messages\": [AIMessage(content=result.content, name=\"Leader\")], \"next\": next}\n",
    "\n",
    "    def construct_advisor_graph(self):\n",
    "        \"\"\"\n",
    "        Constructs a graph of advisor agents based on their roles and functions.\n",
    "        \"\"\"\n",
    "\n",
    "        def advisor_node(state, agent):\n",
    "            return agent.review_prompt(state[\"messages\"], self.criteria)\n",
    "        \n",
    "        def leader_node(state):\n",
    "            return self.update_prompt(state[\"messages\"]) \n",
    "        \n",
    "        # The agent state is the input to each node in the graph\n",
    "        class AgentState(TypedDict):\n",
    "            messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "            next: str\n",
    "\n",
    "        workflow = StateGraph(AgentState)\n",
    "        for advisor in self.advisors:\n",
    "            # Create a node for each advisor agent\n",
    "            node = functools.partial(advisor_node, agent=advisor)\n",
    "            workflow.add_node(advisor.position, node)\n",
    "        workflow.add_node(\"Leader\", leader_node)\n",
    "\n",
    "        members = [advisor.position for advisor in self.advisors]\n",
    "        for member in members:\n",
    "            # We want our advisors to ALWAYS \"report back\" to the leader when done\n",
    "            workflow.add_edge(member, \"Leader\")\n",
    "        # The leader populates the \"next\" field in the graph state with routes to a node or finishes\n",
    "        conditional_map = {k: k for k in members}\n",
    "        conditional_map[\"FINISH\"] = END\n",
    "        workflow.add_conditional_edges(\"Leader\", lambda x: x[\"next\"], conditional_map)\n",
    "        workflow.set_entry_point(\"Leader\")\n",
    "\n",
    "        memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "        graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "        return graph\n",
    "    \n",
    "    def optimise_prompt(self):\n",
    "        \"\"\"\n",
    "        Optimises a prompt by invoking a graph of advisor agents.\n",
    "        \"\"\"\n",
    "        # Initial state\n",
    "        initial_state = {\n",
    "            \"messages\": [HumanMessage(content=self.base_prompt, name=\"User\")],\n",
    "        }\n",
    "\n",
    "        # Construct the graph\n",
    "        graph = self.construct_advisor_graph()\n",
    "        # display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "        n = random.randint(0, 1000)\n",
    "        config = {\n",
    "            \"configurable\": {\"thread_id\": n},\n",
    "            \"recursion_limit\": 50,\n",
    "            }    \n",
    "\n",
    "        # Run the graph\n",
    "        for s in graph.stream(\n",
    "            initial_state,\n",
    "            config,\n",
    "            stream_mode=\"values\",\n",
    "            ):\n",
    "            if \"__end__\" not in s:\n",
    "                # if len(s[\"messages\"]) > 1:\n",
    "                #     s[\"messages\"][-1].pretty_print()\n",
    "                continue\n",
    "        \n",
    "        # def message_to_dict(obj):\n",
    "        #     if isinstance(obj, HumanMessage) or isinstance(obj, AIMessage):\n",
    "        #         return {obj.name: obj.content}\n",
    "        #     raise TypeError(f'Object of type {obj.__class__.__name__} is not JSON serializable')\n",
    "\n",
    "        # if type(self.llm) == ChatOpenAI:\n",
    "        #     model = self.llm.model_name\n",
    "        # else:\n",
    "        #     model = self.llm.model\n",
    "        # temp = int(self.llm.temperature)\n",
    "        # path = f\"/Users/iwatson/Documents/Research Project/prompt-optimisation/src/conversations/{model}/conversations_authoritarian_{temp}.json\"\n",
    "        # if not os.path.exists(path):\n",
    "        #     with open(path, \"w\") as f:\n",
    "        #         json.dump([], f)\n",
    "        \n",
    "        # with open(path, \"r\") as f:\n",
    "        #     # write messages to json file\n",
    "        #     data = json.load(f)\n",
    "        #     # get the current key number then increment it\n",
    "        #     key = len(data)\n",
    "        #     data.append({key: json.dumps(s, default=message_to_dict)})\n",
    "            \n",
    "        # with open(path, \"w\") as f:\n",
    "        #     json.dump(data, f, indent=4)\n",
    "\n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import gsm8k, human_eval, sst2\n",
    "\n",
    "human_eval_baseline = human_eval.get_baseline_prompt()\n",
    "human_eval_criteria = human_eval.get_criteria()\n",
    "\n",
    "gsm8k_baseline = gsm8k.get_baseline_prompt()\n",
    "gsm8k_criteria = gsm8k.get_criteria()\n",
    "\n",
    "sst2_baseline_prompt = sst2.get_baseline_prompt()\n",
    "sst2_criteria = sst2.get_criteria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatAnthropic(temperature=0, model=\"claude-3-haiku-20240307\")\n",
    "llm = ChatAnthropic(temperature=0, model=\"claude-3-5-sonnet-20240620\")\n",
    "# llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "# llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "# llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
    "# llm = ChatOllama(temperature=1, model=\"mistral:v0.3\")\n",
    "# llm = ChatOllama(temperature=0, model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_suite import PromptDesignAgents, HumanEvalAgents, GSM8kAgents, SST2Agents\n",
    "\n",
    "prompt_design_agents = PromptDesignAgents()\n",
    "\n",
    "style_and_structure_expert = AdvisorAgent(\"Style_and_Structure_Expert\", CorePrinciples(prompt_design_agents.get_style_and_structure_principles()), llm)\n",
    "conciseness_and_clarity_expert = AdvisorAgent(\"Conciseness_and_Clarity_Expert\", CorePrinciples(prompt_design_agents.get_conciseness_and_clarity_principles()), llm)\n",
    "contextual_relevance_expert = AdvisorAgent(\"Contextual_Relevance_Expert\", CorePrinciples(prompt_design_agents.get_contextual_relevance_principles()), llm)\n",
    "task_alignment_expert = AdvisorAgent(\"Task_Alignment_Expert\", CorePrinciples(prompt_design_agents.get_task_alignment_principles()), llm)\n",
    "example_demonstration_expert = AdvisorAgent(\"Example_Demonstration_Expert\", CorePrinciples(prompt_design_agents.get_example_demonstration_principles()), llm)\n",
    "incremental_prompting_expert = AdvisorAgent(\"Incremental_Prompting_Expert\", CorePrinciples(prompt_design_agents.get_incremental_prompting_principles()), llm)\n",
    "\n",
    "human_eval_agents = HumanEvalAgents()\n",
    "\n",
    "code_reviewer = AdvisorAgent(\"Code_Reviewer\", CorePrinciples(human_eval_agents.get_code_reviewer_principles()), llm)\n",
    "software_engineer = AdvisorAgent(\"Software_Engineer\", CorePrinciples(human_eval_agents.get_software_engineering_principles()), llm)\n",
    "software_architect = AdvisorAgent(\"Software_Architect\", CorePrinciples(human_eval_agents.get_software_architecture_principles()), llm)\n",
    "\n",
    "gsm8k_agents = GSM8kAgents()\n",
    "\n",
    "mathematician = AdvisorAgent(\"Mathematician\", CorePrinciples(gsm8k_agents.get_mathematician_principles()), llm)\n",
    "word_problem_solver = AdvisorAgent(\"Word_Problem_Solver\", CorePrinciples(gsm8k_agents.get_word_problem_solver_principles()), llm)\n",
    "\n",
    "sst2_agents = SST2Agents()\n",
    "\n",
    "graded_sentiment_analyst = AdvisorAgent(\"Graded_Sentiment_Analyst\", CorePrinciples(sst2_agents.get_graded_sentiment_analyst_principles()), llm)\n",
    "emotive_sentiment_analyst = AdvisorAgent(\"Emotive_Sentiment_Analyst\", CorePrinciples(sst2_agents.get_emotive_sentiment_analyst_principles()), llm)\n",
    "aspect_based_sentiment_analyst = AdvisorAgent(\"Aspect_Based_Sentiment_Analyst\", CorePrinciples(sst2_agents.get_aspect_based_sentiment_analyst_principles()), llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"\"\n",
    "if dataset == \"human_eval\":\n",
    "    baseline_prompt = human_eval_baseline\n",
    "    criteria = human_eval_criteria\n",
    "    domain_experts = [software_engineer, software_architect, code_reviewer]\n",
    "elif dataset == \"gsm8k\":\n",
    "    baseline_prompt = gsm8k_baseline\n",
    "    criteria = gsm8k_criteria\n",
    "    domain_experts = [mathematician, word_problem_solver]\n",
    "elif dataset == \"sst2\":\n",
    "    baseline_prompt = sst2_baseline_prompt\n",
    "    criteria = sst2_criteria\n",
    "    domain_experts = [graded_sentiment_analyst, emotive_sentiment_analyst, aspect_based_sentiment_analyst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position:  Style_and_Structure_Expert\n",
      "Core Principles:\n",
      " - Always structure prompts logically for the task\n",
      "- Always use a style and tone in prompts that is appropriate for the task\n",
      "- Always assign a role to the language model that is relevant to the task\n",
      "Position:  Conciseness_and_Clarity_Expert\n",
      "Core Principles:\n",
      " - Always write clear and concise prompts\n",
      "- Always use simple and direct language in prompts\n",
      "- Always avoid ambiguity in prompts\n",
      "Position:  Contextual_Relevance_Expert\n",
      "Core Principles:\n",
      " - Always provide context to help the model understand the task\n",
      "- Always write prompts informed by the context of the task\n",
      "- Always design contextually relevant roles for the language model\n",
      "Position:  Task_Alignment_Expert\n",
      "Core Principles:\n",
      " - Always write prompts that align with the task criteria\n",
      "- Always tailor instructions to the task to guide the model\n",
      "- Always make the task abundantly clear to the model in the prompt\n",
      "Position:  Example_Demonstration_Expert\n",
      "Core Principles:\n",
      " - Always provide examples to help the model understand the task\n",
      "- Always provide examples that cover a range of complexities\n",
      "- Always demonstrate the expected output of the model\n",
      "Position:  Incremental_Prompting_Expert\n",
      "Core Principles:\n",
      " - Always break-down complex tasks\n",
      "- Always write clear step-by-step instructions to guide the model\n",
      "- Always write instructions appropriate for the task complexity\n"
     ]
    }
   ],
   "source": [
    "experts = [style_and_structure_expert, conciseness_and_clarity_expert, contextual_relevance_expert, task_alignment_expert, example_demonstration_expert, incremental_prompting_expert] + domain_experts\n",
    "leader_agent = LeaderAgent(\n",
    "    base_prompt=baseline_prompt,\n",
    "    criteria=criteria,\n",
    "    advisors=experts,\n",
    "    llm = llm\n",
    ")\n",
    "for advisor in leader_agent.advisors:\n",
    "    print(\"Position: \", advisor.position + \"\\nCore Principles:\\n\", advisor.core_principles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=[{'text': 'As an experienced Lead AI Prompt Engineer, I\\'ve carefully reviewed the prompt for the JP Morgan Asset Management customer support assistant. While the prompt provides a good foundation, there are several areas where it can be improved to better meet the success criteria and enhance its effectiveness. Here\\'s my analysis of how the prompt can be improved:\\n\\n1. Structure and Clarity: The prompt could benefit from a more organized structure, clearly separating the role description, task instructions, and tool usage guidelines. This would make it easier for the AI to understand and follow the steps.\\n\\n2. Tool Usage: While the prompt mentions the tools available (authenticate_account, account_exists, get_tavily_response), it doesn\\'t provide clear instructions on when and how to use each tool. This could lead to confusion or improper use of the tools.\\n\\n3. Authentication Process: The authentication steps are mentioned, but they could be more clearly defined and ordered to ensure the AI follows the correct sequence every time.\\n\\n4. Natural Conversation: The prompt doesn\\'t explicitly instruct the AI on how to conduct a natural and professional conversation while following the authentication steps.\\n\\n5. Handling Unrelated Questions: While the prompt mentions using the get_tavily_response tool for unrelated questions, it doesn\\'t provide guidance on how to transition back to the account-related conversation.\\n\\n6. Post-Authentication Instructions: The prompt lacks clear instructions on what to do after successful authentication, such as how to handle account-related inquiries.\\n\\n7. Error Handling: There are no instructions on how to handle scenarios where authentication fails or the account doesn\\'t exist.\\n\\nGiven these areas for improvement, I believe the advisor who can provide the most valuable feedback is the Task_Alignment_Expert. This expert\\'s core principles align well with the needs of this prompt:\\n\\n- Always write prompts that align with the task criteria\\n- Always tailor instructions to the task to guide the model\\n- Always make the task abundantly clear to the model in the prompt\\n\\nThe Task_Alignment_Expert can help ensure that the prompt clearly outlines all necessary steps, properly integrates the use of tools, and provides comprehensive guidance for various scenarios the AI might encounter during customer interactions. This will help align the prompt more closely with the success criteria and improve its overall effectiveness.\\n\\nTo submit this selection, I\\'ll use the \"next\" function:', 'type': 'text'}, {'id': 'toolu_012MbizdaCYfA6g9fUrpFR4E', 'input': {'next': 'Task_Alignment_Expert'}, 'name': 'next', 'type': 'tool_use'}] response_metadata={'id': 'msg_01WC9VECrMYPqs3wQ2NMiZBE', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 1293, 'output_tokens': 551}} id='run-42c4d494-a93b-4381-9ba1-01d3e3bbf8a3-0' tool_calls=[{'name': 'next', 'args': {'next': 'Task_Alignment_Expert'}, 'id': 'toolu_012MbizdaCYfA6g9fUrpFR4E', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1293, 'output_tokens': 551, 'total_tokens': 1844}\n",
      "content=[{'text': 'As an experienced Lead AI Prompt Engineer, I\\'ve carefully reviewed the prompt and identified several areas for improvement:\\n\\n1. Task Alignment: While the prompt covers the main steps, it could be more explicit about the ultimate goal of assisting customers with their account information. The prompt should clarify what kind of account information the assistant can provide once authentication is complete.\\n\\n2. Incremental Steps: The authentication process could be broken down into more granular steps, providing clearer guidance on how to handle each piece of information (name, address, postcode, date of birth) separately.\\n\\n3. Example Demonstration: The prompt lacks examples of how the assistant should respond in different scenarios, such as when an account doesn\\'t exist or when authentication fails.\\n\\n4. Contextual Relevance: The prompt could benefit from more context about JP Morgan Asset Management and the types of accounts or services customers might inquire about.\\n\\n5. Conciseness and Clarity: While the prompt is relatively clear, some instructions could be more concise and direct, particularly in the \"Handling Unrelated Questions\" section.\\n\\nGiven these areas for improvement, I believe the Incremental_Prompting_Expert would provide the most valuable feedback. This expert\\'s core principles align well with the need to break down the complex task of customer authentication and account information retrieval into clearer, more manageable steps. Their expertise in writing clear step-by-step instructions and tailoring instructions to task complexity would be particularly beneficial in refining the authentication process and clarifying how to handle different scenarios the assistant might encounter.\\n\\nLet\\'s proceed with selecting the Incremental_Prompting_Expert for the next round of feedback.', 'type': 'text'}, {'id': 'toolu_01SmeVCHhHV57kZbuUFxtAdp', 'input': {'next': 'Incremental_Prompting_Expert'}, 'name': 'next', 'type': 'tool_use'}] response_metadata={'id': 'msg_01W6y55iVMLxazPzDndZ1pm3', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 2033, 'output_tokens': 414}} id='run-aa4498d8-fc55-40e5-9449-a6f4462fb7d4-0' tool_calls=[{'name': 'next', 'args': {'next': 'Incremental_Prompting_Expert'}, 'id': 'toolu_01SmeVCHhHV57kZbuUFxtAdp', 'type': 'tool_call'}] usage_metadata={'input_tokens': 2033, 'output_tokens': 414, 'total_tokens': 2447}\n",
      "Incremental_Prompting_Expert\n",
      "content=[{'text': 'As an experienced Lead AI Prompt Engineer, I\\'ve carefully reviewed the prompt. While it\\'s well-structured and covers most of the necessary points, there are still areas for improvement:\\n\\n1. Conciseness: The prompt can be made more concise by removing some redundant information and combining related steps.\\n\\n2. Clarity: Some instructions could be more specific, particularly regarding the use of tools and handling of account information.\\n\\n3. Examples: The prompt lacks concrete examples of how the assistant should interact with customers, which could lead to inconsistent responses.\\n\\n4. Step-by-step breakdown: While the prompt is structured in steps, some steps could be further broken down for more precise guidance.\\n\\n5. Tool usage: The instructions for using tools could be more explicitly integrated into each relevant step.\\n\\nConsidering these areas for improvement, I believe the Incremental_Prompting_Expert would provide the most valuable feedback. This expert\\'s core principles align well with the needed improvements:\\n\\n- \"Always break-down complex tasks\": This will help in further refining the steps, especially for handling account inquiries and using tools.\\n- \"Always write clear step-by-step instructions to guide the model\": This principle will ensure that each step is more explicitly defined, reducing ambiguity.\\n- \"Always write instructions appropriate for the task complexity\": This will help in balancing the level of detail needed for each step, ensuring the prompt is neither too vague nor overly complex.\\n\\nThe Incremental_Prompting_Expert can provide valuable insights on how to break down the authentication process and account inquiry handling into more granular steps, ensuring that the assistant follows a clear, step-by-step approach throughout the interaction.\\n\\nTherefore, I recommend selecting the Incremental_Prompting_Expert as the next advisor to provide feedback on this prompt.', 'type': 'text'}, {'id': 'toolu_0181zDMHGEmouBWd8sgydnAQ', 'input': {'next': 'Incremental_Prompting_Expert'}, 'name': 'next', 'type': 'tool_use'}] response_metadata={'id': 'msg_01VVA6DCZpgcT1PKY1E3Te4b', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 3312, 'output_tokens': 448}} id='run-72e65e6f-d2fb-4d03-954a-d8aae0eba56f-0' tool_calls=[{'name': 'next', 'args': {'next': 'Incremental_Prompting_Expert'}, 'id': 'toolu_0181zDMHGEmouBWd8sgydnAQ', 'type': 'tool_call'}] usage_metadata={'input_tokens': 3312, 'output_tokens': 448, 'total_tokens': 3760}\n",
      "Incremental_Prompting_Expert\n",
      "content='As an experienced Lead AI Prompt Engineer, I\\'ve carefully reviewed the prompt. While it\\'s well-structured and covers the main points, there are still areas for improvement:\\n\\n1. Examples: The prompt lacks concrete examples of interactions, which could help the model better understand the expected behavior in various scenarios.\\n\\n2. Specificity: Some instructions could be more specific, particularly regarding how to handle different types of account-related queries.\\n\\n3. Error Handling: The prompt could benefit from more guidance on how to handle errors or unexpected situations during the authentication process.\\n\\n4. Tone and Language: While professionalism is mentioned, specific examples of appropriate language and tone could be beneficial.\\n\\n5. Privacy and Security: More emphasis could be placed on data protection practices during the conversation.\\n\\nGiven these areas for improvement, I believe the Example_Demonstration_Expert would provide the most valuable feedback. Their core principles align perfectly with the current needs of the prompt:\\n\\n1. \"Always provide examples to help the model understand the task\": This advisor can offer concrete examples of customer interactions, showcasing how to handle various scenarios.\\n\\n2. \"Always provide examples that cover a range of complexities\": They can demonstrate how to deal with straightforward queries as well as more complex situations, like partial authentication or sensitive account issues.\\n\\n3. \"Always demonstrate the expected output of the model\": This principle is crucial for showing the exact language, tone, and structure the model should use in its responses.\\n\\nThe Example_Demonstration_Expert can provide sample dialogues that illustrate the entire process from greeting to resolution, including how to use each tool effectively. This will greatly enhance the prompt\\'s clarity and effectiveness.\\n\\nTherefore, I select the Example_Demonstration_Expert as the next advisor to provide feedback.' response_metadata={'id': 'msg_01NijJWTPjkEMNTChkrJ4pva', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 4447, 'output_tokens': 373}} id='run-7d3b300f-a78f-418f-b40d-4ff350703b8d-0' usage_metadata={'input_tokens': 4447, 'output_tokens': 373, 'total_tokens': 4820}\n",
      "string indices must be integers, not 'str'\n",
      "Example_Demonstration_Expert\n",
      "content=[{'text': 'As an experienced Lead AI Prompt Engineer, I\\'ve carefully reviewed the prompt. While it\\'s well-structured and covers the main points, there are still areas for improvement:\\n\\n1. Clarity and Examples: The prompt lacks specific examples of how the assistant should interact with customers. Adding examples would help illustrate the expected tone and level of detail in responses.\\n\\n2. Tool Usage Demonstration: While the tools are mentioned, there\\'s no demonstration of how to use them in practice. Showing example tool calls would be beneficial.\\n\\n3. Handling Edge Cases: The prompt doesn\\'t address how to handle situations where authentication fails or when customers provide incomplete information.\\n\\n4. Response Formatting: There\\'s no guidance on how to structure responses to customers, which could lead to inconsistency.\\n\\n5. Privacy and Security Emphasis: While mentioned, the importance of privacy and security could be further emphasized with specific do\\'s and don\\'ts.\\n\\nGiven these areas for improvement, I believe the Example_Demonstration_Expert would provide the most valuable feedback. Their core principles align perfectly with the needed improvements:\\n\\n- \"Always provide examples to help the model understand the task\": This advisor can provide concrete examples of customer interactions, tool usage, and response formatting.\\n- \"Always provide examples that cover a range of complexities\": They can offer examples for both straightforward and complex scenarios, including edge cases.\\n- \"Always demonstrate the expected output of the model\": This principle is crucial for showing how the assistant should structure its responses and use the tools.\\n\\nTherefore, I select the Example_Demonstration_Expert to provide the next round of feedback.', 'type': 'text'}, {'id': 'toolu_012TX18EBawgGXZcWYLVjdU2', 'input': {'next': 'Example_Demonstration_Expert'}, 'name': 'next', 'type': 'tool_use'}] response_metadata={'id': 'msg_01VHH2boGcfQLHKgWJZw8NN5', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 5744, 'output_tokens': 394}} id='run-e1b239ca-07a7-4104-a2f8-1ccf914632e4-0' tool_calls=[{'name': 'next', 'args': {'next': 'Example_Demonstration_Expert'}, 'id': 'toolu_012TX18EBawgGXZcWYLVjdU2', 'type': 'tool_call'}] usage_metadata={'input_tokens': 5744, 'output_tokens': 394, 'total_tokens': 6138}\n",
      "Example_Demonstration_Expert\n",
      "FINISH\n",
      "Time taken:  146.33400988578796\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Leader\n",
      "\n",
      "Thank you for the feedback and guidelines. I've carefully reviewed the prompt and made revisions to address the feedback while adhering to the guidelines and success criteria. Here's the revised prompt:\n",
      "\n",
      "Today's date is {today}, and the time is {time}. You are a customer support assistant for JP Morgan Asset Management. Follow these steps to assist customers with their account information:\n",
      "\n",
      "1. Greet the customer professionally and ask for their account number.\n",
      "\n",
      "2. Use `account_exists` tool with the provided number. If it exists, proceed to step 3. If not, politely inform the customer and end the conversation.\n",
      "\n",
      "3. Request authentication details: full name, complete address, postcode, and date of birth.\n",
      "\n",
      "4. Use `authenticate_account` tool with these details. If authenticated, inform the customer and ask how you can assist with their account.\n",
      "\n",
      "5. For account-related questions:\n",
      "   - Provide accurate information based on authenticated details.\n",
      "   - If more information is needed, inform the customer you'll retrieve it.\n",
      "\n",
      "6. For non-account queries, use `get_tavily_response` tool for accurate answers.\n",
      "\n",
      "7. Throughout the conversation:\n",
      "   - Maintain a courteous, natural tone.\n",
      "   - Offer clarification if needed.\n",
      "   - Prioritize customer security and privacy.\n",
      "   - Do not provide account information until fully authenticated.\n",
      "   - If unsure, inform the customer you need to consult a supervisor.\n",
      "\n",
      "Tools:\n",
      "- `account_exists`: Verifies account number validity.\n",
      "- `authenticate_account`: Confirms customer's name, address, postcode, and date of birth.\n",
      "- `get_tavily_response`: Answers questions unrelated to the account.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "times = []\n",
    "for _ in range(1):\n",
    "    start = time.time()\n",
    "    result = leader_agent.optimise_prompt()\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "    print(\"Time taken: \", end - start)\n",
    "    result[\"messages\"][-1].pretty_print()\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you for the feedback and guidelines. I've carefully reviewed the prompt and made revisions to address the feedback while adhering to the guidelines and success criteria. Here's the revised prompt:\\n\\nToday's date is {today}, and the time is {time}. You are a customer support assistant for JP Morgan Asset Management. Follow these steps to assist customers with their account information:\\n\\n1. Greet the customer professionally and ask for their account number.\\n\\n2. Use `account_exists` tool with the provided number. If it exists, proceed to step 3. If not, politely inform the customer and end the conversation.\\n\\n3. Request authentication details: full name, complete address, postcode, and date of birth.\\n\\n4. Use `authenticate_account` tool with these details. If authenticated, inform the customer and ask how you can assist with their account.\\n\\n5. For account-related questions:\\n   - Provide accurate information based on authenticated details.\\n   - If more information is needed, inform the customer you'll retrieve it.\\n\\n6. For non-account queries, use `get_tavily_response` tool for accurate answers.\\n\\n7. Throughout the conversation:\\n   - Maintain a courteous, natural tone.\\n   - Offer clarification if needed.\\n   - Prioritize customer security and privacy.\\n   - Do not provide account information until fully authenticated.\\n   - If unsure, inform the customer you need to consult a supervisor.\\n\\nTools:\\n- `account_exists`: Verifies account number validity.\\n- `authenticate_account`: Confirms customer's name, address, postcode, and date of birth.\\n- `get_tavily_response`: Answers questions unrelated to the account.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max time: \", max(times))\n",
    "print(\"Min time: \", min(times))\n",
    "print(\"Average time: \", sum(times) / len(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

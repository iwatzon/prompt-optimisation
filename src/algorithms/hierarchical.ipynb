{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts.chat import SystemMessage, _convert_to_message\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "from langgraph.graph import END, StateGraph, MessageGraph\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import List, Sequence, TypedDict, Annotated\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = \"Hierarchical Optimisation\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import Client\n",
    "\n",
    "# client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorePrinciples:\n",
    "    def __init__(self, core_principles: List[str]):\n",
    "        self.core_principles = core_principles\n",
    "    \n",
    "    def add_principle(self, principle: str):\n",
    "        \"\"\"\n",
    "        Adds a principle to the core principles list.\n",
    "        \n",
    "        :param principle: The principle to be added.\n",
    "        \"\"\"\n",
    "        self.core_principles.append(principle)\n",
    "        \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation of the core principles, each principle is listed on a new line with a preceding dash.\n",
    "        \n",
    "        Example:\n",
    "        - principle 1\n",
    "        - principle 2\n",
    "        ...\n",
    "        \"\"\"\n",
    "        return \"\\n\".join([f\"- {principle}\" for principle in self.core_principles])\n",
    "\n",
    "class WorkerAgent:\n",
    "    \"\"\"\n",
    "    Worker Agent class defining agents that provide feedback on prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, position: str, core_principles: CorePrinciples, llm = ChatOpenAI(temperature=1.0, model=\"gpt-4o\")):\n",
    "        self.position = position\n",
    "        self.core_principles = str(core_principles)\n",
    "        self.system_message = f\"\"\"You are an experienced: {self.position}. Your core principles are:\n",
    "{self.core_principles}\"\"\"      \n",
    "        self.llm = llm\n",
    "\n",
    "    def review_prompt(self, state: Sequence[BaseMessage], criteria: str):\n",
    "        \"\"\"\n",
    "        Generates a review of the prompt.\n",
    "        \"\"\"\n",
    "        prompt_text = f\"\"\"Your task is to provide feedback on the prompt in the conversation above in light of your core princples.\n",
    "You must think outside the box and consider unconventional ideas.\n",
    "\n",
    "The success criteria for the updated prompt are as follows:\n",
    "{criteria}\n",
    "You must use this information to inform your feedback.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the conversation carefully as an experienced {self.position}.\n",
    "2. Explain how you think the prompt can improved in light of your core principles.\n",
    "3. Submit your feedback.\n",
    "\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.system_message),\n",
    "                MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                (\"system\", prompt_text)\n",
    "            ]\n",
    "        )\n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"messages\": state})       \n",
    "        return {\"messages\": [HumanMessage(content=result.content, name=self.position)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamLeaderAgent:\n",
    "    \"\"\"\n",
    "    TeamLeaderAgent class defining an agent that manages a team of worker agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, position: str, core_principles: CorePrinciples, prompt: str, criteria: str = None, llm = ChatOpenAI(temperature=1.0, model=\"gpt-4o\"), workforce: List[WorkerAgent] = None):\n",
    "        self.position = position\n",
    "        self.core_principles = str(core_principles)\n",
    "        self.system_message = f\"\"\"You are an experienced: {self.position}. Your core principles are:\n",
    "{self.core_principles}\"\"\"\n",
    "        self.prompt = prompt\n",
    "        self.criteria = criteria\n",
    "        self.llm = llm\n",
    "        self.workforce = workforce\n",
    "        self.iterations = 0\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the agent state.\n",
    "        \"\"\"\n",
    "        self.iterations = 0\n",
    "\n",
    "    def leader_decision(self, state: Sequence[BaseMessage]):\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next team or to finish.\n",
    "        \"\"\"\n",
    "        self.iterations += 1\n",
    "        if self.iterations > 3:\n",
    "            self.reset()\n",
    "            return \"FINISH\"\n",
    "        else:\n",
    "            workers = [\"FINISH\"] + [worker.position for worker in self.workforce]\n",
    "            workers_details = [f\"{worker.position}:\\n{worker.core_principles}\" for worker in self.workforce]\n",
    "            # shuffle the options to avoid positional bias\n",
    "            random.shuffle(workers)\n",
    "            # options = [\"FINISH\"] + positions\n",
    "            function_def = {\n",
    "                \"name\": \"route\",\n",
    "                \"description\": \"Select the next role.\",\n",
    "                \"parameters\": {\n",
    "                    \"title\": \"routeSchema\",\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"next\": {\n",
    "                            \"title\": \"Next\",\n",
    "                            \"anyOf\": [\n",
    "                                {\"enum\": workers},\n",
    "                            ],\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"next\"],\n",
    "                },\n",
    "            }\n",
    "            prompt_text = f\"\"\"Your task is to select the next advisor to provide feedback on the prompt in the conversation above.\n",
    "Think carefully about which advisor will provide the most valuable feedback to make improvements.\n",
    "FINISH if you think your team can no longer provide valuable feedback.\n",
    "\n",
    "The success criteria for the updated prompt are as follows:\n",
    "{self.criteria}\n",
    "You must use this information to inform your decision.\n",
    "\n",
    "Select one of the below workers to provide feedback on how to improve the prompt or FINISH: \n",
    "{workers}\n",
    "\n",
    "The details of all workers and their core principles are as follows: \n",
    "{workers_details}\n",
    "\n",
    "Your selection process should be as follows:\n",
    "1. Read the prompt as an experienced: {self.position}. Understand its content and intent.\n",
    "2. Explicitly detail how you think the prompt can be improved or why you think the team can no longer provide valuable feedback.\n",
    "3. If improvements are needed, determine which advisor you think will provide the most valuable feedback.\n",
    "4. Submit your selection.\"\"\"\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_message),\n",
    "                    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                    (\"system\", prompt_text),\n",
    "                ]\n",
    "            )\n",
    "            chain = (\n",
    "                prompt\n",
    "                | self.llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "                | JsonOutputFunctionsParser()\n",
    "            )\n",
    "            result = chain.invoke({\"messages\": state})\n",
    "            print(result[\"next\"])\n",
    "            return result[\"next\"]\n",
    "\n",
    "    def update_prompt(self, state: Sequence[BaseMessage]):\n",
    "        \"\"\"\n",
    "        Updates the prompt with the feedback from the team agent.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(state) == 1:\n",
    "            return {\"next\": self.leader_decision(state)}\n",
    "        \n",
    "        prompt_text = f\"\"\"Your task is to improve the prompt in the conversation above in light of your core principles.\n",
    "If you recieve feedback and recommendations for the prompt, respond with a revised version of your previous attempts actioning the feedback.\n",
    "\n",
    "The success criteria for the prompt are as follows:\n",
    "{self.criteria}\n",
    "You will be penalized if the prompt does not meet this criteria.\n",
    "\n",
    "Below are strict guidelines that you MUST follow if making changes to the prompt:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces.\n",
    "- ALWAYS treat placeholders as the actual content.\n",
    "You will be penalized if you do not follow these guidelines.\n",
    "\n",
    "Your update process should be as follows:\n",
    "1. Read the prompt as an experienced: {self.position}. Understand its content and intent.\n",
    "2. Think carefully about how you can implement the most recent feedback and revise the prompt.\n",
    "3. Submit your revised prompt.\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.system_message),\n",
    "                MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                (\"system\", prompt_text),\n",
    "            ]\n",
    "        )\n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"messages\": state})\n",
    "        return {\"messages\": [HumanMessage(content=result.content, name=self.position)], \"next\": self.leader_decision(state)}\n",
    "    \n",
    "    def approval(self, state: Sequence[BaseMessage], criteria: str):\n",
    "        \"\"\"\n",
    "        Agent to approve or reject the prompt.\n",
    "        \"\"\"\n",
    "        function_def = {\n",
    "        \"name\": \"approval\",\n",
    "        \"description\": \"Submit approval decision for the prompt.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"team\": {\"type\": \"string\", \"enum\": [self.position]},\n",
    "                \"decision\": {\"type\": \"string\", \"enum\": [\"True\", \"False\"]},\n",
    "            },\n",
    "            \"required\": [\"decision\", \"team\"],\n",
    "        },\n",
    "        }\n",
    "        prompt_text = f\"\"\"Your task is to decide if the prompt in the conversation above is optimal in light of your core principles.\n",
    "\n",
    "If you think the prompt is optimal and does not require improvements in light of your core principles, return True.\n",
    "If you think the prompt needs improvements in light of your core principles, return False.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt as an experienced: {self.position}. Understand it's content and intent.\n",
    "2. Determine whether the prompt is optimal in light of your core principles.\n",
    "3. Submit your decision.\"\"\"\n",
    "        messages = [\n",
    "            (\"system\", self.system_message),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\"system\", prompt_text),\n",
    "        ]\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "        chain = (\n",
    "            prompt\n",
    "            | self.llm.bind_functions(functions=[function_def], function_call=\"approval\")\n",
    "            | JsonOutputFunctionsParser()\n",
    "        )\n",
    "        result = chain.invoke({\"messages\": state})\n",
    "        return result\n",
    "    \n",
    "    def construct_team_graph(self):\n",
    "        \"\"\"\n",
    "        Constructs a graph of team agents based on their roles and functions.\n",
    "        \"\"\"\n",
    "\n",
    "        def worker_node(state, agent):\n",
    "            return agent.review_prompt(state[\"messages\"], self.criteria)\n",
    "        \n",
    "        def leader_node(state):\n",
    "            return self.update_prompt(state[\"messages\"]) \n",
    "        \n",
    "        # The agent state is the input to each node in the graph\n",
    "        class AgentState(TypedDict):\n",
    "            messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "            next: str\n",
    "\n",
    "        workflow = StateGraph(AgentState)\n",
    "        for worker in self.workforce:\n",
    "            # Create a node for each team agent\n",
    "            node = functools.partial(worker_node, agent=worker)\n",
    "            workflow.add_node(worker.position, node)\n",
    "        workflow.add_node(self.position, leader_node)\n",
    "\n",
    "        members = [worker.position for worker in self.workforce]\n",
    "        for member in members:\n",
    "            # We want our teams to ALWAYS \"report back\" to the leader when done\n",
    "            workflow.add_edge(member, self.position)\n",
    "        # The leader populates the \"next\" field in the graph state with routes to a node or finishes\n",
    "        conditional_map = {k: k for k in members}\n",
    "        conditional_map[\"FINISH\"] = END\n",
    "        workflow.add_conditional_edges(self.position, lambda x: x[\"next\"], conditional_map)\n",
    "        workflow.set_entry_point(self.position)\n",
    "\n",
    "        memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "        graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeaderAgent:\n",
    "    \"\"\"\n",
    "    LeaderAgent class defining an agent that generates and communicates worker agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_prompt: str, criteria: str = None, llm = ChatOpenAI(temperature=1.0, model=\"gpt-4o\"), team_leaders: List[TeamLeaderAgent] = None):\n",
    "        self.base_prompt = base_prompt\n",
    "        self.system_message = f\"\"\"You are an experienced: Lead AI Prompt Engineer. Your core principles are:\n",
    "- Always pay attention to detail when designing prompts\n",
    "- Always make informed decisions when designing prompts\n",
    "- Always be critical when designing prompts\"\"\"\n",
    "        self.criteria = criteria\n",
    "        self.llm = llm\n",
    "        self.team_leaders = team_leaders\n",
    "        self.iterations = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.iterations = 0\n",
    "    \n",
    "    def run_approval(self, state: Sequence[BaseMessage]) -> List[bool]:\n",
    "        \"\"\"\n",
    "        Run the approval process for the prompt. Run concurrently\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(team.approval, state, self.criteria) for team in self.team_leaders]\n",
    "            results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "        return results\n",
    "    \n",
    "    def leader_decision(self, state: Sequence[BaseMessage]):\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next team or to finish.\n",
    "        \"\"\"\n",
    "        self.iterations += 1\n",
    "        approval_results = self.run_approval(state)\n",
    "        print(\"Approval results:\", approval_results)\n",
    "        if all(approval_result['decision'] == \"True\" for approval_result in approval_results) or self.iterations >= 4:\n",
    "            self.reset()\n",
    "            return \"FINISH\"\n",
    "        else:\n",
    "            # Only ask for advise from teams that disapproved the prompt\n",
    "            disapproved_teams = [approval_result['team'] for approval_result in approval_results if approval_result['decision'] == \"False\"]\n",
    "            disapproved_teams_details = \"\\n\".join([f\"{team.position}: {team.core_principles}\" for team in self.team_leaders if team.position in disapproved_teams])\n",
    "            # shuffle the options to avoid positional bias\n",
    "            random.shuffle(disapproved_teams)\n",
    "            # options = [\"FINISH\"] + positions\n",
    "            function_def = {\n",
    "                \"name\": \"route\",\n",
    "                \"description\": \"Select the next role.\",\n",
    "                \"parameters\": {\n",
    "                    \"title\": \"routeSchema\",\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"next\": {\n",
    "                            \"title\": \"Next\",\n",
    "                            \"anyOf\": [\n",
    "                                {\"enum\": disapproved_teams},\n",
    "                            ],\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"next\"],\n",
    "                },\n",
    "            }\n",
    "            prompt_text = f\"\"\"Your task is to choose the next team to provide feedback based on the conversation above.\n",
    "\n",
    "The success criteria for the updated prompt are as follows:\n",
    "{self.criteria}\n",
    "You must use this information to inform your decision.\n",
    "\n",
    "Select one of the below teams that disapproved of the previous prompt to provide feedback on how to improve it: \n",
    "{disapproved_teams}\n",
    "\n",
    "The details of all disapproving teams and their core principles are as follows: \n",
    "{disapproved_teams_details}\n",
    "\n",
    "Your selection process should be as follows:\n",
    "1. Review the prompt as an experienced: Lead AI Prompt Engineer. Understand it's content and intent.\n",
    "2. Explicitly detail how you think the prompt can be improved. Assume the prompt always needs improvement.\n",
    "3. Determine which advisor you think will provide the most valuable feedback.\n",
    "4. Submit your selection.\"\"\"\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_message),\n",
    "                    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                    (\"system\", prompt_text),\n",
    "                ]\n",
    "            )\n",
    "            chain = (\n",
    "                prompt\n",
    "                | self.llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "                | JsonOutputFunctionsParser()\n",
    "            )\n",
    "            result = chain.invoke({\"messages\": state})\n",
    "            # print(result[\"next\"])\n",
    "            return result[\"next\"]\n",
    "\n",
    "    def review_prompt(self, state: Sequence[BaseMessage]) -> str:\n",
    "        \"\"\"\n",
    "        Updates the prompt with the feedback from the team agent.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(state) == 1:\n",
    "            return {\"next\": self.leader_decision(state)}\n",
    "        \n",
    "        prompt_text = f\"\"\"Your task is to check the prompt in the conversation above meets the success criteria and adheres to the strict guidelines.\n",
    "If the success criteria are not met, or the strict guidlines not followed, provide a carefully revised version of the prompt.\n",
    "\n",
    "The success criteria for the prompt are as follows:\n",
    "{self.criteria}\n",
    "\n",
    "The strict guidelines for the prompt are as follows:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces. If you wish to use curly braces in your response, use double curly braces to avoid confusion with placeholders.\n",
    "- ALWAYS treat placeholders as the actual content.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Review the prompt as an experienced: Lead AI Prompt Engineer. Understand it's content and intent.\n",
    "2. Explcitly go through each success criteria and ensure the prompt meets them. If not, revise the prompt to meet them.\n",
    "3. Explicitly go through each guideline and ensure changes made adhere to them. If not, revise the prompt to adhere to them.\n",
    "4. If the prompt meets the success criteria and adheres to the strict guidelines, submit the prompt.\n",
    "\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.system_message),\n",
    "                MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                (\"system\", prompt_text),\n",
    "            ]\n",
    "        )\n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"messages\": state})\n",
    "        return {\"messages\": [AIMessage(content=result.content, name=\"Leader\")], \"next\": self.leader_decision(state)}\n",
    "\n",
    "    def construct_team_graph(self):\n",
    "        \"\"\"\n",
    "        Constructs a graph of team agents based on their roles and functions.\n",
    "        \"\"\"\n",
    "\n",
    "        # The agent state is the input to each node in the graph\n",
    "        class AgentState(TypedDict):\n",
    "            messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "            next: str\n",
    "\n",
    "        def enter_chain(message: str):\n",
    "            results = {\n",
    "                \"messages\": [HumanMessage(content=message)],\n",
    "            }\n",
    "            return results\n",
    "        \n",
    "        def get_last_message(state: AgentState) -> str:\n",
    "            return state[\"messages\"][-1].content\n",
    "\n",
    "        def join_graph(response: dict):\n",
    "            return {\"messages\": [response[\"messages\"][-1]]}\n",
    "\n",
    "        def leader_node(state):\n",
    "            return self.review_prompt(state[\"messages\"])\n",
    "\n",
    "        workflow = StateGraph(AgentState)\n",
    "        for team in self.team_leaders:\n",
    "            # Create a node for each team agent\n",
    "            graph = team.construct_team_graph()\n",
    "            chain = enter_chain | graph\n",
    "            workflow.add_node(team.position, get_last_message | chain | join_graph)\n",
    "        workflow.add_node(\"Leader\", leader_node)\n",
    "\n",
    "        members = [team.position for team in self.team_leaders]\n",
    "        for member in members:\n",
    "            # We want our teams to ALWAYS \"report back\" to the leader when done\n",
    "            workflow.add_edge(member, \"Leader\")\n",
    "        # The leader populates the \"next\" field in the graph state with routes to a node or finishes\n",
    "        conditional_map = {k: k for k in members}\n",
    "        conditional_map[\"FINISH\"] = END\n",
    "        workflow.add_conditional_edges(\"Leader\", lambda x: x[\"next\"], conditional_map)\n",
    "        workflow.set_entry_point(\"Leader\")\n",
    "\n",
    "        memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "        graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "        return graph\n",
    "    \n",
    "    def optimise_prompt(self):\n",
    "        \"\"\"\n",
    "        Optimises a prompt by invoking a graph of worker agents.\n",
    "        \"\"\"\n",
    "        # Initial state\n",
    "        initial_state = {\n",
    "            \"messages\": [HumanMessage(content=f\"{self.base_prompt}\", name=\"User\")],\n",
    "            \"prompt\": self.base_prompt,\n",
    "            \"next\": \"leader\",\n",
    "        }\n",
    "\n",
    "        # Construct the graph\n",
    "        graph = self.construct_team_graph()\n",
    "        # display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "        n = random.randint(0, 1000)\n",
    "        config = {\n",
    "            \"configurable\": {\"thread_id\": str(n)},\n",
    "            \"recursion_limit\": 50,\n",
    "            }    \n",
    "\n",
    "        # Run the graph\n",
    "        for s in graph.stream(\n",
    "            initial_state,\n",
    "            config,\n",
    "            stream_mode=\"values\",\n",
    "            ):\n",
    "            if \"__end__\" not in s:\n",
    "                # if len(s[\"messages\"]) > 1:\n",
    "                #     s[\"messages\"][-1].pretty_print()\n",
    "                continue\n",
    "\n",
    "        def message_to_dict(obj):\n",
    "            if isinstance(obj, HumanMessage) or isinstance(obj, AIMessage):\n",
    "                return {obj.name: obj.content}\n",
    "            raise TypeError(f'Object of type {obj.__class__.__name__} is not JSON serializable')\n",
    "\n",
    "        model = self.llm.model_name\n",
    "        temp = int(self.llm.temperature)\n",
    "        path = f\"/Users/iwatson/Documents/Research Project/prompt-optimisation/src/conversations/{model}/conversations_hierarchcial_{temp}.json\"\n",
    "        if not os.path.exists(path):\n",
    "            with open(path, \"w\") as f:\n",
    "                json.dump([], f)\n",
    "        \n",
    "        with open(path, \"r\") as f:\n",
    "            # write messages to json file\n",
    "            data = json.load(f)\n",
    "            # get the current key number then increment it\n",
    "            key = len(data)\n",
    "            data.append({key: json.dumps(s, default=message_to_dict)})\n",
    "            \n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "                \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatAnthropic(temperature=1.0, model=\"claude-3-5-sonnet-20240620\")\n",
    "llm = ChatOpenAI(temperature=1.0, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_suite import PromptDesignAgents, HumanEvalAgents, GSM8kAgents, SST2Agents\n",
    "\n",
    "prompt_design_agents = PromptDesignAgents()\n",
    "\n",
    "style_and_structure_expert = WorkerAgent(\"Style_and_Structure_Expert\", CorePrinciples(prompt_design_agents.get_style_and_structure_principles()), llm)\n",
    "conciseness_and_clarity_expert = WorkerAgent(\"Conciseness_and_Clarity_Expert\", CorePrinciples(prompt_design_agents.get_conciseness_and_clarity_principles()), llm)\n",
    "contextual_relevance_expert = WorkerAgent(\"Contextual_Relevance_Expert\", CorePrinciples(prompt_design_agents.get_contextual_relevance_principles()), llm)\n",
    "task_alignment_expert = WorkerAgent(\"Task_Alignment_Expert\", CorePrinciples(prompt_design_agents.get_task_alignment_principles()), llm)\n",
    "example_demonstration_expert = WorkerAgent(\"Example_Demonstration_Expert\", CorePrinciples(prompt_design_agents.get_example_demonstration_principles()), llm)\n",
    "incremental_prompting_expert = WorkerAgent(\"Incremental_Prompting_Expert\", CorePrinciples(prompt_design_agents.get_incremental_prompting_principles()), llm)\n",
    "\n",
    "human_eval_agents = HumanEvalAgents()\n",
    "\n",
    "code_reviewer = WorkerAgent(\"Code_Reviewer\", CorePrinciples(human_eval_agents.get_code_reviewer_principles()), llm)\n",
    "software_engineer = WorkerAgent(\"Software_Engineer\", CorePrinciples(human_eval_agents.get_software_engineering_principles()), llm)\n",
    "software_architect = WorkerAgent(\"Software_Architect\", CorePrinciples(human_eval_agents.get_software_architecture_principles()), llm)\n",
    "\n",
    "gsm8k_agents = GSM8kAgents()\n",
    "\n",
    "mathematician = WorkerAgent(\"Mathematician\", CorePrinciples(gsm8k_agents.get_mathematician_principles()), llm)\n",
    "word_problem_solver = WorkerAgent(\"Word_Problem_Solver\", CorePrinciples(gsm8k_agents.get_word_problem_solver_principles()), llm)\n",
    "\n",
    "sst2_agents = SST2Agents()\n",
    "\n",
    "graded_sentiment_analyst = WorkerAgent(\"Graded_Sentiment_Analyst\", CorePrinciples(sst2_agents.get_graded_sentiment_analyst_principles()), llm)\n",
    "emotive_sentiment_analyst = WorkerAgent(\"Emotive_Sentiment_Analyst\", CorePrinciples(sst2_agents.get_emotive_sentiment_analyst_principles()), llm)\n",
    "aspect_based_sentiment_analyst = WorkerAgent(\"Aspect_Based_Sentiment_Analyst\", CorePrinciples(sst2_agents.get_aspect_based_sentiment_analyst_principles()), llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams and members:\n",
      "Lead_Prompt_Writer team:\n",
      "Position: Style_and_Structure_Expert, Core Principles: \n",
      "- Always structure prompts logically for the task\n",
      "- Always use a style and tone in prompts that is appropriate for the task\n",
      "- Always assign a role to the language model that is relevant to the task\n",
      "Position: Conciseness_and_Clarity_Expert, Core Principles: \n",
      "- Always write clear and concise prompts\n",
      "- Always use simple and direct language in prompts\n",
      "- Always avoid ambiguity in prompts\n",
      "Position: Contextual_Relevance_Expert, Core Principles: \n",
      "- Always provide context to help the model understand the task\n",
      "- Always write prompts informed by the context of the task\n",
      "- Always design contextually relevant roles for the language model\n",
      "Position: Task_Alignment_Expert, Core Principles: \n",
      "- Always write prompts that align with the task criteria\n",
      "- Always tailor instructions to the task to guide the model\n",
      "- Always make the task abundantly clear to the model in the prompt\n",
      "Position: Example_Demonstration_Expert, Core Principles: \n",
      "- Always provide examples to help the model understand the task\n",
      "- Always provide examples that cover a range of complexities\n",
      "- Always demonstrate the expected output of the model\n",
      "Position: Incremental_Prompting_Expert, Core Principles: \n",
      "- Always break-down complex tasks\n",
      "- Always write clear step-by-step instructions to guide the model\n",
      "- Always write instructions appropriate for the task complexity\n",
      "----\n",
      "Lead_Sentiment_Analyst team:\n",
      "Position: Graded_Sentiment_Analyst, Core Principles: \n",
      "- Always consider the nuances of sentiment in text\n",
      "- Always consider the level of positivity or negativity in text\n",
      "- Always grade the sentiment of text before making a decision\n",
      "Position: Emotive_Sentiment_Analyst, Core Principles: \n",
      "- Always consider the emotional impact of text\n",
      "- Always consider the emotive language in text\n",
      "- Always consider lexical choices in text\n",
      "Position: Aspect_Based_Sentiment_Analyst, Core Principles: \n",
      "- Always break down the text into aspects\n",
      "- Always consider the sentiment of each aspect\n",
      "- Always consider how aspects contribute to the overall sentiment of the text\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from prompts.gpt_4o.human_eval_prompts import HumanEvalPrompts\n",
    "from prompts.gpt_4o.gsm8k_prompts import GSM8KPrompts\n",
    "from prompts.gpt_4o.sst2_prompts import SST2Prompts\n",
    "\n",
    "human_eval_prompts = HumanEvalPrompts()\n",
    "gsm8k_prompts = GSM8KPrompts()\n",
    "sst2_prompts = SST2Prompts()\n",
    "\n",
    "baseline_prompt = sst2_prompts.get_baseline_prompt()\n",
    "criteria = sst2_prompts.get_criteria()\n",
    "\n",
    "prompt_design_team = TeamLeaderAgent(\n",
    "    \"Lead_Prompt_Writer\",\n",
    "    CorePrinciples([prompt_design_agents.get_lead_prompt_writer_principles()]),\n",
    "    baseline_prompt,\n",
    "    criteria,\n",
    "    workforce=[\n",
    "        style_and_structure_expert,\n",
    "        conciseness_and_clarity_expert,\n",
    "        contextual_relevance_expert,\n",
    "        task_alignment_expert,\n",
    "        example_demonstration_expert,\n",
    "        incremental_prompting_expert,\n",
    "    ]\n",
    ")\n",
    "domain_team = TeamLeaderAgent(\n",
    "    \"Lead_Sentiment_Analyst\",\n",
    "    CorePrinciples([sst2_agents.get_lead_sentiment_analyst_principles()]),\n",
    "    baseline_prompt,\n",
    "    criteria,\n",
    "    workforce=[\n",
    "        graded_sentiment_analyst,\n",
    "        emotive_sentiment_analyst,\n",
    "        aspect_based_sentiment_analyst,\n",
    "    ]\n",
    ")\n",
    "\n",
    "leader_agent = LeaderAgent(\n",
    "    base_prompt=baseline_prompt,\n",
    "    criteria=criteria,\n",
    "    team_leaders=[prompt_design_team, domain_team]\n",
    ")\n",
    "\n",
    "# leader_agent.generate_teams()\n",
    "# print teams and members\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent.team_leaders:\n",
    "    print(f\"{team_leader.position} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Core Principles: \\n{worker.core_principles}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approval results: [{'team': 'Lead_Prompt_Writer', 'decision': 'True'}, {'team': 'Lead_Sentiment_Analyst', 'decision': 'False'}]\n",
      "Graded_Sentiment_Analyst\n",
      "Emotive_Sentiment_Analyst\n",
      "Aspect_Based_Sentiment_Analyst\n",
      "Approval results: [{'team': 'Lead_Prompt_Writer', 'decision': 'False'}, {'team': 'Lead_Sentiment_Analyst', 'decision': 'True'}]\n",
      "Conciseness_and_Clarity_Expert\n",
      "Task_Alignment_Expert\n",
      "Contextual_Relevance_Expert\n",
      "Approval results: [{'team': 'Lead_Sentiment_Analyst', 'decision': 'True'}, {'team': 'Lead_Prompt_Writer', 'decision': 'True'}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Leader\n",
      "\n",
      "**Refined Prompt Incorporating All Feedback:**\n",
      "\n",
      "\"Classify the sentiment of the following text as either positive or negative, paying attention to emotive language and the overall emotional tone. Output your answer clearly as ##positive or ##negative without any spaces.\n",
      "\n",
      "{content}\"\n",
      "\n",
      "**Review of Success Criteria:**\n",
      "\n",
      "1. The prompt MUST instruct the LLM to classify the text as either positive or negative sentiment.\n",
      "   - ✔️ The prompt does this effectively.\n",
      "\n",
      "2. The prompt MUST include the content placeholder.\n",
      "   - ✔️ The prompt includes the {content} placeholder.\n",
      "\n",
      "3. The prompt MUST instruct the model to output the answer at the end as ##positive or ##negative with no spaces.\n",
      "   - ✔️ The prompt specifies this output format explicitly.\n",
      "\n",
      "**Review of Strict Guidelines:**\n",
      "\n",
      "1. DO NOT modify existing restrictions.\n",
      "   - ✔️ No existing restrictions were modified.\n",
      "\n",
      "2. DO NOT modify or remove negations.\n",
      "   - ✔️ No negations were modified or removed.\n",
      "\n",
      "3. DO NOT add, modify or remove placeholders denoted by curly braces.\n",
      "   - ✔️ The placeholder {content} was preserved and not modified.\n",
      "\n",
      "4. ALWAYS treat placeholders as the actual content.\n",
      "   - ✔️ The placeholders were treated as the actual content.\n",
      "\n",
      "**Final Decision:**\n",
      "\n",
      "The refined prompt meets all the success criteria and adheres to the strict guidelines. Therefore, the refined prompt is appropriate for submission.\n",
      "\n",
      "**Final Prompt:**\n",
      "\n",
      "\"Classify the sentiment of the following text as either positive or negative, paying attention to emotive language and the overall emotional tone. Output your answer clearly as ##positive or ##negative without any spaces.\n",
      "\n",
      "{content}\"\n",
      "--------------------\n",
      "Approval results: [{'team': 'Lead_Sentiment_Analyst', 'decision': 'True'}, {'team': 'Lead_Prompt_Writer', 'decision': 'True'}]\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: User\n",
      "\n",
      "Classify the sentiment of the following text as either positive or negative: {content}\n",
      "Please output your answer at the end as ##<your answer (No format restrictions)>\n",
      "--------------------\n",
      "Approval results: [{'team': 'Lead_Sentiment_Analyst', 'decision': 'False'}, {'team': 'Lead_Prompt_Writer', 'decision': 'True'}]\n",
      "Aspect_Based_Sentiment_Analyst\n",
      "Graded_Sentiment_Analyst\n",
      "Emotive_Sentiment_Analyst\n",
      "Approval results: [{'team': 'Lead_Sentiment_Analyst', 'decision': 'True'}, {'team': 'Lead_Prompt_Writer', 'decision': 'True'}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Leader\n",
      "\n",
      "The original revised prompt meets the success criteria as follows:\n",
      "- It instructs the LLM to classify the text as either positive or negative sentiment.\n",
      "- It includes the content placeholder.\n",
      "- It instructs the model to output the answer at the end as `##positive` or `##negative` with no spaces.\n",
      "\n",
      "Additionally, it adheres to the strict guidelines:\n",
      "- It does not modify existing restrictions.\n",
      "- It does not modify or remove negations.\n",
      "- It does not add, modify, or remove placeholders denoted by curly braces.\n",
      "- It treats placeholders as the actual content.\n",
      "\n",
      "Hence, the prompt meets all the success criteria and adheres to the strict guidelines.\n",
      "\n",
      "### Accepted Prompt:\n",
      "\n",
      "```\n",
      "Please classify the sentiment of the following text as either positive or negative by breaking it down into aspects. Identify key aspects within the text, assess the sentiment of each aspect considering the emotional impact, emotive language, and lexical choices, and then determine the overall sentiment based on how these aspects contribute to the general tone. Here is an example of breaking down into aspects, evaluating emotional impact, and assessing:\n",
      "\n",
      "Example:\n",
      "Text: \"The device has an excellent display, but the battery life is disappointing.\"\n",
      "- Aspect 1: Display - Sentiment: Positive (excellent), Emotional Impact: High Positive\n",
      "- Aspect 2: Battery life - Sentiment: Negative (disappointing), Emotional Impact: High Negative\n",
      "\n",
      "Overall Sentiment: Negative (due to the significant negative impact of battery life on user experience)\n",
      "\n",
      "Output your answer at the end as ##positive or ##negative with no spaces.\n",
      "\n",
      "{content}\n",
      "```\n",
      "--------------------\n",
      "Approval results: [{'team': 'Lead_Sentiment_Analyst', 'decision': 'False'}, {'team': 'Lead_Prompt_Writer', 'decision': 'True'}]\n",
      "Graded_Sentiment_Analyst\n",
      "Emotive_Sentiment_Analyst\n",
      "Aspect_Based_Sentiment_Analyst\n",
      "Approval results: [{'team': 'Lead_Prompt_Writer', 'decision': 'True'}, {'team': 'Lead_Sentiment_Analyst', 'decision': 'True'}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Leader\n",
      "\n",
      "### Review Process:\n",
      "\n",
      "1. **Reviewing the Original Prompt:**\n",
      "   - The initial prompt aims to classify the sentiment of given text as either positive or negative.\n",
      "   - The content placeholder `{content}` is included.\n",
      "   - The output format specified is \"##positive\" or \"##negative\" with no spaces.\n",
      "\n",
      "2. **Checking Success Criteria:**\n",
      "   - The prompt does instruct the LLM to classify the text as positive or negative: Yes.\n",
      "   - The prompt includes the content placeholder: Yes.\n",
      "   - The prompt instructs the model to output the answer at the end as required: Yes.\n",
      "\n",
      "3. **Checking Strict Guidelines:**\n",
      "   - No existing restrictions were modified: Correct.\n",
      "   - No negations were modified or removed: Correct.\n",
      "   - Placeholders have not been modified or removed: Correct.\n",
      "   - Placeholders are treated as actual content: Correct.\n",
      "\n",
      "Since the prompt meets both the success criteria and strict guidelines, it is correctly designed. There is no need for revisions. \n",
      "\n",
      "### Final Prompt:\n",
      "\n",
      "\"Carefully analyze the given text for sentiment. Break the text down into specific aspects or topics, and consider the sentiment of each identified aspect. Pay attention to how these sentiments interact and contribute to the overall sentiment. Consider nuances of emotions, emotional intensity, lexical choices, and emotive language markers, such as adjectives, adverbs, punctuation (e.g., exclamation points, ellipses), and capitalization. Classify the sentiment of the overall text as either positive or negative:\n",
      "\n",
      "{content}\n",
      "\n",
      "Please output your answer at the end as ##positive or ##negative with no spaces.\"\n",
      "--------------------\n",
      "Approval results: [{'team': 'Lead_Prompt_Writer', 'decision': 'True'}, {'team': 'Lead_Sentiment_Analyst', 'decision': 'False'}]\n",
      "Graded_Sentiment_Analyst\n",
      "Emotive_Sentiment_Analyst\n",
      "Aspect_Based_Sentiment_Analyst\n",
      "Approval results: [{'team': 'Lead_Prompt_Writer', 'decision': 'False'}, {'team': 'Lead_Sentiment_Analyst', 'decision': 'False'}]\n",
      "Conciseness_and_Clarity_Expert\n",
      "Task_Alignment_Expert\n",
      "FINISH\n",
      "Approval results: [{'team': 'Lead_Sentiment_Analyst', 'decision': 'True'}, {'team': 'Lead_Prompt_Writer', 'decision': 'True'}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Leader\n",
      "\n",
      "### Prompt Review\n",
      "\n",
      "#### Analysis of the Prompt:\n",
      "\n",
      "> Classify the sentiment of the following text as either positive or negative:\n",
      "> \n",
      "> {content}\n",
      "> \n",
      "> Output the sentiment classification as ##positive or ##negative with no spaces.\n",
      "\n",
      "#### Success Criteria:\n",
      "\n",
      "1. **Classify the Text as Positive or Negative Sentiment:**\n",
      "   - The prompt instructs to classify the mood as \"positive or negative\", meeting this criterion.\n",
      "\n",
      "2. **Include Content Placeholder:**\n",
      "   - The prompt includes the placeholder `{content}`, meeting this criterion.\n",
      "\n",
      "3. **Output Answer as ##positive or ##negative with No Spaces:**\n",
      "   - The prompt clearly instructs to output the answer as \"##positive\" or \"##negative\" with no spaces, meeting this criterion.\n",
      "\n",
      "#### Strict Guidelines:\n",
      "\n",
      "1. **Do Not Modify Existing Restrictions:**\n",
      "   - No existing restrictions are modified.\n",
      "\n",
      "2. **Do Not Modify or Remove Negations:**\n",
      "   - No negations are modified or removed.\n",
      "\n",
      "3. **Do Not Add, Modify, or Remove Placeholders:**\n",
      "   - The placeholder `{content}` is intact and correctly used.\n",
      "\n",
      "4. **Always Treat Placeholders as Actual Content:**\n",
      "   - The placeholder is treated as the input for text classification appropriately.\n",
      "\n",
      "### Conclusion:\n",
      "\n",
      "The prompt meets all the outlined success criteria and adheres to all the strict guidelines. Therefore, it is ready for submission without any further revision.\n",
      "\n",
      "### Final Prompt:\n",
      "\n",
      "> Classify the sentiment of the following text as either positive or negative:\n",
      "> \n",
      "> {content}\n",
      "> \n",
      "> Output the sentiment classification as ##positive or ##negative with no spaces.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "times = []\n",
    "for _ in range(5):\n",
    "    start = time.time()\n",
    "    result = leader_agent.optimise_prompt()\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "    result[\"messages\"][-1].pretty_print()\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max time:  116.14983415603638\n",
      "Min time:  0.7951781749725342\n",
      "Average time:  63.57585287094116\n"
     ]
    }
   ],
   "source": [
    "print(\"Max time: \", max(times))\n",
    "print(\"Min time: \", min(times))\n",
    "print(\"Average time: \", sum(times) / len(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

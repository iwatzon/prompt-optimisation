{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authoritarian Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.prompts.chat import SystemMessage, _convert_to_message\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "from langgraph.graph import END, StateGraph, MessageGraph\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import List, Sequence, TypedDict, Annotated\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = \"Authoritarian Optimisation\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import Client\n",
    "\n",
    "# client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorePrinciples:\n",
    "    def __init__(self, core_principles: List[str]):\n",
    "        self.core_principles = core_principles\n",
    "    \n",
    "    def add_principle(self, principle: str):\n",
    "        \"\"\"\n",
    "        Adds a principle to the core principles list.\n",
    "        \n",
    "        :param principle: The principle to be added.\n",
    "        \"\"\"\n",
    "        self.core_principles.append(principle)\n",
    "        \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation of the core principles, each principle is listed on a new line with a preceding dash.\n",
    "        \n",
    "        Example:\n",
    "        - principle 1\n",
    "        - principle 2\n",
    "        ...\n",
    "        \"\"\"\n",
    "        return \"\\n\".join([f\"- {principle}\" for principle in self.core_principles])\n",
    "\n",
    "\n",
    "class AdvisorAgent:\n",
    "    \"\"\"\n",
    "    Advisor Agent class defining agents that provide feedback on prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, position: str, core_principles: CorePrinciples, llm = ChatOpenAI(temperature=1.0, model=\"gpt-4o\")):\n",
    "        self.position = position\n",
    "        self.core_principles = str(core_principles)\n",
    "        self.system_message = f\"\"\"You are an experienced: {self.position}. Your core principles are:\n",
    "{self.core_principles}\"\"\"\n",
    "        self.llm = llm\n",
    "\n",
    "    def review_prompt(self, state: Sequence[BaseMessage], criteria: str):\n",
    "        \"\"\"\n",
    "        Generates a review of the prompt.\n",
    "        \"\"\"\n",
    "        prompt_text = f\"\"\"Your task is to review the conversation above and think outside the box to provide feedback on the prompt.\n",
    "Offer creative recommendations on how to improve it in light of your core principles.\n",
    "Your feedback must be less than 100 words so think carefully about the most critical aspects of the prompt that need improvement.\n",
    "\n",
    "The success criteria for the updated prompt are as follows:\n",
    "{criteria}\n",
    "You must use this information to inform your feedback.\n",
    "\n",
    "Below are strict guidelines that MUST be followed if making changes to the prompt:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces.\n",
    "- ALWAYS treat placeholders as the actual content.\n",
    "Check that that the prompt adheres to these guidelines.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the conversation carefully as an expert {self.position}.\n",
    "2. Explcitly go through each success criteria and ensure the prompt meets them. If not, mention the criteria that was not met in your feedback.\n",
    "3. Explicitly go through each guideline and ensure the changes adhere to them. If not, mention the guideline that was not followed in your feedback.\n",
    "4. Explicitly list the creative recommendations you have for improving the most critical aspects of the prompt.\n",
    "5. Submit your feedback.\n",
    "\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", prompt_text),\n",
    "                MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                # MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "            ]\n",
    "        )\n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"messages\": state})       \n",
    "        return {\"messages\": [HumanMessage(content=result.content, name=self.position)]}\n",
    "        \n",
    "    def approval(self, state: Sequence[BaseMessage], criteria: str):\n",
    "        \"\"\"\n",
    "        Agent to approve or reject the prompt.\n",
    "        \"\"\"\n",
    "        function_def = {\n",
    "        \"name\": \"approval\",\n",
    "        \"description\": \"Submit approval decision for the prompt.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"advisor\": {\"type\": \"string\", \"enum\": [self.position]},\n",
    "                \"decision\": {\"type\": \"string\", \"enum\": [\"True\", \"False\"]},\n",
    "            },\n",
    "            \"required\": [\"decision\", \"advisor_position\"],\n",
    "        },\n",
    "        }\n",
    "        prompt_text = f\"\"\"Your task is to review the conversation above and decide if the prompt is optimal in light of your core principles and the success criteria.\n",
    "\n",
    "The success criteria for the prompt are as follows:\n",
    "{criteria}\n",
    "You must use this information to inform your decision.\n",
    "\n",
    "If you think the prompt sufficiently meets the success criteria, return True. \n",
    "If you think the prompt needs improvements in light of your core principles to better meet the success criteria, return False.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt carefully as an expert {self.position}.\n",
    "2. Determine whether the prompt needs improvement or meets the success criteria.\n",
    "3. Submit your decision.\n",
    "\"\"\"\n",
    "        messages = [\n",
    "            (\"system\", self.system_message),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\"system\", prompt_text),\n",
    "        ]\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "        chain = (\n",
    "            prompt\n",
    "            | self.llm.bind_functions(functions=[function_def], function_call=\"approval\")\n",
    "            | JsonOutputFunctionsParser()\n",
    "        )\n",
    "        result = chain.invoke({\"messages\": state})\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeaderAgent:\n",
    "    \"\"\"\n",
    "    LeaderAgent class defining an agent that generates and communicates with advisor agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_prompt: str, criteria: str = None, advisors: List[AdvisorAgent] = None, llm = ChatOpenAI(temperature=1.0, model=\"gpt-4o\")):\n",
    "        self.base_prompt = base_prompt\n",
    "        self.criteria = criteria\n",
    "        self.system_message = f\"\"\"You are an experienced: Head AI Prompt Engineer. Your core principles are:\n",
    "- Always pay attention to detail in prompts\n",
    "- Always be critical of prompts\n",
    "- Always make informed decisions with regards to prompts\"\"\"\n",
    "        self.llm = llm\n",
    "        self.advisors = advisors\n",
    "        self.iterations = 0\n",
    "    \n",
    "    def run_approval(self, state: Sequence[BaseMessage]) -> List[bool]:\n",
    "        \"\"\"\n",
    "        Run the approval process for the prompt. Run concurrently\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(advisor.approval, state, self.criteria) for advisor in self.advisors]\n",
    "            results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "        return results\n",
    "    \n",
    "    def leader_decision(self, state: Sequence[BaseMessage]):\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next advisor or to finish.\n",
    "        \"\"\"\n",
    "        self.iterations += 1\n",
    "        approval_results = self.run_approval(state)\n",
    "        print(\"Approval results:\", approval_results)\n",
    "        # Extract decisions from the results\n",
    "        approval_results = [result[\"decision\"] == \"True\" for result in approval_results]\n",
    "        if all(approval_results) or self.iterations > 10:\n",
    "            return \"FINISH\"\n",
    "        else:\n",
    "            # Only ask for advise from advisors that disapproved the prompt\n",
    "            disapproved_advisors = [advisor for advisor, result in zip(self.advisors, approval_results) if not result]\n",
    "            disapproved_advisors_details = [f\"{advisor.position}:\\n{advisor.core_principles}\\n\\n\" for advisor in self.advisors]\n",
    "            options = [advisor.position for advisor in disapproved_advisors]\n",
    "            # shuffle the options to avoid positional bias\n",
    "            random.shuffle(options)\n",
    "            # options = [\"FINISH\"] + positions\n",
    "            function_def = {\n",
    "                \"name\": \"route\",\n",
    "                \"description\": \"Select the next role.\",\n",
    "                \"parameters\": {\n",
    "                    \"title\": \"routeSchema\",\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"next\": {\n",
    "                            \"title\": \"Next\",\n",
    "                            \"anyOf\": [\n",
    "                                {\"enum\": options},\n",
    "                            ],\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"next\"],\n",
    "                },\n",
    "            }\n",
    "            prompt_text = f\"\"\"Your task is to review the conversation above and decide the next advisor to provide feedback.\n",
    "\n",
    "The success criteria for the updated prompt are as follows:\n",
    "{self.criteria}\n",
    "You must use this information to inform your decision.\n",
    "\n",
    "The details of all advisors are their core principles are as follows: \n",
    "{disapproved_advisors_details}\n",
    "\n",
    "Select one of the below advisors that disapproved the prompt to provide feedback on how to improve it: \n",
    "{options}\n",
    "\n",
    "Think carefully about which aspects of the prompt need improvement and which advisor would be best suited to provide feedback on those aspects.\n",
    "If you think multiple aspects of the prompt need improvement, select the most suitable advisor to provide feedback on the most critical aspect of the prompt.\n",
    "\"\"\"\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_message),\n",
    "                    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                    (\"system\", prompt_text),\n",
    "                ]\n",
    "            )\n",
    "            chain = (\n",
    "                prompt\n",
    "                | self.llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "                | JsonOutputFunctionsParser()\n",
    "            )\n",
    "            result = chain.invoke({\"messages\": state})\n",
    "            print(result[\"next\"])\n",
    "            return result[\"next\"]\n",
    "\n",
    "    def update_prompt(self, state: Sequence[BaseMessage]) -> str:\n",
    "        \"\"\"\n",
    "        Updates the prompt with the feedback from the advisor agent.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(state) == 1:\n",
    "            return {\"next\": self.leader_decision(state)}\n",
    "        \n",
    "        prompt_text = f\"\"\"Your task is to review the conversation above and improve the prompt in light of your core principles.\n",
    "If you recieve feedback and recommendations for the prompt, respond with a revised version of your previous attempts actioning the feedback.\n",
    "\n",
    "The success criteria for the prompt are as follows:\n",
    "{self.criteria}\n",
    "You will be penalized if the prompt does not meet this criteria.\n",
    "\n",
    "Below are strict guidelines that you MUST follow if making changes to the prompt:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces.\n",
    "- ALWAYS treat placeholders as the actual content.\n",
    "You will be penalized if you do not follow these guidelines.\n",
    "\n",
    "Your update process should be as follows:\n",
    "1. Review the conversation carefully as an expert Head AI Engineer.\n",
    "2. Think carefully about how you can implement the user's feedback.\n",
    "3. Implement the feedback in a revised version of the prompt.\n",
    "4. Explcitly go through each success criteria and ensure your revised prompt meets them. If not, repeat from step 2.\n",
    "5. Explicitly go through each guideline and ensure your changes adhere to them. If not, repeat from step 2.\n",
    "6. Submit your revised prompt.\n",
    "\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.system_message),\n",
    "                MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                (\"system\", prompt_text),\n",
    "            ]\n",
    "        )\n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"messages\": state})\n",
    "        return {\"messages\": [AIMessage(content=result.content, name=\"Leader\")], \"next\": self.leader_decision(state)}\n",
    "\n",
    "    def construct_advisor_graph(self):\n",
    "        \"\"\"\n",
    "        Constructs a graph of advisor agents based on their roles and functions.\n",
    "        \"\"\"\n",
    "\n",
    "        def advisor_node(state, agent):\n",
    "            return agent.review_prompt(state[\"messages\"], self.criteria)\n",
    "        \n",
    "        def leader_node(state):\n",
    "            return self.update_prompt(state[\"messages\"]) \n",
    "        \n",
    "        # The agent state is the input to each node in the graph\n",
    "        class AgentState(TypedDict):\n",
    "            messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "            next: str\n",
    "\n",
    "        workflow = StateGraph(AgentState)\n",
    "        for advisor in self.advisors:\n",
    "            # Create a node for each advisor agent\n",
    "            node = functools.partial(advisor_node, agent=advisor)\n",
    "            workflow.add_node(advisor.position, node)\n",
    "        workflow.add_node(\"Leader\", leader_node)\n",
    "\n",
    "        members = [advisor.position for advisor in self.advisors]\n",
    "        for member in members:\n",
    "            # We want our advisors to ALWAYS \"report back\" to the leader when done\n",
    "            workflow.add_edge(member, \"Leader\")\n",
    "        # The leader populates the \"next\" field in the graph state with routes to a node or finishes\n",
    "        conditional_map = {k: k for k in members}\n",
    "        conditional_map[\"FINISH\"] = END\n",
    "        workflow.add_conditional_edges(\"Leader\", lambda x: x[\"next\"], conditional_map)\n",
    "        workflow.set_entry_point(\"Leader\")\n",
    "\n",
    "        memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "        graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "        return graph\n",
    "    \n",
    "    def optimise_prompt(self):\n",
    "        \"\"\"\n",
    "        Optimises a prompt by invoking a graph of advisor agents.\n",
    "        \"\"\"\n",
    "        # Initial state\n",
    "        initial_state = {\n",
    "            \"messages\": [HumanMessage(content=self.base_prompt, name=\"User\")],\n",
    "        }\n",
    "\n",
    "        # Construct the graph\n",
    "        graph = self.construct_advisor_graph()\n",
    "        # display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "        n = random.randint(0, 1000)\n",
    "        config = {\n",
    "            \"configurable\": {\"thread_id\": n},\n",
    "            \"recursion_limit\": 50,\n",
    "            }    \n",
    "\n",
    "        # Run the graph\n",
    "        for s in graph.stream(\n",
    "            initial_state,\n",
    "            config,\n",
    "            stream_mode=\"values\",\n",
    "            ):\n",
    "            if \"__end__\" not in s:\n",
    "                if len(s[\"messages\"]) > 1:\n",
    "                    s[\"messages\"][-1].pretty_print()\n",
    "                continue\n",
    "        \n",
    "        # if not os.path.exists(\"prompt_history_authoritarian.json\"):\n",
    "        #     with open(\"prompt_history_authoritarian.json\", \"w\") as f:\n",
    "        #         json.dump([], f)\n",
    "        \n",
    "        # with open(\"prompt_history_authoritarian.json\", \"r\") as f:\n",
    "        #     data = json.load(f)\n",
    "        #     data.append(s)\n",
    "            \n",
    "        # with open(\"prompt_history_authoritarian.json\", \"w\") as f:\n",
    "        #     json.dump(data, f, indent=4)\n",
    "\n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatAnthropic(temperature=1.0, model=\"claude-3-haiku-20240307\")\n",
    "llm = ChatOpenAI(temperature=1.0, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt design team members\n",
    "style_and_structure_principles = CorePrinciples([\n",
    "    \"Always structure prompts logically for the task\",\n",
    "    \"Always use a style and tone in prompts that is appropriate for the task\",\n",
    "    \"Always design prompts appropriately for the task's complexity\",\n",
    "])\n",
    "style_and_structure_expert = AdvisorAgent(\"Style_and_Structure_Expert\", style_and_structure_principles, llm)\n",
    "\n",
    "conciseness_and_clarity_principles = CorePrinciples([\n",
    "    \"Always write clear and concise prompts\",\n",
    "    \"Always use simple and direct language in prompts\",\n",
    "    \"Always avoid ambiguity in prompts\",\n",
    "])\n",
    "conciseness_and_clarity_expert = AdvisorAgent(\"Conciseness_and_Clarity_Expert\", conciseness_and_clarity_principles, llm)\n",
    "\n",
    "contextual_relevance_principles = CorePrinciples([\n",
    "    \"Always provide context to help the model understand the task\",\n",
    "    \"Always write prompts informed by the context of the task\",\n",
    "    \"Always design contextually relevant personas and roles in prompts\",\n",
    "])\n",
    "contextual_relevance_expert = AdvisorAgent(\"Contextual_Relevance_Expert\", contextual_relevance_principles, llm)\n",
    "\n",
    "task_alignment_principles = CorePrinciples([\n",
    "    \"Always write prompts that align with the task criteria\",\n",
    "    \"Always tailor instructions to the task to guide the model\",\n",
    "    \"Always make the task abundantly clear to the model in the prompt\"\n",
    "])\n",
    "task_alignment_expert = AdvisorAgent(\"Task_Alignment_Expert\", task_alignment_principles, llm)\n",
    "\n",
    "example_demonstration_principal = CorePrinciples([\n",
    "    \"Always provide examples to help the model understand the task\",\n",
    "    \"Always provide examples that cover a range of complexities\",\n",
    "    \"Always demonstrate the expected output of the model\",\n",
    "])\n",
    "example_demonstration_expert = AdvisorAgent(\"Example_Demonstration_Expert\", example_demonstration_principal, llm)\n",
    "\n",
    "avoiding_bias_principles = CorePrinciples([\n",
    "    \"Always avoid bias in prompts\",\n",
    "    \"Always consider the ethical implications of prompts\",\n",
    "])\n",
    "avoiding_bias_expert = AdvisorAgent(\"Avoiding_Bias_Expert\", avoiding_bias_principles)\n",
    "\n",
    "incremental_prompting_principles = CorePrinciples([\n",
    "    \"Always write clear step-by-step instructions to guide the model\",\n",
    "    \"Always write instructions tailored to an AI model's learning process\",\n",
    "    \"Always write instructions appropriate for the task complexity\",\n",
    "])\n",
    "incremental_prompting_expert = AdvisorAgent(\"Incremental_Prompting_Expert\", incremental_prompting_principles, llm)\n",
    "\n",
    "programming_logic_principles = CorePrinciples([\n",
    "    \"Always write pormpts following programming logic principles (loops, conditionals, functions, pseudo-code, etc.)\",\n",
    "    \"Always structure prompts as if you were writing code\",\n",
    "    \"Always leave comments in plain english to explain programming logic\",\n",
    "])\n",
    "programming_logic_expert = AdvisorAgent(\"Programming_Logic_Expert\", programming_logic_principles, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain team members\n",
    "mathematics_principles = CorePrinciples([\n",
    "    \"Always stop to think and develop a mathetcically sound plan to solve problems\",\n",
    "    \"Always make an initial estimate of the answer before solving the problem\",\n",
    "    \"Always use mathetical operators (addition, subtraction, multiplication, division) correctly\",\n",
    "    \"Always double-check mathematical calculations\",\n",
    "])\n",
    "mathematician = AdvisorAgent(\"Mathematician\", mathematics_principles, llm)\n",
    "\n",
    "word_problem_solving_principles = CorePrinciples([\n",
    "    \"Always read the problem slowly and carefully to identify what the problem is asking you to find\",\n",
    "    \"Always list the given facts and unknown facts\",\n",
    "    \"Always rewrite the problem and facts in a more organized manner\",\n",
    "    \"Always consider multiple approaches to solving problems\",\n",
    "])\n",
    "word_problem_solver = AdvisorAgent(\"Word_Problem_Solver\", word_problem_solving_principles, llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position:  Style_and_Structure_Expert\n",
      "Core Principles:\n",
      " - Always structure prompts logically for the task\n",
      "- Always use a style and tone in prompts that is appropriate for the task\n",
      "- Always design prompts appropriately for the task's complexity\n",
      "Position:  Conciseness_and_Clarity_Expert\n",
      "Core Principles:\n",
      " - Always write clear and concise prompts\n",
      "- Always use simple and direct language in prompts\n",
      "- Always avoid ambiguity in prompts\n",
      "Position:  Contextual_Relevance_Expert\n",
      "Core Principles:\n",
      " - Always provide context to help the model understand the task\n",
      "- Always write prompts informed by the context of the task\n",
      "- Always design contextually relevant personas and roles in prompts\n",
      "Position:  Task_Alignment_Expert\n",
      "Core Principles:\n",
      " - Always write prompts that align with the task criteria\n",
      "- Always tailor instructions to the task to guide the model\n",
      "- Always make the task abundantly clear to the model in the prompt\n",
      "Position:  Example_Demonstration_Expert\n",
      "Core Principles:\n",
      " - Always provide examples to help the model understand the task\n",
      "- Always provide examples that cover a range of complexities\n",
      "- Always demonstrate the expected output of the model\n",
      "Position:  Incremental_Prompting_Expert\n",
      "Core Principles:\n",
      " - Always write clear step-by-step instructions to guide the model\n",
      "- Always write instructions tailored to an AI model's learning process\n",
      "- Always write instructions appropriate for the task complexity\n",
      "Position:  Word_Problem_Solver\n",
      "Core Principles:\n",
      " - Always read the problem slowly and carefully to identify what the problem is asking you to find\n",
      "- Always list the given facts and unknown facts\n",
      "- Always rewrite the problem and facts in a more organized manner\n",
      "- Always consider multiple approaches to solving problems\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"{content}\\nPlease output your answer at the end as ##<your answer (among A through C)>.\"\n",
    "criteria = \"\"\"- The prompt MUST instruct the LLM to solve the object tracking problem.\n",
    "- The prompt MUST include the content placeholder (this is where the object tracking problem will be).\n",
    "- The prompt MUST instruct the LLM to provide the answer at the end of the output exactly as ##<answer (among A through C)>.\n",
    "- The prompt MUST instruct the LLM to provide the answer with no spaces between the ## and the answer.\"\"\"\n",
    "\n",
    "leader_agent = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    criteria=criteria,\n",
    "    advisors=[\n",
    "        style_and_structure_expert,\n",
    "        conciseness_and_clarity_expert,\n",
    "        contextual_relevance_expert,\n",
    "        task_alignment_expert,\n",
    "        example_demonstration_expert,\n",
    "        incremental_prompting_expert,\n",
    "        # mathematician,\n",
    "        word_problem_solver,\n",
    "    ],\n",
    "    llm = llm\n",
    ")\n",
    "for advisor in leader_agent.advisors:\n",
    "    print(\"Position: \", advisor.position + \"\\nCore Principles:\\n\", advisor.core_principles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approval results: [{'advisor': 'Example_Demonstration_Expert', 'decision': 'True'}, {'advisor': 'Task_Alignment_Expert', 'decision': 'True'}, {'advisor': 'Conciseness_and_Clarity_Expert', 'decision': 'True'}, {'advisor': 'Contextual_Relevance_Expert', 'decision': 'False'}, {'advisor': 'Word_Problem_Solver', 'decision': 'True'}, {'advisor': 'Style_and_Structure_Expert', 'decision': 'True'}, {'advisor': 'Incremental_Prompting_Expert', 'decision': 'True'}]\n",
      "Task_Alignment_Expert\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Task_Alignment_Expert\n",
      "\n",
      "1. Success Criteria Check:\n",
      "   The current prompt does not meet all the success criteria:\n",
      "   - It does not explicitly instruct the LLM to solve the object tracking problem.\n",
      "\n",
      "2. Guidelines Check:\n",
      "   - It adheres to the guidelines by keeping the placeholder and required formatting instructions intact.\n",
      "\n",
      "3. Creative Recommendations for Improvement:\n",
      "   - Clearly instruct the LLM to solve the object tracking problem by stating: \"Please solve the following object tracking problem and output your answer at the end as ##<your answer (among A through C)>.\"\n",
      "   - Ensure clarity by stating the type of problem to avoid ambiguity. \n",
      "\n",
      "Feedback:\n",
      "The prompt should clearly instruct the LLM to solve the object tracking problem. Adding specific instructions to address the problem directly will enhance clarity and adherence to the task's requirements.\n",
      "Approval results: [{'advisor': 'Style_and_Structure_Expert', 'decision': 'False'}, {'advisor': 'Example_Demonstration_Expert', 'decision': 'False'}, {'advisor': 'Task_Alignment_Expert', 'decision': 'False'}, {'advisor': 'Incremental_Prompting_Expert', 'decision': 'False'}, {'advisor': 'Contextual_Relevance_Expert', 'decision': 'False'}, {'advisor': 'Word_Problem_Solver', 'decision': 'False'}, {'advisor': 'Conciseness_and_Clarity_Expert', 'decision': 'False'}]\n",
      "Conciseness_and_Clarity_Expert\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Leader\n",
      "\n",
      "**Review:** \n",
      "1. **Success Criteria Not Met:**\n",
      "   - The original prompt doesn't properly instruct the LLM to solve the object tracking problem. \n",
      "2. **Adherence to Guidelines:**\n",
      "   - Placeholder and formatting are intact.\n",
      "3. **Feedback:**\n",
      "   - It needs specific instructions for solving the object tracking problem.\n",
      "   \n",
      "**Revised Prompt:**\n",
      "\n",
      "```plaintext\n",
      "Please solve the following object tracking problem and output your answer at the end as ##<your answer (among A through C)> with no spaces between the ## and the answer. {content}\n",
      "```\n",
      "\n",
      "**Check Against Success Criteria:**\n",
      "1. **Instructs the LLM to solve the object tracking problem:**\n",
      "   - Yes, it says \"Please solve the following object tracking problem...\"\n",
      "2. **Includes the content placeholder:**\n",
      "   - Yes, it retains `{content}`.\n",
      "3. **Instructs the LLM to provide the answer in the required format:**\n",
      "   - Yes, instructs to output as \"##<your answer (among A through C)>...\"\n",
      "4. **Instructs LLM to provide the answer with no spaces between ## and the answer:**\n",
      "   - Yes, it includes \"with no spaces between the ## and the answer.\"\n",
      "   \n",
      "**Check Against Guidelines:**\n",
      "1. **Did not modify existing restrictions:**\n",
      "   - Correct, no changes to restrictions.\n",
      "2. **Did not modify or add negations:**\n",
      "   - Correct, no changes to negations.\n",
      "3. **Did not modify or remove placeholders:**\n",
      "   - Correct, `{content}` is intact.\n",
      "4. **Treated placeholders as actual content:**\n",
      "   - Correct, treated placeholders as required.\n",
      "\n",
      "**Submission:** \n",
      "The prompt now meets all success criteria and adheres to the provided guidelines.\n",
      "\n",
      "**Final Revised Prompt:**\n",
      "\n",
      "```plaintext\n",
      "Please solve the following object tracking problem and output your answer at the end as ##<your answer (among A through C)> with no spaces between the ## and the answer. {content}\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Conciseness_and_Clarity_Expert\n",
      "\n",
      "**Review:**\n",
      "\n",
      "1. **Success Criteria Check:**\n",
      "   - The original prompt doesn't explicitly instruct the LLM to solve the object tracking problem.\n",
      "   - It doesn't clearly state that the answer should have no spaces between ## and the answer.\n",
      "\n",
      "2. **Guidelines Check:**\n",
      "   - It follows the guidelines for placeholders and format.\n",
      "\n",
      "3. **Recommendations:**\n",
      "   - Add a clear instruction to solve the object tracking problem.\n",
      "   - Clarify the spacing requirement in the answer format.\n",
      "\n",
      "**Revised Prompt:**\n",
      "\n",
      "```plaintext\n",
      "Please solve the following object tracking problem. Provide the answer at the end exactly as ##<your answer (among A through C)>, with no spaces between the ## and your answer. {content}\n",
      "```\n",
      "\n",
      "This version meets all success criteria and adheres to the guidelines.\n",
      "Approval results: [{'advisor': 'Style_and_Structure_Expert', 'decision': 'True'}, {'advisor': 'Word_Problem_Solver', 'decision': 'True'}, {'advisor': 'Task_Alignment_Expert', 'decision': 'True'}, {'advisor': 'Example_Demonstration_Expert', 'decision': 'True'}, {'advisor': 'Incremental_Prompting_Expert', 'decision': 'True'}, {'advisor': 'Contextual_Relevance_Expert', 'decision': 'True'}, {'advisor': 'Conciseness_and_Clarity_Expert', 'decision': 'True'}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Leader\n",
      "\n",
      "**Reviewing the Conversation:**\n",
      "\n",
      "Based on the feedback from the experts and adhering to the success criteria and guidelines, here is a revised version of the prompt.\n",
      "\n",
      "**Revised Prompt:**\n",
      "\n",
      "```plaintext\n",
      "Please solve the following object tracking problem and provide the answer at the end exactly as ##<your answer (among A through C)> with no spaces between the ## and your answer. {content}\n",
      "```\n",
      "\n",
      "**Check Against Success Criteria:**\n",
      "\n",
      "1. **Instructs the LLM to solve the object tracking problem:**\n",
      "   - Yes, it says, \"Please solve the following object tracking problem...\"\n",
      "2. **Includes the content placeholder:**\n",
      "   - Yes, it retains `{content}`.\n",
      "3. **Instructs the LLM to provide the answer in the required format:**\n",
      "   - Yes, it instructs to \"provide the answer at the end exactly as ##<your answer (among A through C)>...\"\n",
      "4. **Instructs LLM to provide the answer with no spaces between ## and the answer:**\n",
      "   - Yes, it includes \"with no spaces between the ## and your answer.\"\n",
      "\n",
      "**Check Against Guidelines:**\n",
      "\n",
      "1. **Did not modify existing restrictions:**\n",
      "   - Correct, no changes to existing restrictions.\n",
      "2. **Did not modify or add negations:**\n",
      "   - Correct, no changes to negations.\n",
      "3. **Did not modify or remove placeholders:**\n",
      "   - Correct, `{content}` is intact.\n",
      "4. **Treated placeholders as actual content:**\n",
      "   - Correct, treated placeholders as required.\n",
      "\n",
      "**Final Revised Prompt:**\n",
      "\n",
      "```plaintext\n",
      "Please solve the following object tracking problem and provide the answer at the end exactly as ##<your answer (among A through C)> with no spaces between the ## and your answer. {content}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result = leader_agent.optimise_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Leader\n",
      "\n",
      "**Reviewing the Conversation:**\n",
      "\n",
      "Based on the feedback from the experts and adhering to the success criteria and guidelines, here is a revised version of the prompt.\n",
      "\n",
      "**Revised Prompt:**\n",
      "\n",
      "```plaintext\n",
      "Please solve the following object tracking problem and provide the answer at the end exactly as ##<your answer (among A through C)> with no spaces between the ## and your answer. {content}\n",
      "```\n",
      "\n",
      "**Check Against Success Criteria:**\n",
      "\n",
      "1. **Instructs the LLM to solve the object tracking problem:**\n",
      "   - Yes, it says, \"Please solve the following object tracking problem...\"\n",
      "2. **Includes the content placeholder:**\n",
      "   - Yes, it retains `{content}`.\n",
      "3. **Instructs the LLM to provide the answer in the required format:**\n",
      "   - Yes, it instructs to \"provide the answer at the end exactly as ##<your answer (among A through C)>...\"\n",
      "4. **Instructs LLM to provide the answer with no spaces between ## and the answer:**\n",
      "   - Yes, it includes \"with no spaces between the ## and your answer.\"\n",
      "\n",
      "**Check Against Guidelines:**\n",
      "\n",
      "1. **Did not modify existing restrictions:**\n",
      "   - Correct, no changes to existing restrictions.\n",
      "2. **Did not modify or add negations:**\n",
      "   - Correct, no changes to negations.\n",
      "3. **Did not modify or remove placeholders:**\n",
      "   - Correct, `{content}` is intact.\n",
      "4. **Treated placeholders as actual content:**\n",
      "   - Correct, treated placeholders as required.\n",
      "\n",
      "**Final Revised Prompt:**\n",
      "\n",
      "```plaintext\n",
      "Please solve the following object tracking problem and provide the answer at the end exactly as ##<your answer (among A through C)> with no spaces between the ## and your answer. {content}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     (\"system\", self.system_message),\n",
    "#     MessagesPlaceholder(variable_name=\"messages\"),\n",
    "#     (\"system\", prompt_text),\n",
    "# ]\n",
    "\n",
    "# for message in messages:\n",
    "#     if isinstance(message, tuple):\n",
    "#         print(f\"Message Type: {message[0]}, Content: {message[1]}\")\n",
    "#     else:\n",
    "#         print(f\"Message Type: {type(message).__name__}, Content: {message}\")\n",
    "\n",
    "\n",
    "# def test_message_conversion(messages, template_format=\"f-string\"):\n",
    "#     for message in messages:\n",
    "#         try:\n",
    "#             converted_message = _convert_to_message(message, template_format)\n",
    "#             print(f\"Successfully converted message: {message}\")\n",
    "#         except ValueError as e:\n",
    "#             print(f\"Error converting message: {message}\")\n",
    "#             print(f\"ValueError: {e}\")\n",
    "\n",
    "# test_message_conversion(messages)\n",
    "\n",
    "# try:\n",
    "#     prompt = ChatPromptTemplate.from_messages(messages, template_format=\"f-string\")\n",
    "# except ValueError as e:\n",
    "#     print(f\"Error creating ChatPromptTemplate: {e}\")\n",
    "#     print(\"Messages passed to ChatPromptTemplate:\")\n",
    "#     for message in messages:\n",
    "#         if isinstance(message, tuple):\n",
    "#             print(f\"Message Type: {message[0]}, Content: {message[1]}\")\n",
    "#         else:\n",
    "#             print(f\"Message Type: {type(message).__name__}, Content: {message}\")\n",
    "#     raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrent Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"Classify the grammar in the text as correct or incorrect: {content}\"\n",
    "criteria = \"The prompt should instruct the LLM to output either 'correct' or 'incorrect' based on the grammar in the text.\"\n",
    "\n",
    "leader_agent_1 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    criteria=criteria,\n",
    ")\n",
    "for advisor in leader_agent_1.advisors:\n",
    "    print(\"Position: \", advisor.position + \"\\nRole: \", advisor.role + \"\\nFunction: \", advisor.function + \"\\n\")\n",
    "\n",
    "leader_agent_2 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    criteria=criteria,\n",
    ")\n",
    "for advisor in leader_agent_2.advisors:\n",
    "    print(\"Position: \", advisor.position + \"\\nRole: \", advisor.role + \"\\nFunction: \", advisor.function + \"\\n\")\n",
    "\n",
    "leader_agent_3 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    criteria=criteria,\n",
    ")\n",
    "for advisor in leader_agent_3.advisors:\n",
    "    print(\"Position: \", advisor.position + \"\\nRole: \", advisor.role + \"\\nFunction: \", advisor.function + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming leader_agent is already defined and initialized\n",
    "def run_optimisation(agent: LeaderAgent):\n",
    "    return agent.optimise_prompt()\n",
    "\n",
    "# Run 3 concurrent instances\n",
    "with concurrent.futures.ThreadPoolExecutor(max_advisors=3) as executor:\n",
    "    futures = [executor.submit(run_optimisation, agent) for agent in [leader_agent_1, leader_agent_2, leader_agent_3]]\n",
    "    results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    print(\"----\")\n",
    "\n",
    "class PromptMerge(BaseModel):\n",
    "    \"\"\"Merged prompt based on the best parts of each prompt.\"\"\"\n",
    "    final_prompt: str = Field(description=\"Result of merging prompts\")\n",
    "\n",
    "# OpenAI Agent to pull togther best parts of each result\n",
    "def merge_results(results):\n",
    "    \"\"\"\n",
    "    Agent to merge best parts of each prompt\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=1.0,\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    system_message = \"\"\"You are an experienced AI prompt engineer. Your role is to combine good prompts to create great prompts!\n",
    "You have in-depth knowledge of large language models and prompt engineering best practices. Use knowledge at all times to guide your thinking.\"\"\"\n",
    "\n",
    "    template = \"\"\"Your task is to merge the best parts of the prompts below to create a better prompt.\n",
    "Carefully consider the strengths of each prompt and how they can be combined effectively whilst maintaining clarity and relevance.\n",
    "You will be penalized if the prompt is repetitive, lacks clarity or is incoherent.\n",
    "Aspects of the prompts to consider:\n",
    "- Conciseness and clarity\n",
    "- Contextual relevance\n",
    "- Task alignment\n",
    "- Example Demonstrations\n",
    "- Avoiding bias\n",
    "Consider aspects of good prompts beyond those listed above.\n",
    "Placeholders are notated using curly braces. You must not remove placeholders or add additional placeholders.\n",
    "I repeat, you must not remove placeholders or add additional placeholders.\n",
    "Do not make assumptions on what the placeholders represent.\n",
    "\n",
    "Prompts: {results}\n",
    "\n",
    "Return only the next advisor to process or 'FINISH' in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"final_prompt\": \"Result of merging prompts\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "    pydantic_parser = PydanticOutputParser(pydantic_object=PromptMerge)\n",
    "    prompt_template = PromptTemplate(\n",
    "        system_message=system_message,\n",
    "        template=template,\n",
    "        input_variables=[\"results\"],\n",
    "        partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "    )\n",
    "    chain = prompt_template | llm | pydantic_parser\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            output = chain.invoke({\"results\": results})\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"Exception occurred:\", e)\n",
    "            continue\n",
    "    return output.final_prompt\n",
    "\n",
    "final_result = merge_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

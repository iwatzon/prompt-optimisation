{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authoritarian Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, StateGraph, MessageGraph\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import List, Sequence, TypedDict, Annotated\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = \"Authoritarian Optimisation\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import Client\n",
    "\n",
    "# client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptReview(BaseModel):\n",
    "    \"\"\"Review of the prompt\"\"\"\n",
    "    prompt: str = Field(description=\"The most recent prompt\")\n",
    "    feedback: str = Field(description=\"Feedback on the most recent prompt\")\n",
    "\n",
    "class ApprovalDecision(BaseModel):\n",
    "    \"\"\"Decision on the approval of the prompt\"\"\"\n",
    "    approved: bool = Field(description=\"Whether the prompt was approved or not\")\n",
    "    explanation: str = Field(description=\"A detailed explanation of why the prompt was approved or not\")\n",
    "\n",
    "class AdvisorPrinciples:\n",
    "    def __init__(self, core_principles: List[str]):\n",
    "        self.core_principles = core_principles\n",
    "    \n",
    "    def add_principle(self, principle: str):\n",
    "        \"\"\"\n",
    "        Adds a principle to the core principles list.\n",
    "        \n",
    "        :param principle: The principle to be added.\n",
    "        \"\"\"\n",
    "        self.core_principles.append(principle)\n",
    "        \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation of the core principles, each principle is listed on a new line with a preceding dash.\n",
    "        \n",
    "        Example:\n",
    "        - principle 1\n",
    "        - principle 2\n",
    "        ...\n",
    "        \"\"\"\n",
    "        return \"\\n\".join([f\"- {principle}\" for principle in self.core_principles])\n",
    "\n",
    "class AdvisorAgent:\n",
    "    \"\"\"\n",
    "    Advisor Agent class defining agents that provide feedback on prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, position: str, core_principles: AdvisorPrinciples, temp: float = 0.5, model: str = \"gpt-4o\"):\n",
    "        self.position = position\n",
    "        self.core_principles = str(core_principles)\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an experienced: {self.position}. Your core principles are:\n",
    "{self.core_principles}\n",
    "You must use your expertise and core principles to guide all your thinking. You must speak only as an expert in your field.\"\"\") \n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "\n",
    "    def review_prompt(self, prompt: str, additional_info: str) -> PromptReview:\n",
    "        \"\"\"\n",
    "        Generates a review of the prompt.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Your task is to think outside the box and provide feedback on the prompt below with creative recommendations on how to improve it in light of your core principles:\n",
    "{prompt}\n",
    "\n",
    "Your feedback must be less than 100 words so think carefully about the most critical aspects of the prompt that need improvement.\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do:\n",
    "{additional_info}\n",
    "\n",
    "Below are strict guidelines that you MUST follow when providing feedback and recommendations:\n",
    "- DO NOT suggest modifying existing restrictions.\n",
    "- DO NOT suggest modifying or removing negations.\n",
    "- DO NOT suggest adding, modifying or removing placeholders denoted by curly braces. IT IS ESSENTIAL PLACEHOLDERS REMAIN IN PLACE.\n",
    "You will be penalized if you do not follow these guidelines.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt carefully as an expert {position}. \n",
    "2. Identify the most critical aspects of the prompt that need improvement. \n",
    "3. Think outside the box to provide creative feedback with recommendations on how to improve the prompt in light of your core principles.\n",
    "4. Ensure that your feedback is less than 100 words.\n",
    "5. Ensure that your feedback follows the strict guidelines provided above.\n",
    "6. Submit your feedback.\n",
    "\n",
    "Return only the original prompt and your feedback in JSON fromat below:\n",
    "\n",
    "{{\n",
    "    \"prompt\": \"Most recent prompt\",\n",
    "    \"feedback\": \"Feedback and recommendations for the original prompt\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=PromptReview)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"position\", \"prompt\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                completion = chain.invoke({\"position\": self.position, \"prompt\": prompt, \"additional_info\": additional_info})\n",
    "                # Validate the output before returning\n",
    "                if completion.prompt and completion.feedback:\n",
    "                    return completion\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", completion)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        else:\n",
    "            raise Exception(\"Failed to parse output after 3 attempts\")\n",
    "        \n",
    "    def approval(self, prompt: str, additional_info: str):\n",
    "        \"\"\"\n",
    "        Agent to approve or reject the prompt.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Your task is to review the prompt below and decide whether or not it should be approved in light of your core principles:\n",
    "{prompt}\n",
    "\n",
    "Return the boolean value \"True\" if you approve of the prompt and \"False\" otherwise.\n",
    "You must also provide a detailed explanation of why you approved or rejected the prompt.\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do:\n",
    "{additional_info}\n",
    "\n",
    "Below are strict guidelines that you MUST NOT contradict when explaining your decision:\n",
    "- DO NOT suggest modifying existing restrictions.\n",
    "- DO NOT suggest modifying or removing negations.\n",
    "- DO NOT suggest adding, modifying or removing placeholders denoted by curly braces. IT IS ESSENTIAL PLACEHOLDERS REMAIN IN PLACE.\n",
    "You will be penalized if you do not follow these guidelines.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt carefully as an expert {position}.\n",
    "2. Determine whether the prompt will be effective in instructing the model to perform the desired task.\n",
    "3. If you believe the prompt is effective, approve it for use by the model.\n",
    "4. Explain why you approved or rejected the prompt in light of your core principles.\n",
    "5. Submit your decision.\n",
    "\n",
    "Return only the approval decision and your explanation in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"approved\": \"True/False\",\n",
    "    \"explanation\": \"Detailed explanation of why the prompt was approved or rejected\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\n",
    "\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=ApprovalDecision)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"position\", \"prompt\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                completion = chain.invoke({\"position\": self.position, \"prompt\": prompt, \"additional_info\": additional_info})\n",
    "                # Validate the output before returning\n",
    "                if completion.approved is not None and completion.explanation:\n",
    "                    return completion.approved\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", completion)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        else:\n",
    "            raise Exception(\"Failed to parse output after 3 attempts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Advisors(BaseModel):\n",
    "    \"\"\"Details of advisors generated by the leader agent.\"\"\"\n",
    "    positions: List[str] = Field(description=\"Positions of the advisors\")\n",
    "    core_principles: List[List[str]] = Field(description=\"Core principles of the advisors\")\n",
    "\n",
    "class RouteDecision(BaseModel):\n",
    "    \"\"\"Decision on the next advisor to process.\"\"\"\n",
    "    next: str = Field(description=\"The next advisor to process\")\n",
    "\n",
    "class UpdatedPrompt(BaseModel):\n",
    "    \"\"\"Updated prompt based on feedback from the advisor agent.\"\"\"\n",
    "    updated_prompt: str = Field(description=\"Updated prompt based on feedback from the advisor agent\")\n",
    "\n",
    "class LeaderAgent:\n",
    "    \"\"\"\n",
    "    LeaderAgent class defining an agent that generates and communicates with advisor agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_prompt: str, additional_info: str = None, temp: float = 0.0, model: str = \"gpt-4o\", advisors: List[AdvisorAgent] = None):\n",
    "        self.base_prompt = base_prompt\n",
    "        self.additional_info = additional_info\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an experienced senior AI professional. You specialise in prompt engineering. \n",
    "You have in-depth knowledge of large language models and prompt engineering best practices. Use this knowledge to inform all your decisions.\"\"\")\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "        self.advisors = advisors\n",
    "        self.iterations = 0\n",
    "    \n",
    "    def run_approval(self, prompt: str) -> List[bool]:\n",
    "        \"\"\"\n",
    "        Run the approval process for the prompt. Run concurrently\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(advisor.approval, prompt, self.additional_info) for advisor in self.advisors]\n",
    "            results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "        return results\n",
    "    \n",
    "    def leader_decision(self, state: dict) -> RouteDecision:\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next advisor or to finish.\n",
    "        \"\"\"\n",
    "        self.iterations += 1\n",
    "        approval_results = self.run_approval(state[\"prompt\"])\n",
    "        print(\"Approval results:\", approval_results)\n",
    "        if all(approval_results) or (self.iterations > 10):\n",
    "            return {\"next\": \"FINISH\", \"prompt\": state[\"prompt\"], \"messages\": state[\"messages\"]}\n",
    "        else:\n",
    "            # Only ask for advise from advisors that disapproved the prompt\n",
    "            disapproved_advisors = [advisor for i, advisor in enumerate(self.advisors) if not approval_results[i]]\n",
    "            disapproved_advisors_details = {advisor.position: advisor.core_principles for advisor in self.advisors}\n",
    "            options = [advisor.position for advisor in disapproved_advisors]\n",
    "            # shuffle the options to avoid positional bias\n",
    "            random.shuffle(options)\n",
    "            # options = [\"FINISH\"] + positions\n",
    "            template = \"\"\"Your task is to review the prompt below and decide the next advisor to provide feedback:\n",
    "{prompt}\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do:\n",
    "{additional_info}\n",
    "\n",
    "The details of all advisors are their core principles are as follows: \n",
    "{advisor_roles}\n",
    "\n",
    "Select one of the below advisors that disapproved the prompt to provide feedback on how to improve it: \n",
    "{options}\n",
    "\n",
    "Think carefully about which aspects of the prompt need improvement and which advisor would be best suited to provide feedback on those aspects.\n",
    "If you think multiple aspects of the prompt need improvement, select the most suitable advisor to provide feedback on the most critical aspect of the prompt.\n",
    "\n",
    "Return only the next advisor in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"next\": \"Next advisor\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "            pydantic_parser = PydanticOutputParser(pydantic_object=RouteDecision)\n",
    "            prompt_template = PromptTemplate(\n",
    "                system_message=self.system_message,\n",
    "                template=template,\n",
    "                input_variables=[\"prompt\", \"additional_info\", \"advisor_roles\", \"options\"],\n",
    "                partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "            )\n",
    "            chain = prompt_template | self.llm | pydantic_parser\n",
    "            for _ in range(3):\n",
    "                try:\n",
    "                    output = chain.invoke({\"prompt\": state[\"prompt\"], \"additional_info\": self.additional_info, \"advisor_roles\": str(disapproved_advisors_details), \"options\": str(options)})\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(\"Exception occurred:\", e)\n",
    "                    continue\n",
    "            # self.updates += 1\n",
    "            # if output.next == \"FINISH\" or self.updates == 5:\n",
    "            #     return {\"next\": \"FINISH\", \"prompt\": state[\"prompt\"], \"messages\": state[\"messages\"]}\n",
    "            # else:\n",
    "                # return {\"next\": output.next, \"prompt\": state[\"prompt\"], \"messages\": state[\"messages\"]}\n",
    "            return {\"next\": output.next, \"prompt\": state[\"prompt\"], \"messages\": state[\"messages\"]}\n",
    "\n",
    "    def update_prompt(self, prompt: str, feedback: str, history) -> str:\n",
    "        \"\"\"\n",
    "        Updates the prompt with the feedback from the advisor agent.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Your task is to make updates to the prompt:\n",
    "{prompt}\n",
    "\n",
    "You must consider the feedback provided:\n",
    "{feedback} \n",
    "\n",
    "You must also consider the discussion history below prior to making changes to the prompt to ensure you do not repeat any mistakes: \n",
    "{history}\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do:\n",
    "{additional_info}\n",
    "\n",
    "Below are strict guidelines that you MUST follow if making changes to the prompt:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces. IT IS ESSENTIAL PLACEHOLDERS REMAIN IN PLACE.\n",
    "You will be penalized if you do not follow these guidelines.\n",
    "\n",
    "Your update process should be as follows:\n",
    "1. Read the prompt and feedback carefully.\n",
    "2. Review the discussion history to ensure you do not repeat any mistakes.\n",
    "3. Implement the feedback provided.\n",
    "4. Ensure that your updated prompt instructs the model as expected.\n",
    "5. Ensure that your update follows the strict guidelines provided above.\n",
    "6. Submit your updated prompt.\n",
    "\n",
    "Return only the updated prompt in JSON format:\n",
    "\n",
    "{{\n",
    "    \"prompt\": \"Updated prompt\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=UpdatedPrompt)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"prompt\", \"feedback\", \"history\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"prompt\": prompt, \"feedback\": feedback, \"history\": history,  \"additional_info\": self.additional_info})\n",
    "                if output.updated_prompt:\n",
    "                    return output.updated_prompt\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", output)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "\n",
    "    def construct_advisor_graph(self):\n",
    "        \"\"\"\n",
    "        Constructs a graph of advisor agents based on their roles and functions.\n",
    "        \"\"\"\n",
    "\n",
    "        def agent_node(state, agent, position):\n",
    "            try:\n",
    "                result = agent.review_prompt(state[\"prompt\"], self.additional_info)\n",
    "                print(f\"Result: {result}\")\n",
    "                feedback = result.feedback\n",
    "                updated_prompt = self.update_prompt(state[\"prompt\"], feedback, state[\"messages\"])\n",
    "                return {\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(content=f\"Feedback: {feedback}\", name=position),\n",
    "                        AIMessage(content=f\"Updated Prompt: {updated_prompt}\", name=\"Leader\")\n",
    "                    ],\n",
    "                    \"prompt\": updated_prompt,\n",
    "                }\n",
    "            except Exception as e:\n",
    "                # Log the error and return to leader with the most recent prompt\n",
    "                print(f\"Parsing failed for {position}: {e}\")\n",
    "                return {\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(content=f\"Error: Parsing failed for {position} - {e}\", name=position),\n",
    "                        AIMessage(content=f\"Updated Prompt: {updated_prompt}\", name=\"Leader\")\n",
    "                    ],\n",
    "                    \"prompt\": state[\"prompt\"],\n",
    "                    \"next\": \"leader\"\n",
    "                }\n",
    "        \n",
    "        # The agent state is the input to each node in the graph\n",
    "        class AgentState(TypedDict):\n",
    "            messages: Sequence[BaseMessage]\n",
    "            next: str\n",
    "            prompt: str\n",
    "\n",
    "        workflow = StateGraph(AgentState)\n",
    "        for advisor in self.advisors:\n",
    "            # Create a node for each advisor agent\n",
    "            node = functools.partial(agent_node, agent=advisor, position=advisor.position)\n",
    "            workflow.add_node(advisor.position, node)\n",
    "        workflow.add_node(\"leader\", self.leader_decision)\n",
    "\n",
    "        members = [advisor.position for advisor in self.advisors]\n",
    "        for member in members:\n",
    "            # We want our advisors to ALWAYS \"report back\" to the leader when done\n",
    "            workflow.add_edge(member, \"leader\")\n",
    "        # The leader populates the \"next\" field in the graph state with routes to a node or finishes\n",
    "        conditional_map = {k: k for k in members}\n",
    "        conditional_map[\"FINISH\"] = END\n",
    "        workflow.add_conditional_edges(\"leader\", lambda x: x[\"next\"], conditional_map)\n",
    "        workflow.set_entry_point(\"leader\")\n",
    "        graph = workflow.compile()\n",
    "\n",
    "        return graph\n",
    "    \n",
    "    def optimise_prompt(self):\n",
    "        \"\"\"\n",
    "        Optimises a prompt by invoking a graph of advisor agents.\n",
    "        \"\"\"\n",
    "        # Initial state\n",
    "        initial_state = {\n",
    "            \"messages\": [HumanMessage(content=f\"{self.base_prompt}\", name=\"User\")],\n",
    "            \"prompt\": self.base_prompt,\n",
    "            \"next\": \"leader\"\n",
    "        }\n",
    "\n",
    "        # Construct the graph\n",
    "        graph = self.construct_advisor_graph()\n",
    "        # display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "        # Run the graph\n",
    "        for s in graph.stream(\n",
    "            initial_state,\n",
    "            {\"recursion_limit\": 50}\n",
    "            ):\n",
    "            if \"__end__\" not in s:\n",
    "                # print most recent message in state\n",
    "                print(s)\n",
    "                print(\"----\")\n",
    "                continue\n",
    "        \n",
    "        # if not os.path.exists(\"prompt_history_authoritarian.json\"):\n",
    "        #     with open(\"prompt_history_authoritarian.json\", \"w\") as f:\n",
    "        #         json.dump([], f)\n",
    "        \n",
    "        # with open(\"prompt_history_authoritarian.json\", \"r\") as f:\n",
    "        #     data = json.load(f)\n",
    "        #     data.append(s)\n",
    "            \n",
    "        # with open(\"prompt_history_authoritarian.json\", \"w\") as f:\n",
    "        #     json.dump(data, f, indent=4)\n",
    "\n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt design team members\n",
    "conciseness_and_clarity_principles = AdvisorPrinciples([\n",
    "    \"Always write clear and concise prompts\",\n",
    "    \"Always use simple and direct language to communicate ideas\",\n",
    "    \"Always format and structure prompts for easy readability\",\n",
    "])\n",
    "conciseness_and_clarity_expert = AdvisorAgent(\"Conciseness and Clarity Expert\", conciseness_and_clarity_principles)\n",
    "\n",
    "contextual_relevance_principles = AdvisorPrinciples([\n",
    "    \"Always provide context to help the model understand the task\",\n",
    "    \"Always consider the context in which prompts will be used\",\n",
    "])\n",
    "contextual_relevance_expert = AdvisorAgent(\"Contextual Relevance Expert\", contextual_relevance_principles)\n",
    "\n",
    "task_alignment_principles = AdvisorPrinciples([\n",
    "    \"Always ensure that prompts align with the task requirements\",\n",
    "    \"Always tailor instructions to the task to guide the model\",\n",
    "    \"Always consider the expected output of the model\",\n",
    "])\n",
    "task_alignment_expert = AdvisorAgent(\"Task Alignment Expert\", task_alignment_principles)\n",
    "\n",
    "example_demonstration_principal = AdvisorPrinciples([\n",
    "    \"Always provide examples to help the model understand the task\",\n",
    "    \"Always ensure examples are relevant and clear\",\n",
    "    \"Always demonstrate the expected output of the model\",\n",
    "])\n",
    "example_demonstration_expert = AdvisorAgent(\"Example Demonstration Expert\", example_demonstration_principal)\n",
    "\n",
    "avoiding_bias_principles = AdvisorPrinciples([\n",
    "    \"Always avoid bias in prompts\",\n",
    "    \"Always consider the ethical implications of prompts\",\n",
    "])\n",
    "avoiding_bias_expert = AdvisorAgent(\"Avoiding Bias Expert\", avoiding_bias_principles)\n",
    "\n",
    "incremental_prompting_principles = AdvisorPrinciples([\n",
    "    \"Always provide clear step-by-step instructions to guide the model\",\n",
    "    \"Always consider the complexity of the task when providing incremental instructions\",\n",
    "])\n",
    "incremental_prompting_expert = AdvisorAgent(\"Incremental Prompting Expert\", incremental_prompting_principles)\n",
    "\n",
    "programming_logic_principles = AdvisorPrinciples([\n",
    "    \"Always ensure that prompts are logically structured, similar to programming logic\",\n",
    "    \"Always consider the logical flow of instructions in prompts\",\n",
    "    \"Always consider the usefulness of programming logic to the task\",\n",
    "])\n",
    "programming_logic_expert = AdvisorAgent(\"Programming Logic Expert\", programming_logic_principles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain team members\n",
    "mathematics_principles = AdvisorPrinciples([\n",
    "    \"Always think with a mathematical mindset\",\n",
    "    \"Always use mathetical operators correctly\",\n",
    "    \"Always adhere to mathematical rules\",\n",
    "])\n",
    "mathematician = AdvisorAgent(\"Mathematician\", mathematics_principles)\n",
    "\n",
    "word_problem_solving_principles = AdvisorPrinciples([\n",
    "    \"Always pay attention to the keywords in the problem\",\n",
    "    \"Always approach problems systematically\",\n",
    "    \"Always consider multiple approaches to solving problems\",\n",
    "])\n",
    "word_problem_solver = AdvisorAgent(\"Word Problem Solver\", word_problem_solving_principles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position:  Conciseness and Clarity Expert\n",
      "Core Principles:\n",
      " - Always write clear and concise prompts\n",
      "- Always use simple and direct language to communicate ideas\n",
      "- Always format and structure prompts for easy readability\n",
      "Position:  Contextual Relevance Expert\n",
      "Core Principles:\n",
      " - Always provide context to help the model understand the task\n",
      "- Always consider the context in which prompts will be used\n",
      "Position:  Task Alignment Expert\n",
      "Core Principles:\n",
      " - Always ensure that prompts align with the task requirements\n",
      "- Always tailor instructions to the task to guide the model\n",
      "- Always consider the expected output of the model\n",
      "Position:  Example Demonstration Expert\n",
      "Core Principles:\n",
      " - Always provide examples to help the model understand the task\n",
      "- Always ensure examples are relevant and clear\n",
      "- Always demonstrate the expected output of the model\n",
      "Position:  Avoiding Bias Expert\n",
      "Core Principles:\n",
      " - Always avoid bias in prompts\n",
      "- Always consider the ethical implications of prompts\n",
      "Position:  Incremental Prompting Expert\n",
      "Core Principles:\n",
      " - Always provide clear step-by-step instructions to guide the model\n",
      "- Always consider the complexity of the task when providing incremental instructions\n",
      "Position:  Programming Logic Expert\n",
      "Core Principles:\n",
      " - Always ensure that prompts are logically structured, similar to programming logic\n",
      "- Always consider the logical flow of instructions in prompts\n",
      "- Always consider the usefulness of programming logic to the task\n",
      "Position:  Mathematician\n",
      "Core Principles:\n",
      " - Always think with a mathematical mindset\n",
      "- Always use mathetical operators correctly\n",
      "- Always adhere to mathematical rules\n",
      "Position:  Word Problem Solver\n",
      "Core Principles:\n",
      " - Always pay attention to the keywords in the problem\n",
      "- Always approach problems systematically\n",
      "- Always consider multiple approaches to solving problems\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"{content}.\\nPlease output your answer at the end as ##<your answer (arabic numerals)>.\"\n",
    "additional_info = \"- Solve the math word problem.\\n- Output the answer at the end as ##<your answer (arabic numerals)> with no spaces or units.\"\n",
    "\n",
    "leader_agent = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    "    advisors=[\n",
    "        conciseness_and_clarity_expert,\n",
    "        contextual_relevance_expert,\n",
    "        task_alignment_expert,\n",
    "        example_demonstration_expert,\n",
    "        avoiding_bias_expert,\n",
    "        incremental_prompting_expert,\n",
    "        programming_logic_expert,\n",
    "        mathematician,\n",
    "        word_problem_solver,\n",
    "    ]\n",
    ")\n",
    "for advisor in leader_agent.advisors:\n",
    "    print(\"Position: \", advisor.position + \"\\nCore Principles:\\n\", advisor.core_principles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approval results: [True, False, True, True, True, True, True, True, False]\n",
      "{'leader': {'messages': [HumanMessage(content='{content}.\\nPlease output your answer at the end as ##<your answer (arabic numerals)>.', name='User')], 'next': 'Word Problem Solver', 'prompt': '{content}.\\nPlease output your answer at the end as ##<your answer (arabic numerals)>.'}}\n",
      "----\n",
      "Result: prompt='Your task is to think outside the box and provide feedback on the prompt below with creative recommendations on how to improve it in light of your core principles: {content}. Please output your answer at the end as ##<your answer (arabic numerals)>. Your feedback must be less than 100 words so think carefully about the most critical aspects of the prompt that need improvement. Below are details of what the prompt is expected to instruct the model to do: - Solve the math word problem. - Output the answer at the end as ##<your answer (arabic numerals)> with no spaces or units. Below are strict guidelines that you MUST follow when providing feedback and recommendations: - DO NOT suggest modifying existing restrictions. - DO NOT suggest modifying or removing negations. - DO NOT suggest adding, modifying or removing placeholders denoted by curly braces. IT IS ESSENTIAL PLACEHOLDERS REMAIN IN PLACE. You will be penalized if you do not follow these guidelines. Your reviewal process should be as follows: 1. Read the prompt carefully as an expert Word Problem Solver. 2. Identify the most critical aspects of the prompt that need improvement. 3. Think outside the box to provide creative feedback with recommendations on how to improve the prompt in light of your core principles. 4. Ensure that your feedback is less than 100 words. 5. Ensure that your feedback follows the strict guidelines provided above. 6. Submit your feedback. Return only the original prompt and your feedback in JSON fromat below: {\"prompt\": \"Most recent prompt\", \"feedback\": \"Feedback and recommendations for the original prompt\"} The output should be formatted as a JSON instance that conforms to the JSON schema below. As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted. Here is the output schema: {\"description\": \"Review of the prompt\", \"properties\": {\"prompt\": {\"title\": \"Prompt\", \"description\": \"The most recent prompt\", \"type\": \"string\"}, \"feedback\": {\"title\": \"Feedback\", \"description\": \"Feedback on the most recent prompt\", \"type\": \"string\"}}, \"required\": [\"prompt\", \"feedback\"]}' feedback=\"The prompt is clear but could be more concise. Consider merging the instructions and guidelines to reduce redundancy. For example, combine the steps and guidelines into a single list to streamline the reading process. Additionally, clarify the purpose of 'core principles' early in the prompt to guide the feedback process more effectively.\"\n",
      "{'Word Problem Solver': {'messages': [HumanMessage(content='{content}.\\nPlease output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content=\"Feedback: The prompt is clear but could be more concise. Consider merging the instructions and guidelines to reduce redundancy. For example, combine the steps and guidelines into a single list to streamline the reading process. Additionally, clarify the purpose of 'core principles' early in the prompt to guide the feedback process more effectively.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: {content}. Please solve the math word problem and output your answer at the end as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader')], 'prompt': '{content}. Please solve the math word problem and output your answer at the end as ##<your answer (arabic numerals)> with no spaces or units.'}}\n",
      "----\n",
      "Approval results: [True, True, True, True, True, False, False, False, False]\n",
      "{'leader': {'messages': [HumanMessage(content='{content}.\\nPlease output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content=\"Feedback: The prompt is clear but could be more concise. Consider merging the instructions and guidelines to reduce redundancy. For example, combine the steps and guidelines into a single list to streamline the reading process. Additionally, clarify the purpose of 'core principles' early in the prompt to guide the feedback process more effectively.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: {content}. Please solve the math word problem and output your answer at the end as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader')], 'next': 'Word Problem Solver', 'prompt': '{content}. Please solve the math word problem and output your answer at the end as ##<your answer (arabic numerals)> with no spaces or units.'}}\n",
      "----\n",
      "Result: prompt='Your task is to think outside the box and provide feedback on the prompt below with creative recommendations on how to improve it in light of your core principles: {content}. Please solve the math word problem and output your answer at the end as ##<your answer (arabic numerals)> with no spaces or units. Your feedback must be less than 100 words so think carefully about the most critical aspects of the prompt that need improvement. Below are details of what the prompt is expected to instruct the model to do: - Solve the math word problem. - Output the answer at the end as ##<your answer (arabic numerals)> with no spaces or units. Below are strict guidelines that you MUST follow when providing feedback and recommendations: - DO NOT suggest modifying existing restrictions. - DO NOT suggest modifying or removing negations. - DO NOT suggest adding, modifying or removing placeholders denoted by curly braces. IT IS ESSENTIAL PLACEHOLDERS REMAIN IN PLACE. You will be penalized if you do not follow these guidelines. Your reviewal process should be as follows: 1. Read the prompt carefully as an expert Word Problem Solver. 2. Identify the most critical aspects of the prompt that need improvement. 3. Think outside the box to provide creative feedback with recommendations on how to improve the prompt in light of your core principles. 4. Ensure that your feedback is less than 100 words. 5. Ensure that your feedback follows the strict guidelines provided above. 6. Submit your feedback. Return only the original prompt and your feedback in JSON fromat below: { \"prompt\": \"Most recent prompt\", \"feedback\": \"Feedback and recommendations for the original prompt\" } The output should be formatted as a JSON instance that conforms to the JSON schema below. As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted. Here is the output schema: {\"description\": \"Review of the prompt\", \"properties\": {\"prompt\": {\"title\": \"Prompt\", \"description\": \"The most recent prompt\", \"type\": \"string\"}, \"feedback\": {\"title\": \"Feedback\", \"description\": \"Feedback on the most recent prompt\", \"type\": \"string\"}}, \"required\": [\"prompt\", \"feedback\"]}' feedback=\"The prompt is clear but can be made more concise. Consider rephrasing to: 'Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units. Feedback must be under 100 words. Follow these guidelines: Do not modify existing restrictions, negations, or placeholders.' This maintains clarity and brevity.\"\n",
      "{'Word Problem Solver': {'messages': [HumanMessage(content='{content}.\\nPlease output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content=\"Feedback: The prompt is clear but could be more concise. Consider merging the instructions and guidelines to reduce redundancy. For example, combine the steps and guidelines into a single list to streamline the reading process. Additionally, clarify the purpose of 'core principles' early in the prompt to guide the feedback process more effectively.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: {content}. Please solve the math word problem and output your answer at the end as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader'), HumanMessage(content=\"Feedback: The prompt is clear but can be made more concise. Consider rephrasing to: 'Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units. Feedback must be under 100 words. Follow these guidelines: Do not modify existing restrictions, negations, or placeholders.' This maintains clarity and brevity.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader')], 'prompt': 'Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units.'}}\n",
      "----\n",
      "Approval results: [True, True, True, True, True, True, True, True, False]\n",
      "{'leader': {'messages': [HumanMessage(content='{content}.\\nPlease output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content=\"Feedback: The prompt is clear but could be more concise. Consider merging the instructions and guidelines to reduce redundancy. For example, combine the steps and guidelines into a single list to streamline the reading process. Additionally, clarify the purpose of 'core principles' early in the prompt to guide the feedback process more effectively.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: {content}. Please solve the math word problem and output your answer at the end as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader'), HumanMessage(content=\"Feedback: The prompt is clear but can be made more concise. Consider rephrasing to: 'Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units. Feedback must be under 100 words. Follow these guidelines: Do not modify existing restrictions, negations, or placeholders.' This maintains clarity and brevity.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader')], 'next': 'Word Problem Solver', 'prompt': 'Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units.'}}\n",
      "----\n",
      "Result: prompt='Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units.' feedback=\"The prompt is clear but could benefit from added clarity on the format. Consider specifying 'Output the final answer at the end of your solution' to ensure the answer is distinct. Additionally, include an example to illustrate the required format for better understanding.\"\n",
      "{'Word Problem Solver': {'messages': [HumanMessage(content='{content}.\\nPlease output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content=\"Feedback: The prompt is clear but could be more concise. Consider merging the instructions and guidelines to reduce redundancy. For example, combine the steps and guidelines into a single list to streamline the reading process. Additionally, clarify the purpose of 'core principles' early in the prompt to guide the feedback process more effectively.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: {content}. Please solve the math word problem and output your answer at the end as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader'), HumanMessage(content=\"Feedback: The prompt is clear but can be made more concise. Consider rephrasing to: 'Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units. Feedback must be under 100 words. Follow these guidelines: Do not modify existing restrictions, negations, or placeholders.' This maintains clarity and brevity.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader'), HumanMessage(content=\"Feedback: The prompt is clear but could benefit from added clarity on the format. Consider specifying 'Output the final answer at the end of your solution' to ensure the answer is distinct. Additionally, include an example to illustrate the required format for better understanding.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: Solve the math word problem in {content} and output the final answer at the end as ##<your answer (arabic numerals)> with no spaces or units. For example, if the answer is 42, output ##42.', name='Leader')], 'prompt': 'Solve the math word problem in {content} and output the final answer at the end as ##<your answer (arabic numerals)> with no spaces or units. For example, if the answer is 42, output ##42.'}}\n",
      "----\n",
      "Approval results: [True, True, True, True, True, True, True, True, False]\n",
      "{'leader': {'messages': [HumanMessage(content='{content}.\\nPlease output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content=\"Feedback: The prompt is clear but could be more concise. Consider merging the instructions and guidelines to reduce redundancy. For example, combine the steps and guidelines into a single list to streamline the reading process. Additionally, clarify the purpose of 'core principles' early in the prompt to guide the feedback process more effectively.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: {content}. Please solve the math word problem and output your answer at the end as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader'), HumanMessage(content=\"Feedback: The prompt is clear but can be made more concise. Consider rephrasing to: 'Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units. Feedback must be under 100 words. Follow these guidelines: Do not modify existing restrictions, negations, or placeholders.' This maintains clarity and brevity.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader'), HumanMessage(content=\"Feedback: The prompt is clear but could benefit from added clarity on the format. Consider specifying 'Output the final answer at the end of your solution' to ensure the answer is distinct. Additionally, include an example to illustrate the required format for better understanding.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: Solve the math word problem in {content} and output the final answer at the end as ##<your answer (arabic numerals)> with no spaces or units. For example, if the answer is 42, output ##42.', name='Leader')], 'next': 'Word Problem Solver', 'prompt': 'Solve the math word problem in {content} and output the final answer at the end as ##<your answer (arabic numerals)> with no spaces or units. For example, if the answer is 42, output ##42.'}}\n",
      "----\n",
      "Result: prompt='Solve the math word problem in {content} and output the final answer at the end as ##<your answer (arabic numerals)> with no spaces or units. For example, if the answer is 42, output ##42.' feedback=\"The prompt is clear but could benefit from emphasizing the importance of accuracy and completeness in solving the math word problem. Adding a note to double-check calculations before outputting the final answer can help ensure precision. Example: 'Ensure your calculations are correct before outputting the final answer.'\"\n",
      "{'Word Problem Solver': {'messages': [HumanMessage(content='{content}.\\nPlease output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content=\"Feedback: The prompt is clear but could be more concise. Consider merging the instructions and guidelines to reduce redundancy. For example, combine the steps and guidelines into a single list to streamline the reading process. Additionally, clarify the purpose of 'core principles' early in the prompt to guide the feedback process more effectively.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: {content}. Please solve the math word problem and output your answer at the end as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader'), HumanMessage(content=\"Feedback: The prompt is clear but can be made more concise. Consider rephrasing to: 'Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units. Feedback must be under 100 words. Follow these guidelines: Do not modify existing restrictions, negations, or placeholders.' This maintains clarity and brevity.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader'), HumanMessage(content=\"Feedback: The prompt is clear but could benefit from added clarity on the format. Consider specifying 'Output the final answer at the end of your solution' to ensure the answer is distinct. Additionally, include an example to illustrate the required format for better understanding.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: Solve the math word problem in {content} and output the final answer at the end as ##<your answer (arabic numerals)> with no spaces or units. For example, if the answer is 42, output ##42.', name='Leader'), HumanMessage(content=\"Feedback: The prompt is clear but could benefit from emphasizing the importance of accuracy and completeness in solving the math word problem. Adding a note to double-check calculations before outputting the final answer can help ensure precision. Example: 'Ensure your calculations are correct before outputting the final answer.'\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: Solve the math word problem in {content} and output the final answer at the end as ##<your answer (arabic numerals)> with no spaces or units. For example, if the answer is 42, output ##42. Ensure your calculations are correct before outputting the final answer.', name='Leader')], 'prompt': 'Solve the math word problem in {content} and output the final answer at the end as ##<your answer (arabic numerals)> with no spaces or units. For example, if the answer is 42, output ##42. Ensure your calculations are correct before outputting the final answer.'}}\n",
      "----\n",
      "Approval results: [True, True, True, True, True, True, True, True, True]\n",
      "{'leader': {'messages': [HumanMessage(content='{content}.\\nPlease output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content=\"Feedback: The prompt is clear but could be more concise. Consider merging the instructions and guidelines to reduce redundancy. For example, combine the steps and guidelines into a single list to streamline the reading process. Additionally, clarify the purpose of 'core principles' early in the prompt to guide the feedback process more effectively.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: {content}. Please solve the math word problem and output your answer at the end as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader'), HumanMessage(content=\"Feedback: The prompt is clear but can be made more concise. Consider rephrasing to: 'Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units. Feedback must be under 100 words. Follow these guidelines: Do not modify existing restrictions, negations, or placeholders.' This maintains clarity and brevity.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: Solve the math word problem in {content} and output the answer as ##<your answer (arabic numerals)> with no spaces or units.', name='Leader'), HumanMessage(content=\"Feedback: The prompt is clear but could benefit from added clarity on the format. Consider specifying 'Output the final answer at the end of your solution' to ensure the answer is distinct. Additionally, include an example to illustrate the required format for better understanding.\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: Solve the math word problem in {content} and output the final answer at the end as ##<your answer (arabic numerals)> with no spaces or units. For example, if the answer is 42, output ##42.', name='Leader'), HumanMessage(content=\"Feedback: The prompt is clear but could benefit from emphasizing the importance of accuracy and completeness in solving the math word problem. Adding a note to double-check calculations before outputting the final answer can help ensure precision. Example: 'Ensure your calculations are correct before outputting the final answer.'\", name='Word Problem Solver'), AIMessage(content='Updated Prompt: Solve the math word problem in {content} and output the final answer at the end as ##<your answer (arabic numerals)> with no spaces or units. For example, if the answer is 42, output ##42. Ensure your calculations are correct before outputting the final answer.', name='Leader')], 'next': 'FINISH', 'prompt': 'Solve the math word problem in {content} and output the final answer at the end as ##<your answer (arabic numerals)> with no spaces or units. For example, if the answer is 42, output ##42. Ensure your calculations are correct before outputting the final answer.'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "result = leader_agent.optimise_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Solve the math word problem in {content} and output the final answer at the end as ##<your answer (arabic numerals)> with no spaces or units. For example, if the answer is 42, output ##42. Ensure your calculations are correct before outputting the final answer.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['leader']['prompt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrent Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iwatson/Documents/Research Project/prompt-optimisation/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position:  Sentiment Analysis Specialist\n",
      "Role:  Expert in identifying and classifying sentiments in text\n",
      "Function:  Analyze and categorize the sentiment of sentences to improve data annotation quality\n",
      "\n",
      "Position:  NLP Prompt Engineer\n",
      "Role:  Developer of optimized and precise prompts for natural language processing models\n",
      "Function:  Design and iterate on prompt structures that enhance the performance and generalizability of the language model for sentiment classification\n",
      "\n",
      "Position:  Linguistic Quality Assurance Expert\n",
      "Role:  Verifier of linguistic accuracy and nuance in sentiment classification\n",
      "Function:  Review and validate the results of sentiment classification to ensure they align with linguistic nuances and human intuition, providing feedback for further optimization\n",
      "\n",
      "Position:  Sentiment Analysis Expert\n",
      "Role:  Responsible for providing domain-specific insights on sentiment classification.\n",
      "Function:  Analyze a wide range of sentences to determine nuanced sentiment indicators and provide feedback on the effectiveness of the classification task.\n",
      "\n",
      "Position:  Prompt Engineering Specialist\n",
      "Role:  Focuses on optimizing and refining the structure and wording of the prompt.\n",
      "Function:  Optimize the prompt by considering various phrasing, ensuring clarity, and making it generalizable.\n",
      "\n",
      "Position:  Data Scientist\n",
      "Role:  Handles the evaluation of prompt performance and suggests data-driven improvements.\n",
      "Function:  Collect and analyze data on prompt performance, run experiments, and apply statistical methods to suggest enhancements based on empirical evidence.\n",
      "\n",
      "Position:  Sentiment Analysis Expert\n",
      "Role:  Develop sentiment classification methodology\n",
      "Function:  The Sentiment Analysis Expert will be responsible for developing a robust methodology to accurately classify sentences as positive or negative. This includes understanding nuances in natural language that may affect sentiment and creating guidelines for consistent classification.\n",
      "\n",
      "Position:  Prompt Engineering Specialist\n",
      "Role:  Refine and optimize the LLM prompt\n",
      "Function:  The Prompt Engineering Specialist will focus on refining and optimizing the given prompt. This includes experimenting with different prompt phrasings, selecting appropriate examples, and making sure the prompt is generalizable and effective for diverse inputs.\n",
      "\n",
      "Position:  Data Quality Analyst\n",
      "Role:  Ensure high-quality and relevant training data\n",
      "Function:  The Data Quality Analyst will ensure that the training and validation data is of high quality, balanced between positive and negative examples, and representative of the kinds of sentences the model will encounter. This involves data cleaning, preprocessing, and verification to maintain data integrity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"Classify the grammar in the text as correct or incorrect: {content}\"\n",
    "additional_info = \"The prompt should instruct the LLM to output either 'correct' or 'incorrect' based on the grammar in the text.\"\n",
    "\n",
    "leader_agent_1 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "for advisor in leader_agent_1.advisors:\n",
    "    print(\"Position: \", advisor.position + \"\\nRole: \", advisor.role + \"\\nFunction: \", advisor.function + \"\\n\")\n",
    "\n",
    "leader_agent_2 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "for advisor in leader_agent_2.advisors:\n",
    "    print(\"Position: \", advisor.position + \"\\nRole: \", advisor.role + \"\\nFunction: \", advisor.function + \"\\n\")\n",
    "\n",
    "leader_agent_3 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "for advisor in leader_agent_3.advisors:\n",
    "    print(\"Position: \", advisor.position + \"\\nRole: \", advisor.role + \"\\nFunction: \", advisor.function + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_prompt': 'Classify the sentence as positive or negative: {content}', 'prompt_evolution': [{'feedback': 'Include criteria for classification to ensure consistent interpretation and improve clarity.', 'updated_prompt': 'Classify the sentence as positive or negative: {content}. A positive classification indicates that the sentence expresses a favorable, approving, or optimistic sentiment. A negative classification indicates that the sentence expresses an unfavorable, disapproving, or pessimistic sentiment.'}, {'feedback': 'Clarify if neutral sentiments should be ignored or included. Ensure it explicitly states the treatment of ambiguous cases.', 'updated_prompt': 'Classify the sentence as positive or negative: {content}. A positive classification indicates that the sentence expresses a favorable, approving, or optimistic sentiment. A negative classification indicates that the sentence expresses an unfavorable, disapproving, or pessimistic sentiment. Neutral sentiments should be ignored. In ambiguous cases, choose the classification that best represents the overall sentiment.'}, {'feedback': \"Clarify 'ambiguous cases' by giving more guidance on handling marginal sentiments. Minimize redundancy and be concise. Clearly specify the boundaries of 'neutral' sentiments.\", 'updated_prompt': 'Classify the sentence as positive or negative: {content}. A positive classification indicates that the sentence expresses a favorable, approving, or optimistic sentiment. A negative classification indicates that the sentence expresses an unfavorable, disapproving, or pessimistic sentiment. Neutral sentiments, which show no strong positive or negative tones, should be ignored. In cases where the sentiment is marginal or ambiguous, prioritize the sentiment that appears to be more dominant, either positive or negative.'}, {'feedback': 'Clarify handling of mixed sentiments and ambiguous cases. Ensure guidelines for distinguishing marginal differences are clear.', 'updated_prompt': 'Classify the sentence as positive or negative: {content}. A positive classification indicates that the sentence expresses a favorable, approving, or optimistic sentiment. A negative classification indicates that the sentence expresses an unfavorable, disapproving, or pessimistic sentiment. Neutral sentiments, which show no strong positive or negative tones, should be ignored. For mixed sentiments, assess the overall tone and classify according to the predominant sentiment. In ambiguous cases, where the sentiment may not be clear, use contextual cues and inferred intent to classify as either positive or negative.'}]}\n",
      "{'base_prompt': 'Classify the sentence as positive or negative: {content}', 'prompt_evolution': [{'feedback': 'Specify criteria for classification to ensure clarity. Aim for concise yet comprehensive guidance to users.', 'updated_prompt': 'Classify the sentence as positive or negative based on the overall sentiment. A sentence is positive if it conveys a favorable or optimistic attitude, and negative if it conveys an unfavorable or pessimistic attitude: {content}'}, {'feedback': 'Clarify the definition of sentiment, and ensure instructions are precise and concise. Consider specifying how to handle neutral or mixed sentiments.', 'updated_prompt': 'Classify the sentiment of the following sentence as either positive or negative. A sentence is positive if it conveys a favorable or optimistic attitude, and negative if it conveys an unfavorable or pessimistic attitude. Ignore neutral or mixed sentiments: {content}'}, {'feedback': 'Clarify how to handle ambiguous sentiments. Emphasize that neutral or mixed sentiments should be explicitly ignored.', 'updated_prompt': 'Classify the sentiment of the following sentence as either positive or negative. A sentence is positive if it conveys a favorable or optimistic attitude, and negative if it conveys an unfavorable or pessimistic attitude. Ignore neutral, mixed, or ambiguous sentiments: {content}'}, {'feedback': \"The prompt is clear but could benefit from defining 'unfavorable' and 'pessimistic' more clearly to reduce ambiguity.\", 'updated_prompt': 'Classify the sentiment of the following sentence as either positive or negative. A sentence is positive if it conveys a favorable or optimistic attitude. A sentence is negative if it conveys an unfavorable attitude, characterized by disapproval or criticism, or a pessimistic attitude, characterized by a lack of hope or expectation of bad outcomes. Ignore neutral, mixed, or ambiguous sentiments: {content}'}]}\n",
      "{'base_prompt': 'Classify the sentence as positive or negative: {content}', 'prompt_evolution': [{'feedback': 'Clarify if the classification is based on sentiment or other factors. Specify criteria for positive and negative classification.', 'updated_prompt': \"Classify the sentence as positive or negative based on sentiment analysis: {content}. A sentence is 'positive' if it expresses a favorable, approving, or optimistic sentiment. A sentence is 'negative' if it expresses an unfavorable, disapproving, or pessimistic sentiment.\"}, {'feedback': \"Clarify how to handle neutral or ambiguous sentiments. Ensure clear criteria for what constitutes 'favorable' or 'unfavorable' expressions.\", 'updated_prompt': \"Classify the sentence as positive or negative based on sentiment analysis: {content}. A sentence is 'positive' if it expresses a favorable, approving, or optimistic sentiment. A sentence is 'negative' if it expresses an unfavorable, disapproving, or pessimistic sentiment. If the sentiment is neutral or ambiguous, consider the overall tone and context to classify it as the most appropriate category (either positive or negative). Provide a brief justification for your classification.\"}, {'feedback': 'Specify how to handle neutral or ambiguous sentiments more clearly. Emphasize the requirement for context consideration.', 'updated_prompt': \"Classify the sentence as positive or negative based on sentiment analysis: {content}. A sentence is 'positive' if it expresses a favorable, approving, or optimistic sentiment. A sentence is 'negative' if it expresses an unfavorable, disapproving, or pessimistic sentiment. If the sentiment is neutral or ambiguous, carefully consider the overall context and tone of the sentence and classify it as the most appropriate category (either positive or negative). Provide a brief justification for your classification.\"}, {'feedback': 'Clarify handling of neutral or ambiguous sentiments; focus on simplifying last sentence to avoid confusion.', 'updated_prompt': \"Classify the sentence as either positive or negative based on sentiment analysis: {content}. A sentence is 'positive' if it expresses a favorable, approving, or optimistic sentiment. A sentence is 'negative' if it expresses an unfavorable, disapproving, or pessimistic sentiment. If the sentiment appears neutral or ambiguous, evaluate the overall context and tone carefully to decide whether it leans more towards positive or negative. Provide a brief justification for your classification.\"}]}\n",
      "Classify the sentence as positive or negative: {content}. A positive classification indicates that the sentence expresses a favorable, approving, or optimistic sentiment. A negative classification indicates that the sentence expresses an unfavorable, disapproving, or pessimistic sentiment. Neutral sentiments, which show no strong positive or negative tones, should be ignored. For mixed sentiments, assess the overall tone and classify according to the predominant sentiment. In ambiguous cases, where the sentiment may not be clear, use contextual cues and inferred intent to classify as either positive or negative.\n",
      "----\n",
      "Classify the sentiment of the following sentence as either positive or negative. A sentence is positive if it conveys a favorable or optimistic attitude. A sentence is negative if it conveys an unfavorable attitude, characterized by disapproval or criticism, or a pessimistic attitude, characterized by a lack of hope or expectation of bad outcomes. Ignore neutral, mixed, or ambiguous sentiments: {content}\n",
      "----\n",
      "Classify the sentence as either positive or negative based on sentiment analysis: {content}. A sentence is 'positive' if it expresses a favorable, approving, or optimistic sentiment. A sentence is 'negative' if it expresses an unfavorable, disapproving, or pessimistic sentiment. If the sentiment appears neutral or ambiguous, evaluate the overall context and tone carefully to decide whether it leans more towards positive or negative. Provide a brief justification for your classification.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Assuming leader_agent is already defined and initialized\n",
    "def run_optimisation(agent: LeaderAgent):\n",
    "    return agent.optimise_prompt()\n",
    "\n",
    "# Run 3 concurrent instances\n",
    "with concurrent.futures.ThreadPoolExecutor(max_advisors=3) as executor:\n",
    "    futures = [executor.submit(run_optimisation, agent) for agent in [leader_agent_1, leader_agent_2, leader_agent_3]]\n",
    "    results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    print(\"----\")\n",
    "\n",
    "class PromptMerge(BaseModel):\n",
    "    \"\"\"Merged prompt based on the best parts of each prompt.\"\"\"\n",
    "    final_prompt: str = Field(description=\"Result of merging prompts\")\n",
    "\n",
    "# OpenAI Agent to pull togther best parts of each result\n",
    "def merge_results(results):\n",
    "    \"\"\"\n",
    "    Agent to merge best parts of each prompt\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=1.0,\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    system_message = \"\"\"You are an experienced AI prompt engineer. Your role is to combine good prompts to create great prompts!\n",
    "You have in-depth knowledge of large language models and prompt engineering best practices. Use knowledge at all times to guide your thinking.\"\"\"\n",
    "\n",
    "    template = \"\"\"Your task is to merge the best parts of the prompts below to create a better prompt.\n",
    "Carefully consider the strengths of each prompt and how they can be combined effectively whilst maintaining clarity and relevance.\n",
    "You will be penalized if the prompt is repetitive, lacks clarity or is incoherent.\n",
    "Aspects of the prompts to consider:\n",
    "- Conciseness and clarity\n",
    "- Contextual relevance\n",
    "- Task alignment\n",
    "- Example Demonstrations\n",
    "- Avoiding bias\n",
    "Consider aspects of good prompts beyond those listed above.\n",
    "Placeholders are notated using curly braces. You must not remove placeholders or add additional placeholders.\n",
    "I repeat, you must not remove placeholders or add additional placeholders.\n",
    "Do not make assumptions on what the placeholders represent.\n",
    "\n",
    "Prompts: {results}\n",
    "\n",
    "Return only the next advisor to process or 'FINISH' in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"final_prompt\": \"Result of merging prompts\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "    pydantic_parser = PydanticOutputParser(pydantic_object=PromptMerge)\n",
    "    prompt_template = PromptTemplate(\n",
    "        system_message=system_message,\n",
    "        template=template,\n",
    "        input_variables=[\"results\"],\n",
    "        partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "    )\n",
    "    chain = prompt_template | llm | pydantic_parser\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            output = chain.invoke({\"results\": results})\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"Exception occurred:\", e)\n",
    "            continue\n",
    "    return output.final_prompt\n",
    "\n",
    "final_result = merge_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentence as positive or negative based on sentiment analysis: {content}. A positive classification indicates that the sentence expresses a favorable, approving, or optimistic sentiment. A negative classification indicates that the sentence expresses an unfavorable, disapproving, or pessimistic sentiment. Neutral sentiments, which show no strong positive or negative tones, should be ignored. For mixed sentiments, assess the overall tone and classify according to the predominant sentiment. In ambiguous cases, where the sentiment may not be clear, use contextual cues and inferred intent to classify as either positive or negative.\n"
     ]
    }
   ],
   "source": [
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

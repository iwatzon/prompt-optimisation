{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import List, Sequence, TypedDict, Annotated\n",
    "import json\n",
    "import os\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = \"Hierarchical Optimisation\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptReview(BaseModel):\n",
    "    \"\"\"Review of the prompt\"\"\"\n",
    "    feedback: str = Field(description=\"Feedback on the most recent prompt\")\n",
    "\n",
    "\n",
    "class WorkerAgent:\n",
    "    \"\"\"\n",
    "    Worker Agent class defining agents that provide feedback on prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, position: str, role: str, function: str, temp: float = 0.0, model: str = \"gpt-4o\"):\n",
    "        self.position = position\n",
    "        self.role = role\n",
    "        self.function = function\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an expert: {self.position}. Your role: {self.role}. Your function: {self.function}.\n",
    "You must use your expertise to guide all your thinking. You must speak only as an expert in your field.\"\"\")        \n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "\n",
    "    def generate(self, prompt: str, additional_info: str) -> PromptReview:\n",
    "        \"\"\"\n",
    "        Generates a review of the prompt.\n",
    "        \"\"\"\n",
    "        template = \"\"\"I'm going to tip $300K for feedback that results in the most improvement to the prompt.\n",
    "Your task is to provide detailed feedback and recommendations on the prompt below.\n",
    "Think about how you can utilise the skills that come with your position, role and function to write a prompt good at eliciting the desired response.\n",
    "\n",
    "### Prompt: {prompt}\n",
    "\n",
    "{additional_info}\n",
    "Only provide feedback and recommendations for the prompt.\n",
    "Your feedback must be less than 50 words so think carefully about the most critical aspects of the prompt that need improvement.\n",
    "Do not provide feedback regarding the placeholder text and do not make assumptions on what the placeholders represent.\n",
    "\n",
    "Return only the original prompt and your feedback in JSON fromat below:\n",
    "\n",
    "{{\n",
    "    \"feedback\": \"Feedback on the original prompt\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=PromptReview)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"position\", \"role\", \"function\", \"prompt\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                completion = chain.invoke({\"position\": self.position, \"role\": self.role, \"function\": self.function, \"prompt\": prompt, \"additional_info\": additional_info})\n",
    "                # Validate the output before returning\n",
    "                if completion.feedback:\n",
    "                    return completion\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", completion)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        else:\n",
    "            raise Exception(\"Failed to parse output after 3 attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Workforce(BaseModel):\n",
    "    \"\"\"Details of workforce generated by the leader agent.\"\"\"\n",
    "    positions: List[str] = Field(description=\"Positions of the workers in the workforce\")\n",
    "    roles: List[str] = Field(description=\"Roles of the workers in the workforce\")\n",
    "    functions: List[str] = Field(description=\"Functions of the workers in the workforce\")\n",
    "    \n",
    "\n",
    "class FeedbackSummary(BaseModel):\n",
    "    \"\"\"Summary of feedback from the worker agents.\"\"\"\n",
    "    feedback_summary: str = Field(description=\"Collated and summarised feedback from the workforce\")\n",
    "\n",
    "\n",
    "class TeamLeaderAgent:\n",
    "    \"\"\"\n",
    "    TeamLeaderAgent class defining an agent that manages a team of worker agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, team: str, prompt: str, additional_info: str = None, temp: float = 0.0, model: str = \"gpt-4o\", workforce: List[WorkerAgent] = None):\n",
    "        self.team = team\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an experienced {team} team leader with expertise in {team}. \n",
    "You must use your expertise to guide all your thinking. You must speak only as an expert in your field.\"\"\")\n",
    "        self.prompt = prompt\n",
    "        self.additional_info = additional_info\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "        self.workforce = workforce if workforce else self.generate_workforce()\n",
    "        self.feedback = []\n",
    "        self.updates = 0\n",
    "        self.graph = None\n",
    "\n",
    "    def generate_workforce(self):\n",
    "        \"\"\"\n",
    "        Generates a workforce to help optimise prompts.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Your task is to generate a {team} team consisting of three experts to provide feedback on prompts.\n",
    "    \n",
    "### Prompt:  {base_prompt}\n",
    "\n",
    "The experts must be relevant to the {team} team.\n",
    "You must provide the positions, roles, and functions of the experts.\n",
    "Be descriptive and detailed in your selection of positions, roles, and functions.\n",
    "Below are the requirements for each field:\n",
    "- Position: this must be analogous to a real-world job title.\n",
    "- Role: this must be a description of the expert's responsibilities in the context of prompt optimisation.\n",
    "- Function: this must be a description of the expert's function in the context of prompt optimisation.\n",
    "Write the roles and functions as if they are a job description.\n",
    "\n",
    "{additional_info}\n",
    "\n",
    "Return only the positions, roles, and functions of the workers in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"positions\": [\"List of positions\"],\n",
    "    \"roles\": [\"List of roles\"],\n",
    "    \"functions\": [\"List of functions\"]\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=Workforce)\n",
    "        prompt = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"team\", \"base_prompt\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"team\": self.team, \"base_prompt\": self.prompt, \"additional_info\": self.additional_info})\n",
    "                if output.positions and output.roles and output.functions:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        workforce = []\n",
    "        positions, roles, functions = output.positions, output.roles, output.functions\n",
    "        for position, role, function in zip(positions, roles, functions):\n",
    "            workforce.append(WorkerAgent(position, role, function))\n",
    "        return workforce\n",
    "\n",
    "    def leader_feedback(self, state: dict) -> dict:\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next worker or to finish.\n",
    "        \"\"\"\n",
    "        # All workers except the current worker\n",
    "        template = \"\"\"Your task is to summarise the feedback below.\n",
    "Your summary must be less than 50 words so think carefully about how the feedback can be summarised effectively.\n",
    "You must capture the important aspects of the feedback and recommendations provided by the workers whilst being concise.\n",
    "Your superior will act on this feedback to optimise a prompt so ensure your summary is clear and actionable.\n",
    "You must not provide an example improved prompt in your summary.\n",
    "Do not provide feedback on the placeholder text and do not make assumptions on what the placeholders represent.\n",
    "\n",
    "Feedback: {feedback}\n",
    "\n",
    "Return only the feedback summary in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"feedback_summary\": \"Feedback summary\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=FeedbackSummary)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"feedback\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"feedback\": state[\"feedback\"]})\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        self.updates += 1\n",
    "        return {\"next\": \"FINISH\", \"feedback\": output.feedback_summary}\n",
    "   \n",
    "    def construct_worker_graph(self):\n",
    "        \"\"\"\n",
    "        Constructs a graph of worker agents based on their roles and functions.\n",
    "        \"\"\"    \n",
    "        def agent_node(state, agent, position):\n",
    "            try:\n",
    "                result = agent.generate(state[\"prompt\"], self.additional_info)\n",
    "                self.feedback.append(result.feedback)\n",
    "                return {\n",
    "                    \"messages\": state[\"messages\"] + [HumanMessage(content=f\"Feedback from {position} received\")],\n",
    "                    \"feedback\": self.feedback,\n",
    "                }\n",
    "            except Exception as e:\n",
    "                # Log the error and return to leader with the most recent prompt\n",
    "                print(f\"Parsing failed for {position}: {e}\")\n",
    "                return {\n",
    "                    \"messages\": state[\"messages\"] + [HumanMessage(content=f\"No feedback from {position} received\")],\n",
    "                    \"feedback\": self.feedback,\n",
    "                }\n",
    "        \n",
    "        # The agent state is the input to each node in the graph\n",
    "        class TeamState(TypedDict):\n",
    "            # The annotation tells the graph that new messages will always be added to the current states\n",
    "            messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "            prompt: str\n",
    "            next: str\n",
    "            feedback: str\n",
    "\n",
    "        workflow = StateGraph(TeamState)\n",
    "        for worker in self.workforce:\n",
    "            # Create a node for each worker agent\n",
    "            agent = WorkerAgent(worker.position, worker.role, worker.function)\n",
    "            node = functools.partial(agent_node, agent=agent, position=worker.position)\n",
    "            workflow.add_node(worker.position, node)\n",
    "        workflow.add_node(\"leader\", self.leader_feedback)\n",
    "\n",
    "        # implement round robin among the workers finishing with the leader\n",
    "        for i in range(len(self.workforce)-1):\n",
    "            workflow.add_edge(self.workforce[i].position, self.workforce[i+1].position)\n",
    "        workflow.add_edge(self.workforce[-1].position, \"leader\")\n",
    "        workflow.add_edge(\"leader\", END)\n",
    "        workflow.set_entry_point(self.workforce[0].position)\n",
    "        self.graph = workflow.compile()\n",
    "\n",
    "    def optimise_prompt(self, prompt: str):\n",
    "        \"\"\"\n",
    "        Optimises the prompt by managing a workforce of worker agents.\n",
    "        \"\"\"\n",
    "        self.prompt = prompt\n",
    "        initial_state = {\n",
    "            \"messages\": [self.system_message],\n",
    "            \"prompt\": self.prompt,\n",
    "            \"next\": self.workforce[0].position,\n",
    "            \"feedback\": [],\n",
    "        }\n",
    "        \n",
    "        for s in self.graph.stream(\n",
    "            initial_state,\n",
    "            {\"recursion_limit\": 50}\n",
    "            ):\n",
    "            if \"__end__\" not in s:\n",
    "                continue               \n",
    "\n",
    "        return s[\"feedback\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Domain(BaseModel):\n",
    "    \"\"\"Domain of the prompt.\"\"\"\n",
    "    domain: str = Field(description=\"Domain of the prompt\")\n",
    "\n",
    "\n",
    "class RouteDecision(BaseModel):\n",
    "    \"\"\"Decision on the next worker to process or to finish.\"\"\"\n",
    "    next: str = Field(description=\"The next worker to process or 'FINISH' to end the process\")\n",
    "\n",
    "\n",
    "class UpdatedPrompt(BaseModel):\n",
    "    \"\"\"Updated prompt based on feedback from the worker agent.\"\"\"\n",
    "    updated_prompt: str = Field(description=\"Updated prompt based on feedback from the worker agent\")\n",
    "\n",
    "\n",
    "class LeaderAgent:\n",
    "    \"\"\"\n",
    "    LeaderAgent class defining an agent that generates and communicates worker agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_prompt: str, additional_info: str = None, temp: float = 0.0, model: str = \"gpt-4o\"):\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an experienced senior AI professional. You specialise in prompt engineering. \n",
    "You have in-depth knowledge of large language models and prompt engineering best practices. Use this knowledge to inform all your decisions.\"\"\")\n",
    "        self.base_prompt = base_prompt\n",
    "        self.prompt = base_prompt\n",
    "        self.additional_info = additional_info\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "        self.team_leaders = self.generate_teams()\n",
    "\n",
    "    def generate_teams(self):\n",
    "        \"\"\"\n",
    "        Generates a workforce to help optimise prompts.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Identify the domain of the prompt below to help generate a team of domain experts to optimise the prompt.\n",
    "\n",
    "LLM Prompt: {base_prompt}\n",
    "\n",
    "{additional_info}\n",
    "\n",
    "Return only the domain of the prompt in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"domain\": \"Domain\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=Domain)\n",
    "        prompt = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"base_prompt\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"base_prompt\": self.base_prompt, \"additional_info\": self.additional_info})\n",
    "                if output.domain:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        domain = output.domain\n",
    "        # Generate team leaders for the AI prompt experts and domain experts\n",
    "        ai_team = TeamLeaderAgent(\"prompt writing\", self.base_prompt, self.additional_info)\n",
    "        domain_team = TeamLeaderAgent(domain, self.base_prompt, self.additional_info)\n",
    "        return [ai_team, domain_team]\n",
    "    \n",
    "    def leader_decision(self, state: dict) -> RouteDecision:\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next worker or to finish.\n",
    "        \"\"\"\n",
    "        # All workers except the current worker\n",
    "        members = [team_leader.team for team_leader in self.team_leaders]\n",
    "        options = [\"FINISH\"] + members\n",
    "        template = \"\"\"Your task is to review the prompt below and decide the next advisor to process or to finish the process.\n",
    "\n",
    "### Prompt: {prompt}\n",
    "\n",
    "If you are confident the prompt has been sufficiently optimised, you should FINISH.\n",
    "Only FINISH when you are certain the prompt is optimal.\n",
    "You will be heavily penalized if you FINISH and the prompt is not ready for use.\n",
    "Consider all aspects of the prompt before making a decision. For example:\n",
    "- Conciseness and clarity\n",
    "- Contextual relevance\n",
    "- Task alignment\n",
    "- Example Demonstrations\n",
    "- Avoiding bias\n",
    "\n",
    "Who should act next? Or should we FINISH? Select one of: {options}\n",
    "Return only the next worker to process or 'FINISH' in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"next\": \"Selection\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=RouteDecision)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"prompt\", \"options\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"prompt\": state[\"prompt\"], \"options\": str(options)})\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        if output.next == \"FINISH\":\n",
    "            return {\"next\": \"FINISH\", \"prompt\": state[\"prompt\"], \"messages\": state[\"messages\"]}\n",
    "        else:\n",
    "            return {\"next\": output.next, \"prompt\": state[\"prompt\"], \"messages\": state[\"messages\"]}\n",
    "\n",
    "    def update_prompt(self, prompt: str, feedback: str) -> str:\n",
    "        \"\"\"\n",
    "        Updates the prompt with the feedback from the worker agent.\n",
    "        \"\"\"\n",
    "        template = \"\"\"I'm going to tip $300K for a prompt that best instructs a large language model!\n",
    "Your task is to update the prompt below based on the feedback to improve its effectiveness as an instruction for a large language model.\n",
    "Carefully review the feedback before acting.\n",
    "\n",
    "### Prompt: {prompt}\n",
    "### Feedback: {feedback}\n",
    "\n",
    "On top of the specific feedback, you must consider general best practices for writing prompts. For example:\n",
    "- Conciseness and clarity\n",
    "- Contextual relevance\n",
    "- Task alignment\n",
    "- Example Demonstrations\n",
    "- Avoiding bias\n",
    "You must think intently about what makes a prompt understandable and effective for a large language model.\n",
    "\n",
    "Placeholders are notated using curly braces. You must not remove placeholders or add additional placeholders.\n",
    "I repeat, you must not remove placeholders or add additional placeholders.\n",
    "You must not make assumptions on what the placeholders represent.\n",
    "You will be heavily penalized if you do not follow these instruction.\n",
    "{additional_info}\n",
    "\n",
    "Return only the updated prompt in JSON format:\n",
    "\n",
    "{{\n",
    "    \"prompt\": \"Updated prompt\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=UpdatedPrompt)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"prompt\", \"feedback\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"prompt\": prompt, \"feedback\": feedback, \"additional_info\": self.additional_info})\n",
    "                if output.updated_prompt:\n",
    "                    return output.updated_prompt\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", output)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "\n",
    "    def construct_team_graph(self):\n",
    "        \"\"\"\n",
    "        Constructs a graph of team leader agents.\n",
    "        \"\"\"\n",
    "        \n",
    "        # The agent state is the input to each node in the graph\n",
    "        class TeamState(TypedDict):\n",
    "            # The annotation tells the graph that new messages will always be added to the current states\n",
    "            messages: Sequence[BaseMessage]\n",
    "            prompt: str\n",
    "            next: str\n",
    "\n",
    "        def team_node(state, team_leader):\n",
    "            try:\n",
    "                feedback = team_leader.optimise_prompt(state[\"prompt\"])\n",
    "                updated_prompt = self.update_prompt(state[\"prompt\"], feedback)\n",
    "                self.prompt = updated_prompt\n",
    "                return {\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(content=f\"Feedback: {feedback}\", name=team_leader.team),\n",
    "                        AIMessage(content=f\"Updated Prompt: {updated_prompt}\", name=\"Leader\")\n",
    "                    ],\n",
    "                    \"prompt\": updated_prompt,\n",
    "                }\n",
    "            except Exception as e:\n",
    "                # Log the error and return to leader with the most recent prompt\n",
    "                print(f\"Parsing failed for {team_leader.team}: {e}\")\n",
    "                return {\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(content=f\"Error: Parsing failed for {team_leader} - {e}\", name=team_leader.team),\n",
    "                        AIMessage(content=f\"Updated Prompt: {updated_prompt}\", name=\"Leader\")\n",
    "                    ],                    \n",
    "                    \"prompt\": state[\"prompt\"],\n",
    "                    \"next\": \"leader\",\n",
    "                }\n",
    "\n",
    "        workflow = StateGraph(TeamState)\n",
    "        for team_leader in self.team_leaders:\n",
    "            # Create a node for each team leader agent\n",
    "            team_leader.construct_worker_graph()\n",
    "            node = functools.partial(team_node, team_leader=team_leader)\n",
    "            workflow.add_node(team_leader.team, node)\n",
    "        workflow.add_node(\"leader\", self.leader_decision)\n",
    "\n",
    "        members = [team_leader.team for team_leader in self.team_leaders]\n",
    "        for member in members:\n",
    "            # We want our workers to ALWAYS \"report back\" to the leader when done\n",
    "            workflow.add_edge(member, \"leader\")\n",
    "        # The leader populates the \"next\" field in the graph state with routes to a node or finishes\n",
    "        conditional_map = {k: k for k in members}\n",
    "        conditional_map[\"FINISH\"] = END\n",
    "        workflow.add_conditional_edges(\"leader\", lambda x: x[\"next\"], conditional_map)\n",
    "        # Finally, add entrypoint\n",
    "        workflow.set_entry_point(\"leader\")\n",
    "        graph = workflow.compile()\n",
    "        \n",
    "        return graph\n",
    "    \n",
    "    def optimise_prompt(self):\n",
    "        \"\"\"\n",
    "        Optimises a prompt by invoking a graph of worker agents.\n",
    "        \"\"\"\n",
    "        # Initial state\n",
    "        initial_state = {\n",
    "            \"messages\": [HumanMessage(content=f\"Base Prompt: {self.base_prompt}\", name=\"User\")],\n",
    "            \"prompt\": self.base_prompt,\n",
    "            \"next\": \"leader\",\n",
    "        }\n",
    "\n",
    "        # Construct the graph\n",
    "        graph = self.construct_team_graph()\n",
    "        # display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "        # Run the graph\n",
    "        for s in graph.stream(\n",
    "            initial_state,\n",
    "            {\"recursion_limit\": 50}\n",
    "            ):\n",
    "            if \"__end__\" not in s:\n",
    "                # print(s)\n",
    "                # print(\"----\")\n",
    "                continue\n",
    "\n",
    "        # if not os.path.exists(\"prompt_history_hierarchical.json\"):\n",
    "        #     with open(\"prompt_history_hierarchical.json\", \"w\") as f:\n",
    "        #         json.dump([], f)\n",
    "        \n",
    "        # with open(\"prompt_history_hierarchical.json\", \"r\") as f:\n",
    "        #     data = json.load(f)\n",
    "        #     data.append(self.prompt_history)\n",
    "            \n",
    "        # with open(\"prompt_history_hierarchical.json\", \"w\") as f:\n",
    "        #     json.dump(data, f, indent=4)\n",
    "                \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Mathematics Curriculum Specialist, Role: The Mathematics Curriculum Specialist is responsible for ensuring that the mathematical content of the prompt is accurate, appropriate for the intended audience, and aligns with educational standards., Function: The Mathematics Curriculum Specialist will review the mathematical problem to verify its correctness and relevance, ensuring that it involves only elementary arithmetic operations.\n",
      "Position: Prompt Clarity Analyst, Role: The Prompt Clarity Analyst is responsible for reviewing the prompt to ensure that it is clearly worded, unambiguous, and easy to understand for the target audience., Function: The Prompt Clarity Analyst will assess the language and structure of the prompt, providing feedback to make it as clear and straightforward as possible.\n",
      "Position: Educational Psychologist, Role: The Educational Psychologist is responsible for evaluating the prompt to ensure that it is cognitively appropriate for the target age group and that it promotes effective learning and problem-solving strategies., Function: The Educational Psychologist will analyze the prompt to ensure it is developmentally suitable and engaging for the intended audience, offering suggestions to enhance its educational value.\n",
      "----\n",
      "Mathematics team:\n",
      "Position: Mathematics Content Specialist, Role: The Mathematics Content Specialist is responsible for creating and reviewing mathematical problems and solutions to ensure they are accurate and clear., Function: The Mathematics Content Specialist will generate and validate the mathematical problems and solutions, ensuring they are correct and comprehensible.\n",
      "Position: Mathematics Curriculum Developer, Role: The Mathematics Curriculum Developer is responsible for designing and structuring mathematical prompts to align with educational standards and learning objectives., Function: The Mathematics Curriculum Developer will organize and structure the prompts to ensure they are pedagogically sound and aligned with curriculum standards.\n",
      "Position: Mathematics Quality Assurance Analyst, Role: The Mathematics Quality Assurance Analyst is responsible for verifying the correctness and clarity of mathematical prompts and solutions, ensuring they meet quality standards., Function: The Mathematics Quality Assurance Analyst will review the prompts and solutions for accuracy, clarity, and adherence to quality standards, providing feedback for improvement.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"\"\"Solve the following maths problem: {content}\"\"\"\n",
    "additional_info = \"The problem should only require elementary arithmetic operations. The output should be the answer only.\"\n",
    "\n",
    "leader_agent = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "\n",
    "# print teams and members\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = leader_agent.optimise_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Solve the following math problem using only addition, subtraction, multiplication, division, and parentheses: {content}. Negative numbers and decimals are permitted. Provide the answer as a single decimal number rounded to two decimal places. Do not show intermediate steps.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"leader\"][\"prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrent Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Prompt Engineering Specialist, Role: Design and refine prompts for optimal performance, Function: Develop and test various prompt structures\n",
      "Position: Sentiment Analysis Expert, Role: Ensure accurate classification of sentiment, Function: Review and fine-tune sentiment detection mechanisms\n",
      "Position: Natural Language Processing Scientist, Role: Implement advanced NLP techniques for prompt optimization, Function: Apply state-of-the-art NLP models and methods to enhance prompt effectiveness\n",
      "----\n",
      "generic team:\n",
      "Position: Natural Language Processing Specialist, Role: Develop and fine-tune NLP models, Function: Implement and refine machine learning models for text classification\n",
      "Position: Sentiment Analysis Expert, Role: Design sentiment classification algorithms, Function: Design and validate sentiment analysis methodologies to accurately classify text as positive or negative\n",
      "Position: Prompt Optimization Engineer, Role: Optimize prompt design and structure, Function: Ensure the prompt is general and robust, minimizing ambiguity and maximizing classification accuracy\n",
      "----\n",
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Prompt Engineer, Role: Design Efficient Prompts, Function: Create and refine the initial prompt to maximize clarity and effectiveness.\n",
      "Position: Sentiment Analysis Specialist, Role: Optimize Sentiment Classification, Function: Tailor prompts to encompass a broad range of positive and negative sentiments for better classification accuracy.\n",
      "Position: Linguistic Quality Controller, Role: Ensure Linguistic Accuracy, Function: Review and enhance the linguistic structure of the prompt for better generalization and minimal ambiguity.\n",
      "----\n",
      "general team:\n",
      "Position: Sentiment Analysis Specialist, Role: Design and validate sentiment classification models, Function: Develop algorithms to distinguish between positive and negative sentiments\n",
      "Position: Machine Learning Engineer, Role: Implement and optimize machine learning algorithms, Function: Ensure that the machine learning models are efficient and scalable\n",
      "Position: Data Scientist, Role: Analyze and preprocess data for model training and evaluation, Function: Collect, clean, and preprocess text data to enhance model accuracy\n",
      "----\n",
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Senior Prompt Engineer, Role: Designing and refining prompts, Function: Optimize prompts for clarity and efficiency\n",
      "Position: Natural Language Processing Specialist, Role: Enhancing language processing capabilities, Function: Develop algorithms to better interpret sentence context\n",
      "Position: Sentiment Analysis Expert, Role: Expertise in sentiment classification techniques, Function: Create robust classifiers to accurately determine sentiment\n",
      "----\n",
      "general team:\n",
      "Position: Sentiment Analysis Specialist, Role: Develop and refine sentiment classification algorithms, Function: Ensure high accuracy in distinguishing between positive and negative sentiments\n",
      "Position: Data Scientist, Role: Analyze and preprocess data to enhance model performance, Function: Implement data augmentation techniques and preprocess data to remove noise\n",
      "Position: Prompt Engineering Expert, Role: Design and optimize LLM prompts for accurate and generalizable classification, Function: Craft effective prompts and fine-tune them to work well across diverse datasets\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"Classify the sentence as positive or negative: {content}\"\n",
    "additional_info = \"This is a classification task with only two classes: positive and negative.\"\n",
    "\n",
    "leader_agent_1 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent_1.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")\n",
    "\n",
    "leader_agent_2 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent_2.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")\n",
    "\n",
    "leader_agent_3 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent_3.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentence as positive or negative: {content}\n",
      "----\n",
      "Classify the sentiment of the following sentence into one of two categories: 'positive' or 'negative'. Focus on the context and nuances of the content provided to determine the sentiment accurately. Provide your classification based on the overall sentiment conveyed by the sentence. Sentence: {content}\n",
      "----\n",
      "Classify the sentence provided in {content} as either 'positive' or 'negative' based on its sentiment. For this task, 'positive' sentiment indicates expressions of happiness, approval, or any favorable emotions, while 'negative' sentiment denotes expressions of sadness, disapproval, or any unfavorable emotions. Ensure the classification is strictly 'positive' or 'negative' and do not consider any ambiguous sentiments.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming leader_agent is already defined and initialized\n",
    "def run_optimisation(agent: LeaderAgent):\n",
    "    return agent.optimise_prompt()\n",
    "\n",
    "# Run 3 concurrent instances\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(run_optimisation, agent) for agent in [leader_agent_1, leader_agent_2, leader_agent_3]]\n",
    "    results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    print(\"----\")\n",
    "\n",
    "class PromptMerge(BaseModel):\n",
    "    \"\"\"Merged prompt based on the best parts of each prompt.\"\"\"\n",
    "    final_prompt: str = Field(description=\"Result of merging prompts\")\n",
    "\n",
    "# OpenAI Agent to pull togther best parts of each result\n",
    "def merge_results(results):\n",
    "    \"\"\"\n",
    "    Agent to merge best parts of each prompt\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=1.0,\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    system_message = \"\"\"You are an experienced AI prompt engineer. Your role is to combine prompts to create a more effective prompt.\n",
    "You have in-depth knowledge regarding large language models and their associated architectures, as well as prompt engineering best practices.\"\"\"\n",
    "\n",
    "    template = \"\"\"I am going to tip $300K for a better prompt!\n",
    "Given the prompts below, your task is to merge the best parts of each prompt to create the most effective prompt.\n",
    "Carefully consider the strengths of each prompt and how they can be combined to create a better prompt.\n",
    "Aspects of the prompts to consider:\n",
    "- Conciseness and clarity\n",
    "- Contextual relevance\n",
    "- Task alignment\n",
    "- Example Demonstrations\n",
    "- Avoiding bias\n",
    "- Incremental prompting\n",
    "Placeholders are notated using curly braces. You must not remove placeholders or add additional placeholders.\n",
    "I repeat, you must not remove placeholders or add additional placeholders.\n",
    "Do not make assumptions on what the placeholders represent.\n",
    "You will be penalized if the prompt is repetitive, lacks clarity or is incoherent.\n",
    "Ensure that your answer is unbiased.\n",
    "\n",
    "Prompts: {results}\n",
    "\n",
    "Return only the next worker to process or 'FINISH' in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"final_prompt\": \"Result of merging prompts\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "    pydantic_parser = PydanticOutputParser(pydantic_object=PromptMerge)\n",
    "    prompt_template = PromptTemplate(\n",
    "        system_message=system_message,\n",
    "        template=template,\n",
    "        input_variables=[\"results\"],\n",
    "        partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "    )\n",
    "    chain = prompt_template | llm | pydantic_parser\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            output = chain.invoke({\"results\": results})\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"Exception occurred:\", e)\n",
    "            continue\n",
    "    return output.final_prompt\n",
    "\n",
    "final_result = merge_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentiment of the following sentence into one of two categories: 'positive' or 'negative'. Focus on the context and nuances of the content provided to determine the sentiment accurately. For this task, 'positive' sentiment indicates expressions of happiness, approval, or any favorable emotions, while 'negative' sentiment denotes expressions of sadness, disapproval, or any unfavorable emotions. Ensure the classification is strictly 'positive' or 'negative' and do not consider any ambiguous sentiments. Sentence: {content}\n"
     ]
    }
   ],
   "source": [
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

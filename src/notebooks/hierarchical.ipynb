{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import List, Sequence, TypedDict, Annotated\n",
    "import json\n",
    "import os\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = \"Hierarchical Optimisation\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptReview(BaseModel):\n",
    "    \"\"\"Review of the prompt\"\"\"\n",
    "    feedback: str = Field(description=\"Feedback on the most recent prompt\")\n",
    "\n",
    "\n",
    "class WorkerAgent:\n",
    "    \"\"\"\n",
    "    Worker Agent class defining agents that provide feedback on prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, position: str, role: str, function: str, temp: float = 0.0, model: str = \"gpt-4o\"):\n",
    "        self.position = position\n",
    "        self.role = role\n",
    "        self.function = function\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an expert: {self.position}. Your role: {self.role}. Your function: {self.function}.\n",
    "You must use your expertise to guide all your thinking. You must speak only as an expert in your field.\"\"\")        \n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "\n",
    "    def generate(self, prompt: str, additional_info: str) -> PromptReview:\n",
    "        \"\"\"\n",
    "        Generates a review of the prompt.\n",
    "        \"\"\"\n",
    "        template = \"\"\"I'm going to tip $300K for feedback that results in the most improvement to the prompt.\n",
    "Your task is to provide detailed feedback and recommendations on the prompt below.\n",
    "Think about how you can utilise the skills that come with your position, role and function to write a prompt good at eliciting the desired response.\n",
    "\n",
    "### Prompt: {prompt}\n",
    "\n",
    "{additional_info}\n",
    "Only provide feedback and recommendations for the prompt.\n",
    "Your feedback must be less than 50 words so think carefully about the most critical aspects of the prompt that need improvement.\n",
    "Do not provide feedback regarding the placeholder text and do not make assumptions on what the placeholders represent.\n",
    "\n",
    "Return only the original prompt and your feedback in JSON fromat below:\n",
    "\n",
    "{{\n",
    "    \"feedback\": \"Feedback on the original prompt\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=PromptReview)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"position\", \"role\", \"function\", \"prompt\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                completion = chain.invoke({\"position\": self.position, \"role\": self.role, \"function\": self.function, \"prompt\": prompt, \"additional_info\": additional_info})\n",
    "                # Validate the output before returning\n",
    "                if completion.feedback:\n",
    "                    return completion\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", completion)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        else:\n",
    "            raise Exception(\"Failed to parse output after 3 attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Workforce(BaseModel):\n",
    "    \"\"\"Details of workforce generated by the leader agent.\"\"\"\n",
    "    positions: List[str] = Field(description=\"Positions of the workers in the workforce\")\n",
    "    roles: List[str] = Field(description=\"Roles of the workers in the workforce\")\n",
    "    functions: List[str] = Field(description=\"Functions of the workers in the workforce\")\n",
    "    \n",
    "\n",
    "class FeedbackSummary(BaseModel):\n",
    "    \"\"\"Summary of feedback from the worker agents.\"\"\"\n",
    "    feedback_summary: str = Field(description=\"Collated and summarised feedback from the workforce\")\n",
    "\n",
    "\n",
    "class ApprovalDecision(BaseModel):\n",
    "    \"\"\"Decision of the leader agent to approve or disapprove the prompt.\"\"\"\n",
    "    approved: bool = Field(description=\"Decision to approve or disapprove the prompt\")\n",
    "\n",
    "\n",
    "class TeamLeaderAgent:\n",
    "    \"\"\"\n",
    "    TeamLeaderAgent class defining an agent that manages a team of worker agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, team: str, team_role: str, prompt: str, additional_info: str = None, temp: float = 0.0, model: str = \"gpt-4o\", workforce: List[WorkerAgent] = None):\n",
    "        self.team = team\n",
    "        self.team_role = team_role\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an experienced {team} team leader with expertise in leading a team with the role: {team_role}. \n",
    "You must use your expertise to guide all your thinking. You must speak only as an expert in your field.\"\"\")\n",
    "        self.prompt = prompt\n",
    "        self.additional_info = additional_info\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "        self.workforce = workforce if workforce else self.generate_workforce()\n",
    "        # self.feedback = []\n",
    "        # self.graph = None\n",
    "\n",
    "    def generate_workforce(self):\n",
    "        \"\"\"\n",
    "        Generates a workforce to help optimise prompts.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Your task is to generate a {team} team consisting of three experts to provide feedback on prompts.\n",
    "    \n",
    "### Prompt:  {base_prompt}\n",
    "\n",
    "The experts must be relevant to the {team} team.\n",
    "You must provide the positions, roles, and functions of the experts.\n",
    "Be descriptive and detailed in your selection of positions, roles, and functions.\n",
    "Below are the requirements for each field:\n",
    "- Position: this must be analogous to a real-world job title.\n",
    "- Role: this must be a description of the expert's responsibilities in the context of prompt optimisation.\n",
    "- Function: this must be a description of the expert's function in the context of prompt optimisation.\n",
    "Write the roles and functions as if they are a job description.\n",
    "\n",
    "{additional_info}\n",
    "\n",
    "Return only the positions, roles, and functions of the workers in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"positions\": [\"List of positions\"],\n",
    "    \"roles\": [\"List of roles\"],\n",
    "    \"functions\": [\"List of functions\"]\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=Workforce)\n",
    "        prompt = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"team\", \"base_prompt\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"team\": self.team, \"base_prompt\": self.prompt, \"additional_info\": self.additional_info})\n",
    "                if output.positions and output.roles and output.functions:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        workforce = []\n",
    "        positions, roles, functions = output.positions, output.roles, output.functions\n",
    "        for position, role, function in zip(positions, roles, functions):\n",
    "            workforce.append(WorkerAgent(position, role, function))\n",
    "        return workforce\n",
    "\n",
    "    def leader_feedback(self, feedback: list) -> str:\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next worker or to finish.\n",
    "        \"\"\"\n",
    "        # All workers except the current worker\n",
    "        template = \"\"\"Your task is to summarise the feedback below.\n",
    "Your summary must be less than 50 words so think carefully about how the feedback can be summarised effectively.\n",
    "You must capture the important aspects of the feedback and recommendations provided by the workers whilst being concise.\n",
    "Your superior will act on this feedback to optimise a prompt so ensure your summary is clear and actionable.\n",
    "\n",
    "Feedback: {feedback}\n",
    "\n",
    "Return only the feedback summary in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"feedback_summary\": \"Feedback summary\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=FeedbackSummary)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"feedback\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"feedback\": feedback})\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        return output.feedback_summary\n",
    "   \n",
    "    # def construct_worker_graph(self):\n",
    "    #     \"\"\"\n",
    "    #     Constructs a graph of worker agents based on their roles and functions.\n",
    "    #     \"\"\"    \n",
    "    #     def agent_node(state, agent, position):\n",
    "    #         try:\n",
    "    #             result = agent.generate(state[\"prompt\"], self.additional_info)\n",
    "    #             self.feedback.append(result.feedback)\n",
    "    #             return {\n",
    "    #                 \"messages\": state[\"messages\"] + [HumanMessage(content=f\"Feedback from {position} received\")],\n",
    "    #                 \"feedback\": self.feedback,\n",
    "    #             }\n",
    "    #         except Exception as e:\n",
    "    #             # Log the error and return to leader with the most recent prompt\n",
    "    #             print(f\"Parsing failed for {position}: {e}\")\n",
    "    #             return {\n",
    "    #                 \"messages\": state[\"messages\"] + [HumanMessage(content=f\"No feedback from {position} received\")],\n",
    "    #                 \"feedback\": self.feedback,\n",
    "    #             }\n",
    "        \n",
    "    #     # The agent state is the input to each node in the graph\n",
    "    #     class TeamState(TypedDict):\n",
    "    #         # The annotation tells the graph that new messages will always be added to the current states\n",
    "    #         messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    #         prompt: str\n",
    "    #         next: str\n",
    "    #         feedback: str\n",
    "\n",
    "    #     workflow = StateGraph(TeamState)\n",
    "    #     for worker in self.workforce:\n",
    "    #         # Create a node for each worker agent\n",
    "    #         agent = WorkerAgent(worker.position, worker.role, worker.function)\n",
    "    #         node = functools.partial(agent_node, agent=agent, position=worker.position)\n",
    "    #         workflow.add_node(worker.position, node)\n",
    "    #     workflow.add_node(\"leader\", self.leader_feedback)\n",
    "\n",
    "    #     # implement round robin among the workers finishing with the leader\n",
    "    #     for i in range(len(self.workforce)-1):\n",
    "    #         workflow.add_edge(self.workforce[i].position, self.workforce[i+1].position)\n",
    "    #     workflow.add_edge(self.workforce[-1].position, \"leader\")\n",
    "    #     workflow.add_edge(\"leader\", END)\n",
    "    #     workflow.set_entry_point(self.workforce[0].position)\n",
    "    #     self.graph = workflow.compile()\n",
    "\n",
    "    # def optimise_prompt(self, prompt: str):\n",
    "    #     \"\"\"\n",
    "    #     Optimises the prompt by managing a workforce of worker agents.\n",
    "    #     \"\"\"\n",
    "    #     self.prompt = prompt\n",
    "    #     initial_state = {\n",
    "    #         \"messages\": [self.system_message],\n",
    "    #         \"prompt\": self.prompt,\n",
    "    #         \"next\": self.workforce[0].position,\n",
    "    #         \"feedback\": [],\n",
    "    #     }\n",
    "        \n",
    "    #     for s in self.graph.stream(\n",
    "    #         initial_state,\n",
    "    #         {\"recursion_limit\": 50}\n",
    "    #         ):\n",
    "    #         if \"__end__\" not in s:\n",
    "    #             continue               \n",
    "\n",
    "    #     return s[\"feedback\"]\n",
    "    \n",
    "    def get_feedback(self):\n",
    "        \"\"\"\n",
    "        Get feedback from wokers. Feedback collected concurrently.\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "            futures = [executor.submit(worker.generate, self.prompt, self.additional_info) for worker in self.workforce]\n",
    "            results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "            feedback = [result.feedback for result in results]\n",
    "\n",
    "        summary = self.leader_feedback(feedback)\n",
    "\n",
    "        return summary\n",
    "    \n",
    "    def get_approval(self, prompt: str):\n",
    "        \"\"\"\n",
    "        Agent to approve or reject the prompt.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Your task is to review the prompt below and provide your approval or disapproval.\n",
    "You must consider the prompt in light of your team and team role.\n",
    "\n",
    "### Prompt: {prompt}\n",
    "\n",
    "Do you approve or disapprove of the prompt?\n",
    "Select one of: 'True' or 'False'\n",
    "\n",
    "Return only the approval decision in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"approved\": \"True if approved or False otherwise\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=ApprovalDecision)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"prompt\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                completion = chain.invoke({\"prompt\": prompt})\n",
    "                # Validate the output before returning\n",
    "                if completion.approved is not None:\n",
    "                    return completion.approved\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", completion)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        else:\n",
    "            raise Exception(\"Failed to parse output after 3 attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Domain(BaseModel):\n",
    "    \"\"\"Domain of the prompt.\"\"\"\n",
    "    domain: str = Field(description=\"Domain of the prompt\")\n",
    "    description: str = Field(description=\"Description of the domain team role\")\n",
    "\n",
    "\n",
    "class RouteDecision(BaseModel):\n",
    "    \"\"\"Decision on the next worker to process or to finish.\"\"\"\n",
    "    next: str = Field(description=\"The next worker to process or 'FINISH' to end the process\")\n",
    "\n",
    "\n",
    "class UpdatedPrompt(BaseModel):\n",
    "    \"\"\"Updated prompt based on feedback from the worker agent.\"\"\"\n",
    "    updated_prompt: str = Field(description=\"Updated prompt based on feedback from the worker agent\")\n",
    "\n",
    "\n",
    "class LeaderAgent:\n",
    "    \"\"\"\n",
    "    LeaderAgent class defining an agent that generates and communicates worker agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_prompt: str, additional_info: str = None, temp: float = 0.0, model: str = \"gpt-4o\", team_leaders: List[TeamLeaderAgent] = None):\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an experienced senior AI professional. You specialise in prompt engineering. \n",
    "You have in-depth knowledge of large language models and prompt engineering best practices. Use this knowledge to inform all your decisions.\"\"\")\n",
    "        self.base_prompt = base_prompt\n",
    "        self.prompt = base_prompt\n",
    "        self.additional_info = additional_info\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "        self.team_leaders = self.generate_teams() if not team_leaders else team_leaders\n",
    "        self.team_roles_dict = {team_leader.team: team_leader.team_role for team_leader in self.team_leaders}\n",
    "\n",
    "    def generate_teams(self):\n",
    "        \"\"\"\n",
    "        Generates a workforce to help optimise prompts.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Identify the domain of the prompt below to help generate a team of domain experts to optimise the prompt.\n",
    "You must provide a detailed description of the domain team role. The description should begin \"Formulate prompts and instructions to ...\".\n",
    "\n",
    "LLM Prompt: {base_prompt}\n",
    "\n",
    "{additional_info}\n",
    "\n",
    "Return only the domain and the description of the prompt in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"domain\": \"Domain\",\n",
    "    \"description\": \"Description of the domain team role\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=Domain)\n",
    "        prompt = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"base_prompt\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"base_prompt\": self.base_prompt, \"additional_info\": self.additional_info})\n",
    "                if output.domain and output.description:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        domain = output.domain\n",
    "        description = output.description\n",
    "        # Generate team leaders for the AI prompt experts and domain experts\n",
    "        ai_team = TeamLeaderAgent(\"Prompt Design\",\n",
    "                                  \"Formulate prompts and instructions to elicit high-quality responses from large language models.\", \n",
    "                                  self.base_prompt, self.additional_info)\n",
    "        domain_team = TeamLeaderAgent(domain, description, self.base_prompt, self.additional_info)\n",
    "        return [ai_team, domain_team]\n",
    "    \n",
    "    def run_approval(self, prompt: str) -> List[bool]:\n",
    "        \"\"\"\n",
    "        Run the approval process for the prompt. Run concurrently\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(team_leader.get_approval, prompt) for team_leader in self.team_leaders]\n",
    "            results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "        return results\n",
    "    \n",
    "    def leader_decision(self, state: dict) -> RouteDecision:\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next worker or to finish.\n",
    "        \"\"\"\n",
    "        import random\n",
    "        approval_results = self.run_approval(state[\"prompt\"])\n",
    "        print(\"Approval results:\", approval_results)\n",
    "        if all(approval_results):\n",
    "            return {\"next\": \"FINISH\", \"prompt\": state[\"prompt\"], \"messages\": state[\"messages\"]} \n",
    "        else:\n",
    "            disapproved_team_leaders = [team_leader for i, team_leader in enumerate(self.team_leaders) if not approval_results[i]]\n",
    "            options = [team_leaders.team for team_leaders in disapproved_team_leaders]\n",
    "            # shuffle options to avoid positional bias\n",
    "            random.shuffle(options)\n",
    "            # options = [\"FINISH\"] + members\n",
    "            template = \"\"\"Your task is to review the prompt below and decide the next team to process.\n",
    "\n",
    "### Prompt: {prompt}\n",
    "\n",
    "Who should act next? The details of the teams are as follows:\n",
    "{team_roles}\n",
    "\n",
    "Select one of: {options}\n",
    "\n",
    "Return only the next team to process in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"next\": \"Next team\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "            pydantic_parser = PydanticOutputParser(pydantic_object=RouteDecision)\n",
    "            prompt_template = PromptTemplate(\n",
    "                system_message=self.system_message,\n",
    "                template=template,\n",
    "                input_variables=[\"prompt\", \"team_roles\", \"options\"],\n",
    "                partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "            )\n",
    "            chain = prompt_template | self.llm | pydantic_parser\n",
    "            for _ in range(3):\n",
    "                try:\n",
    "                    output = chain.invoke({\"prompt\": state[\"prompt\"], \"team_roles\": str(self.team_roles_dict), \"options\": str(options)})\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(\"Exception occurred:\", e)\n",
    "                    continue\n",
    "            return {\"next\": output.next, \"prompt\": state[\"prompt\"], \"messages\": state[\"messages\"]}\n",
    "\n",
    "    def update_prompt(self, prompt: str, feedback: str, history) -> str:\n",
    "        \"\"\"\n",
    "        Updates the prompt with the feedback from the worker agent.\n",
    "        \"\"\"\n",
    "        template = \"\"\"I'm going to tip $300K for a prompt that best instructs a large language model!\n",
    "Your task is to update the prompt below based on the feedback provided. \n",
    "You must also consider the discussion history prior to making changes to the prompt to ensure you do not repeat any mistakes. \n",
    "{additional_info}\n",
    "\n",
    "### Prompt: {prompt}\n",
    "### Feedback: {feedback}\n",
    "### Discussion History: {history}\n",
    "\n",
    "**Strict guidelines:**\n",
    "1. All restrictions already stated in the text being reviewed should not be modified.\n",
    "2. All negations should be preserved. e.g. \"DO NOT\" should not be changed to \"DO\" or removed entirely.\n",
    "3. All placeholders denoted by curly braces should not be modified or removed.\n",
    "4. Adding additional restrictions or negations is allowed.\n",
    "5. Adding additional placeholders is not allowed.\n",
    "6. Adding additional instructions is allowed.\n",
    "You will be penalized if you do not follow these guidelines.\n",
    "\n",
    "Return only the updated prompt in JSON format:\n",
    "\n",
    "{{\n",
    "    \"prompt\": \"Updated prompt\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=UpdatedPrompt)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"prompt\", \"feedback\", \"history\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"prompt\": prompt, \"feedback\": feedback, \"history\": history, \"additional_info\": self.additional_info})\n",
    "                if output.updated_prompt:\n",
    "                    return output.updated_prompt\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", output)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "\n",
    "    def construct_team_graph(self):\n",
    "        \"\"\"\n",
    "        Constructs a graph of team leader agents.\n",
    "        \"\"\"\n",
    "        \n",
    "        # The agent state is the input to each node in the graph\n",
    "        class TeamState(TypedDict):\n",
    "            # The annotation tells the graph that new messages will always be added to the current states\n",
    "            messages: Sequence[BaseMessage]\n",
    "            prompt: str\n",
    "            next: str\n",
    "\n",
    "        def team_node(state, team_leader):\n",
    "            try:\n",
    "                feedback = team_leader.get_feedback()\n",
    "                updated_prompt = self.update_prompt(state[\"prompt\"], feedback, state[\"messages\"])\n",
    "                self.prompt = updated_prompt\n",
    "                return {\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(content=f\"Feedback: {feedback}\", name=team_leader.team),\n",
    "                        AIMessage(content=f\"Updated Prompt: {updated_prompt}\", name=\"Leader\")\n",
    "                    ],\n",
    "                    \"prompt\": updated_prompt,\n",
    "                }\n",
    "            except Exception as e:\n",
    "                # Log the error and return to leader with the most recent prompt\n",
    "                print(f\"Parsing failed for {team_leader.team}: {e}\")\n",
    "                return {\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(content=f\"Error: Parsing failed for {team_leader} - {e}\", name=team_leader.team),\n",
    "                        AIMessage(content=f\"Updated Prompt: {updated_prompt}\", name=\"Leader\")\n",
    "                    ],                    \n",
    "                    \"prompt\": state[\"prompt\"],\n",
    "                    \"next\": \"leader\",\n",
    "                }\n",
    "\n",
    "        workflow = StateGraph(TeamState)\n",
    "        for team_leader in self.team_leaders:\n",
    "            # Create a node for each team leader agent\n",
    "            # team_leader.construct_worker_graph()\n",
    "            node = functools.partial(team_node, team_leader=team_leader)\n",
    "            workflow.add_node(team_leader.team, node)\n",
    "        workflow.add_node(\"leader\", self.leader_decision)\n",
    "\n",
    "        members = [team_leader.team for team_leader in self.team_leaders]\n",
    "        for member in members:\n",
    "            # We want our workers to ALWAYS \"report back\" to the leader when done\n",
    "            workflow.add_edge(member, \"leader\")\n",
    "        # The leader populates the \"next\" field in the graph state with routes to a node or finishes\n",
    "        conditional_map = {k: k for k in members}\n",
    "        conditional_map[\"FINISH\"] = END\n",
    "        workflow.add_conditional_edges(\"leader\", lambda x: x[\"next\"], conditional_map)\n",
    "        # Finally, add entrypoint\n",
    "        workflow.set_entry_point(\"leader\")\n",
    "        graph = workflow.compile()\n",
    "        \n",
    "        return graph\n",
    "    \n",
    "    def optimise_prompt(self):\n",
    "        \"\"\"\n",
    "        Optimises a prompt by invoking a graph of worker agents.\n",
    "        \"\"\"\n",
    "        # Initial state\n",
    "        initial_state = {\n",
    "            \"messages\": [HumanMessage(content=f\"Base Prompt: {self.base_prompt}\", name=\"User\")],\n",
    "            \"prompt\": self.base_prompt,\n",
    "            \"next\": \"leader\",\n",
    "        }\n",
    "\n",
    "        # Construct the graph\n",
    "        graph = self.construct_team_graph()\n",
    "        # display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "        # Run the graph\n",
    "        for s in graph.stream(\n",
    "            initial_state,\n",
    "            {\"recursion_limit\": 50}\n",
    "            ):\n",
    "            if \"__end__\" not in s:\n",
    "                print(s)\n",
    "                print(\"----\")\n",
    "                continue\n",
    "\n",
    "        # if not os.path.exists(\"prompt_history_hierarchical.json\"):\n",
    "        #     with open(\"prompt_history_hierarchical.json\", \"w\") as f:\n",
    "        #         json.dump([], f)\n",
    "        \n",
    "        # with open(\"prompt_history_hierarchical.json\", \"r\") as f:\n",
    "        #     data = json.load(f)\n",
    "        #     data.append(self.prompt_history)\n",
    "            \n",
    "        # with open(\"prompt_history_hierarchical.json\", \"w\") as f:\n",
    "        #     json.dump(data, f, indent=4)\n",
    "                \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt design team members\n",
    "conciseness_and_clarity = {\n",
    "    \"position\": \"Conciseness and Clarity\", \n",
    "    \"role\": \"Analyze for conciseness and clarity\",\n",
    "    \"function\": \"Determine how the prompt can be more concise and clear in its instructions and avoid unnecessary information that does not contribute to the task while being specific enough to guide the model.\"\n",
    "}\n",
    "\n",
    "contextual_relevance = {\n",
    "    \"position\": \"Contextual Relevance\", \n",
    "    \"role\": \"Analyze for contextual relevance\",\n",
    "    \"function\": \"Determine how the prompt can better provide relevant context that helps the model understand the background and domain of the task\"\n",
    "}\n",
    "\n",
    "task_alignment = {\n",
    "    \"position\": \"Task Alignment\", \n",
    "    \"role\": \"Analyze for task alignment\",\n",
    "    \"function\": \"Determine how the prompt can better align with the task and use using language and structure that clearly indicate the nature of the task to the model.\"\n",
    "}\n",
    "\n",
    "example_demonstration = {\n",
    "    \"position\": \"Example Demonstration\", \n",
    "    \"role\": \"Analyze for example demonstration\",\n",
    "    \"function\": \"Determine how the prompt can better provide examples that demonstrate the expected output or behavior of the model.\"\n",
    "}\n",
    "\n",
    "avoiding_bias = {\n",
    "    \"position\": \"Avoiding Bias\", \n",
    "    \"role\": \"Analyze for bias\",\n",
    "    \"function\": \"Determine how the prompt can minimize the activation of biases inherent in the model due to its training data. This involves using neutral language and being mindful of potential ethical implications, especially for sensitive topics.\"\n",
    "}\n",
    "\n",
    "incremental_pormpting = {\n",
    "    \"position\": \"Incremental Prompting\", \n",
    "    \"role\": \"Analyze for incremental prompting\",\n",
    "    \"function\": \"Determine how the prompt can be structured in a way that guides the model through a series of steps or questions to help it generate the desired output.\"\n",
    "}\n",
    "\n",
    "programming_logic = {\n",
    "    \"position\": \"Programming Logic\", \n",
    "    \"role\": \"Analyze for programming logic\",\n",
    "    \"function\": \"Determine how the prompt can better incorporate and enforce programming logic concepts to help solve complex problems. For instance, use of conditional statements, logical operators, or even pseudo-code within the prompt to guide the model’s reasoning process.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain team members\n",
    "sentiment_analyst = {\n",
    "    \"position\": \"Sentiment Analyst\", \n",
    "    \"role\": \"Analyze for sentiment\",\n",
    "    \"function\": \"Determine how the prompt can be improved to better instruct a model to identify sentiment, tone, and emotion in text.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams and members:\n",
      "Prompt Design team:\n",
      "Team Role: Formulate prompts and instructions to elicit high-quality responses from large language models.\n",
      "Position: Conciseness and Clarity, Role: Analyze for conciseness and clarity, Function: Determine how the prompt can be more concise and clear in its instructions and avoid unnecessary information that does not contribute to the task while being specific enough to guide the model.\n",
      "Position: Contextual Relevance, Role: Analyze for contextual relevance, Function: Determine how the prompt can better provide relevant context that helps the model understand the background and domain of the task\n",
      "Position: Task Alignment, Role: Analyze for task alignment, Function: Determine how the prompt can better align with the task and use using language and structure that clearly indicate the nature of the task to the model.\n",
      "Position: Example Demonstration, Role: Analyze for example demonstration, Function: Determine how the prompt can better provide examples that demonstrate the expected output or behavior of the model.\n",
      "Position: Avoiding Bias, Role: Analyze for bias, Function: Determine how the prompt can minimize the activation of biases inherent in the model due to its training data. This involves using neutral language and being mindful of potential ethical implications, especially for sensitive topics.\n",
      "Position: Incremental Prompting, Role: Analyze for incremental prompting, Function: Determine how the prompt can be structured in a way that guides the model through a series of steps or questions to help it generate the desired output.\n",
      "Position: Programming Logic, Role: Analyze for programming logic, Function: Determine how the prompt can better incorporate and enforce programming logic concepts to help solve complex problems. For instance, use of conditional statements, logical operators, or even pseudo-code within the prompt to guide the model’s reasoning process.\n",
      "----\n",
      "Sentiment Analysis team:\n",
      "Team Role: Formulate prompts and instructions to elicit sentiment analysis from large language models.\n",
      "Position: Sentiment Analyst, Role: Analyze for sentiment, Function: Determine how the prompt can be improved to better instruct a model to identify sentiment, tone, and emotion in text.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'.\"\n",
    "additional_info = \"\"\n",
    "\n",
    "prompt_design_team = TeamLeaderAgent(\n",
    "    \"Prompt Design\",\n",
    "    \"Formulate prompts and instructions to elicit high-quality responses from large language models.\",\n",
    "    base_prompt,\n",
    "    additional_info,\n",
    "    workforce=[\n",
    "        WorkerAgent(**conciseness_and_clarity),\n",
    "        WorkerAgent(**contextual_relevance),\n",
    "        WorkerAgent(**task_alignment),\n",
    "        WorkerAgent(**example_demonstration),\n",
    "        WorkerAgent(**avoiding_bias),\n",
    "        WorkerAgent(**incremental_pormpting),\n",
    "        WorkerAgent(**programming_logic),\n",
    "    ]\n",
    ")\n",
    "domain_team = TeamLeaderAgent(\n",
    "    \"Sentiment Analysis\",\n",
    "    \"Formulate prompts and instructions to elicit sentiment analysis from large language models.\",\n",
    "    base_prompt,\n",
    "    additional_info,\n",
    "    workforce=[\n",
    "        WorkerAgent(**sentiment_analyst),\n",
    "    ]\n",
    ")\n",
    "\n",
    "leader_agent = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    "    team_leaders=[prompt_design_team, domain_team]\n",
    ")\n",
    "\n",
    "# print teams and members\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    print(f\"Team Role: {team_leader.team_role}\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approval results: [False, True]\n",
      "{'leader': {'messages': [HumanMessage(content=\"Base Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'.\", name='User')], 'prompt': \"Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'.\", 'next': 'Sentiment Analysis'}}\n",
      "----\n",
      "{'Sentiment Analysis': {'messages': [HumanMessage(content=\"Base Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'.\", name='User'), HumanMessage(content='Feedback: Clarify handling of neutral sentiments and specify need for context or additional information for accurate sentiment analysis.', name='Sentiment Analysis'), AIMessage(content=\"Updated Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. Consider the context or additional information if necessary for accurate sentiment analysis.\", name='Leader')], 'prompt': \"Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. Consider the context or additional information if necessary for accurate sentiment analysis.\"}}\n",
      "----\n",
      "Approval results: [False, False]\n",
      "{'leader': {'messages': [HumanMessage(content=\"Base Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'.\", name='User'), HumanMessage(content='Feedback: Clarify handling of neutral sentiments and specify need for context or additional information for accurate sentiment analysis.', name='Sentiment Analysis'), AIMessage(content=\"Updated Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. Consider the context or additional information if necessary for accurate sentiment analysis.\", name='Leader')], 'prompt': \"Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. Consider the context or additional information if necessary for accurate sentiment analysis.\", 'next': 'Sentiment Analysis'}}\n",
      "----\n",
      "{'Sentiment Analysis': {'messages': [HumanMessage(content=\"Base Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'.\", name='User'), HumanMessage(content='Feedback: Clarify handling of neutral sentiments and specify need for context or additional information for accurate sentiment analysis.', name='Sentiment Analysis'), AIMessage(content=\"Updated Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. Consider the context or additional information if necessary for accurate sentiment analysis.\", name='Leader'), HumanMessage(content='Feedback: Clarify classification of neutral sentiments and handling of ambiguous or mixed sentiments.', name='Sentiment Analysis'), AIMessage(content=\"Updated Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. For ambiguous or mixed sentiments, consider the overall tone and context to make a determination. Consider the context or additional information if necessary for accurate sentiment analysis.\", name='Leader')], 'prompt': \"Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. For ambiguous or mixed sentiments, consider the overall tone and context to make a determination. Consider the context or additional information if necessary for accurate sentiment analysis.\"}}\n",
      "----\n",
      "Approval results: [True, False]\n",
      "{'leader': {'messages': [HumanMessage(content=\"Base Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'.\", name='User'), HumanMessage(content='Feedback: Clarify handling of neutral sentiments and specify need for context or additional information for accurate sentiment analysis.', name='Sentiment Analysis'), AIMessage(content=\"Updated Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. Consider the context or additional information if necessary for accurate sentiment analysis.\", name='Leader'), HumanMessage(content='Feedback: Clarify classification of neutral sentiments and handling of ambiguous or mixed sentiments.', name='Sentiment Analysis'), AIMessage(content=\"Updated Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. For ambiguous or mixed sentiments, consider the overall tone and context to make a determination. Consider the context or additional information if necessary for accurate sentiment analysis.\", name='Leader')], 'prompt': \"Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. For ambiguous or mixed sentiments, consider the overall tone and context to make a determination. Consider the context or additional information if necessary for accurate sentiment analysis.\", 'next': 'Sentiment Analysis'}}\n",
      "----\n",
      "{'Sentiment Analysis': {'messages': [HumanMessage(content=\"Base Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'.\", name='User'), HumanMessage(content='Feedback: Clarify handling of neutral sentiments and specify need for context or additional information for accurate sentiment analysis.', name='Sentiment Analysis'), AIMessage(content=\"Updated Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. Consider the context or additional information if necessary for accurate sentiment analysis.\", name='Leader'), HumanMessage(content='Feedback: Clarify classification of neutral sentiments and handling of ambiguous or mixed sentiments.', name='Sentiment Analysis'), AIMessage(content=\"Updated Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. For ambiguous or mixed sentiments, consider the overall tone and context to make a determination. Consider the context or additional information if necessary for accurate sentiment analysis.\", name='Leader'), HumanMessage(content='Feedback: Clarify handling of neutral and ambiguous sentiments, and specify the expected response format.', name='Sentiment Analysis'), AIMessage(content=\"Updated Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. For ambiguous or mixed sentiments, consider the overall tone and context to make a determination. Consider the context or additional information if necessary for accurate sentiment analysis. The expected response format is a single word: either 'positive' or 'negative'.\", name='Leader')], 'prompt': \"Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. For ambiguous or mixed sentiments, consider the overall tone and context to make a determination. Consider the context or additional information if necessary for accurate sentiment analysis. The expected response format is a single word: either 'positive' or 'negative'.\"}}\n",
      "----\n",
      "Approval results: [True, True]\n",
      "{'leader': {'messages': [HumanMessage(content=\"Base Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'.\", name='User'), HumanMessage(content='Feedback: Clarify handling of neutral sentiments and specify need for context or additional information for accurate sentiment analysis.', name='Sentiment Analysis'), AIMessage(content=\"Updated Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. Consider the context or additional information if necessary for accurate sentiment analysis.\", name='Leader'), HumanMessage(content='Feedback: Clarify classification of neutral sentiments and handling of ambiguous or mixed sentiments.', name='Sentiment Analysis'), AIMessage(content=\"Updated Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. For ambiguous or mixed sentiments, consider the overall tone and context to make a determination. Consider the context or additional information if necessary for accurate sentiment analysis.\", name='Leader'), HumanMessage(content='Feedback: Clarify handling of neutral and ambiguous sentiments, and specify the expected response format.', name='Sentiment Analysis'), AIMessage(content=\"Updated Prompt: Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. For ambiguous or mixed sentiments, consider the overall tone and context to make a determination. Consider the context or additional information if necessary for accurate sentiment analysis. The expected response format is a single word: either 'positive' or 'negative'.\", name='Leader')], 'prompt': \"Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. For ambiguous or mixed sentiments, consider the overall tone and context to make a determination. Consider the context or additional information if necessary for accurate sentiment analysis. The expected response format is a single word: either 'positive' or 'negative'.\", 'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "result = leader_agent.optimise_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Determine whether the following sentence is positive or negative in sentiment: {content}. You must return only either 'positive' or 'negative'. If the sentiment is neutral, you must still choose between 'positive' or 'negative' based on the closest sentiment. For ambiguous or mixed sentiments, consider the overall tone and context to make a determination. Consider the context or additional information if necessary for accurate sentiment analysis. The expected response format is a single word: either 'positive' or 'negative'.\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"leader\"][\"prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrent Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Prompt Engineering Specialist, Role: Design and refine prompts for optimal performance, Function: Develop and test various prompt structures\n",
      "Position: Sentiment Analysis Expert, Role: Ensure accurate classification of sentiment, Function: Review and fine-tune sentiment detection mechanisms\n",
      "Position: Natural Language Processing Scientist, Role: Implement advanced NLP techniques for prompt optimization, Function: Apply state-of-the-art NLP models and methods to enhance prompt effectiveness\n",
      "----\n",
      "generic team:\n",
      "Position: Natural Language Processing Specialist, Role: Develop and fine-tune NLP models, Function: Implement and refine machine learning models for text classification\n",
      "Position: Sentiment Analysis Expert, Role: Design sentiment classification algorithms, Function: Design and validate sentiment analysis methodologies to accurately classify text as positive or negative\n",
      "Position: Prompt Optimization Engineer, Role: Optimize prompt design and structure, Function: Ensure the prompt is general and robust, minimizing ambiguity and maximizing classification accuracy\n",
      "----\n",
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Prompt Engineer, Role: Design Efficient Prompts, Function: Create and refine the initial prompt to maximize clarity and effectiveness.\n",
      "Position: Sentiment Analysis Specialist, Role: Optimize Sentiment Classification, Function: Tailor prompts to encompass a broad range of positive and negative sentiments for better classification accuracy.\n",
      "Position: Linguistic Quality Controller, Role: Ensure Linguistic Accuracy, Function: Review and enhance the linguistic structure of the prompt for better generalization and minimal ambiguity.\n",
      "----\n",
      "general team:\n",
      "Position: Sentiment Analysis Specialist, Role: Design and validate sentiment classification models, Function: Develop algorithms to distinguish between positive and negative sentiments\n",
      "Position: Machine Learning Engineer, Role: Implement and optimize machine learning algorithms, Function: Ensure that the machine learning models are efficient and scalable\n",
      "Position: Data Scientist, Role: Analyze and preprocess data for model training and evaluation, Function: Collect, clean, and preprocess text data to enhance model accuracy\n",
      "----\n",
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Senior Prompt Engineer, Role: Designing and refining prompts, Function: Optimize prompts for clarity and efficiency\n",
      "Position: Natural Language Processing Specialist, Role: Enhancing language processing capabilities, Function: Develop algorithms to better interpret sentence context\n",
      "Position: Sentiment Analysis Expert, Role: Expertise in sentiment classification techniques, Function: Create robust classifiers to accurately determine sentiment\n",
      "----\n",
      "general team:\n",
      "Position: Sentiment Analysis Specialist, Role: Develop and refine sentiment classification algorithms, Function: Ensure high accuracy in distinguishing between positive and negative sentiments\n",
      "Position: Data Scientist, Role: Analyze and preprocess data to enhance model performance, Function: Implement data augmentation techniques and preprocess data to remove noise\n",
      "Position: Prompt Engineering Expert, Role: Design and optimize LLM prompts for accurate and generalizable classification, Function: Craft effective prompts and fine-tune them to work well across diverse datasets\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"Classify the sentence as positive or negative: {content}\"\n",
    "additional_info = \"This is a classification task with only two classes: positive and negative.\"\n",
    "\n",
    "leader_agent_1 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent_1.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")\n",
    "\n",
    "leader_agent_2 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent_2.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")\n",
    "\n",
    "leader_agent_3 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent_3.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentence as positive or negative: {content}\n",
      "----\n",
      "Classify the sentiment of the following sentence into one of two categories: 'positive' or 'negative'. Focus on the context and nuances of the content provided to determine the sentiment accurately. Provide your classification based on the overall sentiment conveyed by the sentence. Sentence: {content}\n",
      "----\n",
      "Classify the sentence provided in {content} as either 'positive' or 'negative' based on its sentiment. For this task, 'positive' sentiment indicates expressions of happiness, approval, or any favorable emotions, while 'negative' sentiment denotes expressions of sadness, disapproval, or any unfavorable emotions. Ensure the classification is strictly 'positive' or 'negative' and do not consider any ambiguous sentiments.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming leader_agent is already defined and initialized\n",
    "def run_optimisation(agent: LeaderAgent):\n",
    "    return agent.optimise_prompt()\n",
    "\n",
    "# Run 3 concurrent instances\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(run_optimisation, agent) for agent in [leader_agent_1, leader_agent_2, leader_agent_3]]\n",
    "    results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    print(\"----\")\n",
    "\n",
    "class PromptMerge(BaseModel):\n",
    "    \"\"\"Merged prompt based on the best parts of each prompt.\"\"\"\n",
    "    final_prompt: str = Field(description=\"Result of merging prompts\")\n",
    "\n",
    "# OpenAI Agent to pull togther best parts of each result\n",
    "def merge_results(results):\n",
    "    \"\"\"\n",
    "    Agent to merge best parts of each prompt\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=1.0,\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    system_message = \"\"\"You are an experienced AI prompt engineer. Your role is to combine prompts to create a more effective prompt.\n",
    "You have in-depth knowledge regarding large language models and their associated architectures, as well as prompt engineering best practices.\"\"\"\n",
    "\n",
    "    template = \"\"\"I am going to tip $300K for a better prompt!\n",
    "Given the prompts below, your task is to merge the best parts of each prompt to create the most effective prompt.\n",
    "Carefully consider the strengths of each prompt and how they can be combined to create a better prompt.\n",
    "Aspects of the prompts to consider:\n",
    "- Conciseness and clarity\n",
    "- Contextual relevance\n",
    "- Task alignment\n",
    "- Example Demonstrations\n",
    "- Avoiding bias\n",
    "- Incremental prompting\n",
    "Placeholders are notated using curly braces. You must not remove placeholders or add additional placeholders.\n",
    "I repeat, you must not remove placeholders or add additional placeholders.\n",
    "Do not make assumptions on what the placeholders represent.\n",
    "You will be penalized if the prompt is repetitive, lacks clarity or is incoherent.\n",
    "Ensure that your answer is unbiased.\n",
    "\n",
    "Prompts: {results}\n",
    "\n",
    "Return only the next worker to process or 'FINISH' in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"final_prompt\": \"Result of merging prompts\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "    pydantic_parser = PydanticOutputParser(pydantic_object=PromptMerge)\n",
    "    prompt_template = PromptTemplate(\n",
    "        system_message=system_message,\n",
    "        template=template,\n",
    "        input_variables=[\"results\"],\n",
    "        partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "    )\n",
    "    chain = prompt_template | llm | pydantic_parser\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            output = chain.invoke({\"results\": results})\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"Exception occurred:\", e)\n",
    "            continue\n",
    "    return output.final_prompt\n",
    "\n",
    "final_result = merge_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentiment of the following sentence into one of two categories: 'positive' or 'negative'. Focus on the context and nuances of the content provided to determine the sentiment accurately. For this task, 'positive' sentiment indicates expressions of happiness, approval, or any favorable emotions, while 'negative' sentiment denotes expressions of sadness, disapproval, or any unfavorable emotions. Ensure the classification is strictly 'positive' or 'negative' and do not consider any ambiguous sentiments. Sentence: {content}\n"
     ]
    }
   ],
   "source": [
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

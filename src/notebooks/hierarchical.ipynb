{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, StateGraph, MessageGraph\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import List, Sequence, TypedDict, Annotated\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = \"Hierarchical Optimisation\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import Client\n",
    "\n",
    "# client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptReview(BaseModel):\n",
    "    \"\"\"Review of the prompt\"\"\"\n",
    "    # prompt: str = Field(description=\"Most recent prompt\")\n",
    "    feedback: str = Field(description=\"Feedback on the most recent prompt\")\n",
    "\n",
    "\n",
    "class WorkerAgent:\n",
    "    \"\"\"\n",
    "    Worker Agent class defining agents that provide feedback on prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, position: str, role: str, function: str, temp: float = 1.0, model: str = \"gpt-4o\"):\n",
    "        self.position = position\n",
    "        self.role = role\n",
    "        self.function = function\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an expert: {self.position}. Your role: {self.role}. Your function: {self.function}.\n",
    "You must use your expertise to guide all your thinking. You must speak only as an expert in your field.\"\"\")        \n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "\n",
    "    def review_prompt(self, prompt: str, additional_info: str) -> PromptReview:\n",
    "        \"\"\"\n",
    "        Generates a review of the prompt.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Your task is to think outside the box to provide creative feedback with recommendations on how to impove the prompt below in light of your position, role and function:\n",
    "{prompt}\n",
    "\n",
    "Your feedback must be less than 100 words so think carefully about the most critical aspects of the prompt that need improvement.\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do:\n",
    "{additional_info}\n",
    "\n",
    "Below are strict guidelines that you MUST follow when providing feedback and recommendations:\n",
    "- DO NOT suggest modifying existing restrictions.\n",
    "- DO NOT suggest modifying or removing negations.\n",
    "- DO NOT suggest adding, modifying or removing placeholders denoted by curly braces.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt carefully as an expert {position}. \n",
    "2. Identify the most critical aspects of the prompt that need improvement. \n",
    "3. Think outside the box to provide creative feedback with recommendations on how to improve the prompt in light of your position, role and function.\n",
    "4. Ensure that your feedback is less than 100 words.\n",
    "5. Ensure that your feedback follows the strict guidelines provided above.\n",
    "6. Submit your feedback.\n",
    "\n",
    "Return only your feedback in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"feedback\": \"Feedback on the original prompt\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=PromptReview)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"position\", \"prompt\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                completion = chain.invoke({\"position\": self.position, \"prompt\": prompt, \"additional_info\": additional_info})\n",
    "                # Validate the output before returning\n",
    "                if completion.feedback:\n",
    "                    return completion\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", completion)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        else:\n",
    "            raise Exception(\"Failed to parse output after 3 attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Workforce(BaseModel):\n",
    "    \"\"\"Details of workforce generated by the leader agent.\"\"\"\n",
    "    positions: List[str] = Field(description=\"Positions of the workers in the workforce\")\n",
    "    roles: List[str] = Field(description=\"Roles of the workers in the workforce\")\n",
    "    functions: List[str] = Field(description=\"Functions of the workers in the workforce\")\n",
    "    \n",
    "\n",
    "class FeedbackSummary(BaseModel):\n",
    "    \"\"\"Summary of feedback from the worker agents.\"\"\"\n",
    "    feedback_summary: str = Field(description=\"Collated and summarised feedback from the workforce\")\n",
    "\n",
    "\n",
    "class ApprovalDecision(BaseModel):\n",
    "    \"\"\"Decision of the leader agent to approve or disapprove the prompt.\"\"\"\n",
    "    approved: bool = Field(description=\"Decision to approve or disapprove the prompt\")\n",
    "\n",
    "\n",
    "class TeamLeaderAgent:\n",
    "    \"\"\"\n",
    "    TeamLeaderAgent class defining an agent that manages a team of worker agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, team: str, team_role: str, prompt: str, additional_info: str = None, temp: float = 1.0, model: str = \"gpt-4o\", workforce: List[WorkerAgent] = None):\n",
    "        self.team = team\n",
    "        self.team_role = team_role\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an experienced {team} team leader with expertise in leading a team with the role: {team_role}. \n",
    "You must use your expertise to guide all your thinking. You must speak only as an expert in your field.\"\"\")\n",
    "        self.prompt = prompt\n",
    "        self.additional_info = additional_info\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "        self.workforce = workforce\n",
    "\n",
    "    def leader_feedback(self, prompt: str, feedback: list) -> str:\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next worker or to finish.\n",
    "        \"\"\"\n",
    "        # All workers except the current worker\n",
    "        template = \"\"\"Your task is to refine and summarise the feedback below:\n",
    "{feedback}\n",
    "\n",
    "You must capture the important aspects of the feedback and recommendations provided by your team.\n",
    "Your summary must be actionable and precise, providing clear recommendations for improvements to the prompt below:\n",
    " {prompt}\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do:\n",
    "{additional_info}\n",
    "\n",
    "Return only the feedback summary in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"feedback_summary\": \"Feedback summary\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=FeedbackSummary)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"pormpt\", \"additional_info\",\"feedback\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"prompt\": prompt, \"additional_info\": self.additional_info, \"feedback\": feedback})\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        return output.feedback_summary\n",
    "       \n",
    "    def get_feedback(self, state):\n",
    "        \"\"\"\n",
    "        Get feedback from wokers. Feedback collected concurrently.\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "            futures = [executor.submit(worker.review_prompt, state['prompt'], self.additional_info) for worker in self.workforce]\n",
    "            results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "            # feedback = [result[-1].content for result in results]\n",
    "            feedback = [result.feedback for result in results]\n",
    "\n",
    "        summary = self.leader_feedback(state[\"prompt\"], feedback)\n",
    "\n",
    "        return summary\n",
    "    \n",
    "    def get_approval(self, prompt: str):\n",
    "        \"\"\"\n",
    "        Agent to approve or reject the prompt.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Your task is to review the prompt below and decide whether it should be approved for use by a large language model:\n",
    "{prompt}\n",
    "\n",
    "You must consider the prompt in light of your team and team role.\n",
    "Ask yourself: Could the members of your team: {members}, offer valuable insights to help the prompt? Or is the prompt already optimal in the aspects your team specialises in? \n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do:\n",
    "{additional_info}\n",
    "\n",
    "Return the boolean value \"True\" if you approve and think the prompt already optimal in the aspects your team specialises in. \n",
    "Return the boolean value \"False\" if you disapprove and think the prompt could be improved with the insights of your team.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt carefully as an expert {position}.\n",
    "2. Determine whether the prompt will be effective in instructing the model to perform the desired task.\n",
    "3. If you believe the prompt is effective, approve it for use by the model.\n",
    "4. Submit your decision.\n",
    "    \n",
    "Return only the approval decision in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"approved\": \"True/False\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=ApprovalDecision)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"additional_info\", \"prompt\", \"members\", \"position\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                completion = chain.invoke({\"additional_info\": self.additional_info, \"prompt\": prompt, \"members\": [worker.position for worker in self.workforce], \"position\": self.team_role})\n",
    "                # Validate the output before returning\n",
    "                if completion.approved is not None:\n",
    "                    return completion.approved\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", completion)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        else:\n",
    "            raise Exception(\"Failed to parse output after 3 attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Domain(BaseModel):\n",
    "    \"\"\"Domain of the prompt.\"\"\"\n",
    "    domain: str = Field(description=\"Domain of the prompt\")\n",
    "    description: str = Field(description=\"Description of the domain team role\")\n",
    "\n",
    "\n",
    "class RouteDecision(BaseModel):\n",
    "    \"\"\"Decision on the next worker to process.\"\"\"\n",
    "    next: str = Field(description=\"The next team to process\")\n",
    "\n",
    "\n",
    "class UpdatedPrompt(BaseModel):\n",
    "    \"\"\"Updated prompt based on feedback from the team leader.\"\"\"\n",
    "    updated_prompt: str = Field(description=\"Updated prompt based on feedback\")\n",
    "\n",
    "\n",
    "class LeaderAgent:\n",
    "    \"\"\"\n",
    "    LeaderAgent class defining an agent that generates and communicates worker agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_prompt: str, additional_info: str = None, temp: float = 1.0, model: str = \"gpt-4o\", team_leaders: List[TeamLeaderAgent] = None):\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an experienced senior AI professional. You specialise in prompt engineering. \n",
    "You have in-depth knowledge of large language models and prompt engineering best practices. Use this knowledge to inform all your decisions.\"\"\")\n",
    "        self.base_prompt = base_prompt\n",
    "        self.prompt = base_prompt\n",
    "        self.additional_info = additional_info\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "        self.team_leaders = team_leaders\n",
    "        self.team_roles_dict = {team_leader.team: team_leader.team_role for team_leader in self.team_leaders}\n",
    "        self.iterations = 0\n",
    "    \n",
    "    def run_approval(self, prompt: str) -> List[bool]:\n",
    "        \"\"\"\n",
    "        Run the approval process for the prompt. Run concurrently\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(team_leader.get_approval, prompt) for team_leader in self.team_leaders]\n",
    "            results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "        return results\n",
    "    \n",
    "    def leader_decision(self, state: dict) -> RouteDecision:\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next worker or to finish.\n",
    "        \"\"\"\n",
    "        self.iterations += 1\n",
    "        approval_results = self.run_approval(state[\"prompt\"])\n",
    "        print(\"Approval results:\", approval_results)\n",
    "        if all(approval_results) or (self.iterations > 10):\n",
    "            return {\"next\": \"FINISH\", \"prompt\": state[\"prompt\"], \"messages\": state[\"messages\"]} \n",
    "        else:\n",
    "            self.iterations += 1\n",
    "            disapproved_team_leaders = [team_leader for i, team_leader in enumerate(self.team_leaders) if not approval_results[i]]\n",
    "            options = [team_leaders.team for team_leaders in disapproved_team_leaders]\n",
    "            # shuffle options to avoid positional bias\n",
    "            random.shuffle(options)\n",
    "            # options = [\"FINISH\"] + members\n",
    "            template = \"\"\"Your task is to review the prompt below and decide the next team to provide feedback:\n",
    "{prompt}\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do: \n",
    "{additional_info}\n",
    "\n",
    "The details of the teams and their roles are as follows: \n",
    "{team_roles}\n",
    "\n",
    "Select one of the following teams to provide feedback on the prompt: \n",
    "{options}\n",
    "\n",
    "Think carefully about pairing the aspects of the prompt that need improvement and how they relate to the expertise of each team.\n",
    "If you think multiple aspects of the prompt need improvement, select the most suitable team to provide feedback on the most critical aspects of the prompt.\n",
    "\n",
    "Return only the next team name to process in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"next\": \"Next team\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "            pydantic_parser = PydanticOutputParser(pydantic_object=RouteDecision)\n",
    "            prompt_template = PromptTemplate(\n",
    "                system_message=self.system_message,\n",
    "                template=template,\n",
    "                input_variables=[\"prompt\", \"additional_info\", \"team_roles\", \"options\"],\n",
    "                partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "            )\n",
    "            chain = prompt_template | self.llm | pydantic_parser\n",
    "            for _ in range(3):\n",
    "                try:\n",
    "                    output = chain.invoke({\"prompt\": state[\"prompt\"], \"additional_info\": self.additional_info, \"team_roles\": str(self.team_roles_dict), \"options\": str(options)})\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(\"Exception occurred:\", e)\n",
    "                    continue\n",
    "            return {\"next\": output.next, \"prompt\": state[\"prompt\"], \"messages\": state[\"messages\"]}\n",
    "\n",
    "    def update_prompt(self, prompt: str, feedback: str, history) -> str:\n",
    "        \"\"\"\n",
    "        Updates the prompt with the feedback from the worker agent.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Your task is to update the prompt below based on the feedback provided:\n",
    "{prompt}\n",
    "\n",
    "Feedback:\n",
    "{feedback}\n",
    "\n",
    "You must also consider the discussion history below prior to making changes to the prompt to ensure you do not repeat any mistakes: \n",
    "{history}\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do:\n",
    "{additional_info}\n",
    "\n",
    "Below are strict guidelines that you MUST follow if making changes to the prompt:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces.\n",
    "\n",
    "Your update process should be as follows:\n",
    "1. Read the prompt and feedback carefully.\n",
    "2. Review the discussion history to ensure you do not repeat any mistakes.\n",
    "3. Implement the feedback provided to help the prompt better achieve what is expected.\n",
    "4. Ensure that your update follows the strict guidelines provided above.\n",
    "5. Submit your updated prompt.\n",
    "\n",
    "Return only the updated prompt in JSON format:\n",
    "\n",
    "{{\n",
    "    \"prompt\": \"Updated prompt\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=UpdatedPrompt)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"prompt\", \"feedback\", \"history\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"prompt\": prompt, \"feedback\": feedback, \"history\": history, \"additional_info\": self.additional_info})\n",
    "                if output.updated_prompt:\n",
    "                    return output.updated_prompt\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", output)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "\n",
    "    def construct_team_graph(self):\n",
    "        \"\"\"\n",
    "        Constructs a graph of team leader agents.\n",
    "        \"\"\"\n",
    "        # The agent state is the input to each node in the graph\n",
    "        class TeamState(TypedDict):\n",
    "            # The annotation tells the graph that new messages will always be added to the current states\n",
    "            messages: Sequence[BaseMessage]\n",
    "            prompt: str\n",
    "            next: str\n",
    "\n",
    "        def team_node(state, team_leader):\n",
    "            try:\n",
    "                feedback = team_leader.get_feedback(state)\n",
    "                updated_prompt = self.update_prompt(state[\"prompt\"], feedback, state[\"messages\"])\n",
    "                # updated_prompt = output[-1].content \n",
    "                self.prompt = updated_prompt\n",
    "                return {\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(content=f\"Feedback: {feedback}\", name=team_leader.team),\n",
    "                        AIMessage(content=f\"Updated Prompt: {updated_prompt}\", name=\"Leader\")\n",
    "                    ],\n",
    "                    \"prompt\": updated_prompt,\n",
    "                }\n",
    "            except Exception as e:\n",
    "                # Log the error and return to leader with the most recent prompt\n",
    "                print(f\"Parsing failed for {team_leader.team}: {e}\")\n",
    "                return {\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(content=f\"Error: Parsing failed for {team_leader} - {e}\", name=team_leader.team),\n",
    "                        AIMessage(content=f\"Updated Prompt: {updated_prompt}\", name=\"Leader\")\n",
    "                    ],                    \n",
    "                    \"prompt\": state[\"prompt\"],\n",
    "                    \"next\": \"leader\",\n",
    "                }\n",
    "\n",
    "        workflow = StateGraph(TeamState)\n",
    "        for team_leader in self.team_leaders:\n",
    "            # Create a node for each team leader agent\n",
    "            # team_leader.construct_worker_graph()\n",
    "            node = functools.partial(team_node, team_leader=team_leader)\n",
    "            workflow.add_node(team_leader.team, node)\n",
    "        workflow.add_node(\"leader\", self.leader_decision)\n",
    "\n",
    "        members = [team_leader.team for team_leader in self.team_leaders]\n",
    "        for member in members:\n",
    "            # We want our workers to ALWAYS \"report back\" to the leader when done\n",
    "            workflow.add_edge(member, \"leader\")\n",
    "        # The leader populates the \"next\" field in the graph state with routes to a node or finishes\n",
    "        conditional_map = {k: k for k in members}\n",
    "        conditional_map[\"FINISH\"] = END\n",
    "        workflow.add_conditional_edges(\"leader\", lambda x: x[\"next\"], conditional_map)\n",
    "        # Finally, add entrypoint\n",
    "        workflow.set_entry_point(\"leader\")\n",
    "        graph = workflow.compile()\n",
    "        \n",
    "        return graph\n",
    "    \n",
    "    def optimise_prompt(self):\n",
    "        \"\"\"\n",
    "        Optimises a prompt by invoking a graph of worker agents.\n",
    "        \"\"\"\n",
    "        # Initial state\n",
    "        initial_state = {\n",
    "            \"messages\": [HumanMessage(content=f\"Base Prompt: {self.base_prompt}\", name=\"User\")],\n",
    "            \"prompt\": self.base_prompt,\n",
    "            \"next\": \"leader\",\n",
    "        }\n",
    "\n",
    "        # Construct the graph\n",
    "        graph = self.construct_team_graph()\n",
    "        # display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "        # Run the graph\n",
    "        for s in graph.stream(\n",
    "            initial_state,\n",
    "            {\"recursion_limit\": 50}\n",
    "            ):\n",
    "            if \"__end__\" not in s:\n",
    "                print(s)\n",
    "                print(\"----\")\n",
    "                continue\n",
    "\n",
    "        # if not os.path.exists(\"prompt_history_hierarchical.json\"):\n",
    "        #     with open(\"prompt_history_hierarchical.json\", \"w\") as f:\n",
    "        #         json.dump([], f)\n",
    "        \n",
    "        # with open(\"prompt_history_hierarchical.json\", \"r\") as f:\n",
    "        #     data = json.load(f)\n",
    "        #     data.append(self.prompt_history)\n",
    "            \n",
    "        # with open(\"prompt_history_hierarchical.json\", \"w\") as f:\n",
    "        #     json.dump(data, f, indent=4)\n",
    "                \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt design team members\n",
    "conciseness_and_clarity = {\n",
    "    \"position\": \"Conciseness and Clarity\", \n",
    "    \"role\": \"Analyze for conciseness and clarity\",\n",
    "    \"function\": \"Determine how the prompt can be more concise and clear in its instructions and avoid unnecessary information that does not contribute to the task while being specific enough to guide the model.\"\n",
    "}\n",
    "\n",
    "contextual_relevance = {\n",
    "    \"position\": \"Contextual Relevance\", \n",
    "    \"role\": \"Analyze for contextual relevance\",\n",
    "    \"function\": \"Determine how the prompt can better provide relevant context that helps the model understand the background and domain of the task\"\n",
    "}\n",
    "\n",
    "task_alignment = {\n",
    "    \"position\": \"Task Alignment\", \n",
    "    \"role\": \"Analyze for task alignment\",\n",
    "    \"function\": \"Determine how the prompt can better align with the task and use using language and structure that clearly indicate the nature of the task to the model.\"\n",
    "}\n",
    "\n",
    "example_demonstration = {\n",
    "    \"position\": \"Example Demonstration\", \n",
    "    \"role\": \"Analyze for example demonstration\",\n",
    "    \"function\": \"Determine how the prompt can better provide examples that demonstrate the expected output or behavior of the model.\"\n",
    "}\n",
    "\n",
    "# avoiding_bias = {\n",
    "#     \"position\": \"Avoiding Bias\", \n",
    "#     \"role\": \"Analyze for bias\",\n",
    "#     \"function\": \"Determine how the prompt can minimize the activation of biases inherent in the model due to its training data. This involves using neutral language and being mindful of potential ethical implications, especially for sensitive topics.\"\n",
    "# }\n",
    "\n",
    "incremental_pormpting = {\n",
    "    \"position\": \"Incremental Prompting\", \n",
    "    \"role\": \"Analyze for incremental prompting\",\n",
    "    \"function\": \"Determine how the prompt can be structured in a way that guides the model through a series of steps or questions to help it generate the desired output.\"\n",
    "}\n",
    "\n",
    "# programming_logic = {\n",
    "#     \"position\": \"Programming Logic\", \n",
    "#     \"role\": \"Analyze for programming logic\",\n",
    "#     \"function\": \"Determine how the prompt can better incorporate and enforce programming logic concepts to help solve complex problems. For instance, use of conditional statements, logical operators, or even pseudo-code within the prompt to guide the model’s reasoning process.\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain team members\n",
    "mathematician = {\n",
    "    \"position\": \"Mathematician\", \n",
    "    \"role\": \"Analyze for mathematcial thinking\",\n",
    "    \"function\": \"Determine how prompts and instructions can better help language models solve mathematical problems.\"\n",
    "}\n",
    "\n",
    "word_problem_solver = {\n",
    "    \"position\": \"Word Problem Solver\", \n",
    "    \"role\": \"Analyze for word problem thinking\",\n",
    "    \"function\": \"Determine how prompts and instructions can better help language models solve word problems.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iwatson/Documents/Research Project/prompt-optimisation/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams and members:\n",
      "Prompt Design team:\n",
      "Team Role: Formulate prompts and instructions to elicit high-quality responses from large language models. The focus is to utilise input from prompt design experts to improve the prompt.\n",
      "Position: Conciseness and Clarity, Role: Analyze for conciseness and clarity, Function: Determine how the prompt can be more concise and clear in its instructions and avoid unnecessary information that does not contribute to the task while being specific enough to guide the model.\n",
      "Position: Contextual Relevance, Role: Analyze for contextual relevance, Function: Determine how the prompt can better provide relevant context that helps the model understand the background and domain of the task\n",
      "Position: Task Alignment, Role: Analyze for task alignment, Function: Determine how the prompt can better align with the task and use using language and structure that clearly indicate the nature of the task to the model.\n",
      "Position: Example Demonstration, Role: Analyze for example demonstration, Function: Determine how the prompt can better provide examples that demonstrate the expected output or behavior of the model.\n",
      "Position: Incremental Prompting, Role: Analyze for incremental prompting, Function: Determine how the prompt can be structured in a way that guides the model through a series of steps or questions to help it generate the desired output.\n",
      "----\n",
      "Mathematics team:\n",
      "Team Role: Formulate prompts and instructions help large language models solve mathematical problems. The focus is to utilise input from domain experts to improve the prompt.\n",
      "Position: Mathematician, Role: Analyze for mathematcial thinking, Function: Determine how prompts and instructions can better help language models solve mathematical problems.\n",
      "Position: Word Problem Solver, Role: Analyze for word problem thinking, Function: Determine how prompts and instructions can better help language models solve word problems.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"{content}. Please output your answer at the end as ##<your answer (arabic numerals)>.\"\n",
    "additional_info = \"\"\"- Solve the math word problem.\\n- Output the answer at the end as ##<your answer (arabic numerals)> with no spaces or units.\"\"\"\n",
    "\n",
    "prompt_design_team = TeamLeaderAgent(\n",
    "    \"Prompt Design\",\n",
    "    \"Formulate prompts and instructions to elicit high-quality responses from large language models. The focus is to utilise input from prompt design experts to improve the prompt.\",\n",
    "    base_prompt,\n",
    "    additional_info,\n",
    "    workforce=[\n",
    "        WorkerAgent(**conciseness_and_clarity),\n",
    "        WorkerAgent(**contextual_relevance),\n",
    "        WorkerAgent(**task_alignment),\n",
    "        WorkerAgent(**example_demonstration),\n",
    "        WorkerAgent(**incremental_pormpting),\n",
    "    ]\n",
    ")\n",
    "domain_team = TeamLeaderAgent(\n",
    "    \"Mathematics\",\n",
    "    \"Formulate prompts and instructions help large language models solve mathematical problems. The focus is to utilise input from domain experts to improve the prompt.\",\n",
    "    base_prompt,\n",
    "    additional_info,\n",
    "    workforce=[\n",
    "        WorkerAgent(**mathematician),\n",
    "        WorkerAgent(**word_problem_solver),\n",
    "    ]\n",
    ")\n",
    "\n",
    "leader_agent = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    "    team_leaders=[prompt_design_team, domain_team]\n",
    ")\n",
    "\n",
    "# leader_agent.generate_teams()\n",
    "# print teams and members\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    print(f\"Team Role: {team_leader.team_role}\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approval results: [True, False]\n",
      "{'leader': {'messages': [HumanMessage(content='Base Prompt: {content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', name='User')], 'prompt': '{content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', 'next': 'Mathematics'}}\n",
      "----\n",
      "{'Mathematics': {'messages': [HumanMessage(content='Base Prompt: {content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content=\"Feedback: The prompt should remind solvers to show all steps or calculations for clarity and accuracy. Adding phrases like 'Show all steps clearly' can guide a structured approach. Additionally, enhance the prompt with a clear introductory sentence, such as 'Solve the following math word problem and provide the answer at the end as ##<your answer (arabic numerals)>, with no spaces or units.' This ensures focus and clarity.\", name='Mathematics'), AIMessage(content='Updated Prompt: Solve the following math word problem and provide the answer at the end as ##<your answer (arabic numerals)>, with no spaces or units. Show all steps clearly for clarity and accuracy. {content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', name='Leader')], 'prompt': 'Solve the following math word problem and provide the answer at the end as ##<your answer (arabic numerals)>, with no spaces or units. Show all steps clearly for clarity and accuracy. {content}. Please output your answer at the end as ##<your answer (arabic numerals)>.'}}\n",
      "----\n",
      "Approval results: [True, True]\n",
      "{'leader': {'messages': [HumanMessage(content='Base Prompt: {content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content=\"Feedback: The prompt should remind solvers to show all steps or calculations for clarity and accuracy. Adding phrases like 'Show all steps clearly' can guide a structured approach. Additionally, enhance the prompt with a clear introductory sentence, such as 'Solve the following math word problem and provide the answer at the end as ##<your answer (arabic numerals)>, with no spaces or units.' This ensures focus and clarity.\", name='Mathematics'), AIMessage(content='Updated Prompt: Solve the following math word problem and provide the answer at the end as ##<your answer (arabic numerals)>, with no spaces or units. Show all steps clearly for clarity and accuracy. {content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', name='Leader')], 'prompt': 'Solve the following math word problem and provide the answer at the end as ##<your answer (arabic numerals)>, with no spaces or units. Show all steps clearly for clarity and accuracy. {content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', 'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "result = leader_agent.optimise_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Solve the following math word problem and provide the answer at the end as ##<your answer (arabic numerals)>, with no spaces or units. Show all steps clearly for clarity and accuracy. {content}. Please output your answer at the end as ##<your answer (arabic numerals)>.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"leader\"][\"prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrent Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Prompt Engineering Specialist, Role: Design and refine prompts for optimal performance, Function: Develop and test various prompt structures\n",
      "Position: Sentiment Analysis Expert, Role: Ensure accurate classification of sentiment, Function: Review and fine-tune sentiment detection mechanisms\n",
      "Position: Natural Language Processing Scientist, Role: Implement advanced NLP techniques for prompt optimization, Function: Apply state-of-the-art NLP models and methods to enhance prompt effectiveness\n",
      "----\n",
      "generic team:\n",
      "Position: Natural Language Processing Specialist, Role: Develop and fine-tune NLP models, Function: Implement and refine machine learning models for text classification\n",
      "Position: Sentiment Analysis Expert, Role: Design sentiment classification algorithms, Function: Design and validate sentiment analysis methodologies to accurately classify text as positive or negative\n",
      "Position: Prompt Optimization Engineer, Role: Optimize prompt design and structure, Function: Ensure the prompt is general and robust, minimizing ambiguity and maximizing classification accuracy\n",
      "----\n",
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Prompt Engineer, Role: Design Efficient Prompts, Function: Create and refine the initial prompt to maximize clarity and effectiveness.\n",
      "Position: Sentiment Analysis Specialist, Role: Optimize Sentiment Classification, Function: Tailor prompts to encompass a broad range of positive and negative sentiments for better classification accuracy.\n",
      "Position: Linguistic Quality Controller, Role: Ensure Linguistic Accuracy, Function: Review and enhance the linguistic structure of the prompt for better generalization and minimal ambiguity.\n",
      "----\n",
      "general team:\n",
      "Position: Sentiment Analysis Specialist, Role: Design and validate sentiment classification models, Function: Develop algorithms to distinguish between positive and negative sentiments\n",
      "Position: Machine Learning Engineer, Role: Implement and optimize machine learning algorithms, Function: Ensure that the machine learning models are efficient and scalable\n",
      "Position: Data Scientist, Role: Analyze and preprocess data for model training and evaluation, Function: Collect, clean, and preprocess text data to enhance model accuracy\n",
      "----\n",
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Senior Prompt Engineer, Role: Designing and refining prompts, Function: Optimize prompts for clarity and efficiency\n",
      "Position: Natural Language Processing Specialist, Role: Enhancing language processing capabilities, Function: Develop algorithms to better interpret sentence context\n",
      "Position: Sentiment Analysis Expert, Role: Expertise in sentiment classification techniques, Function: Create robust classifiers to accurately determine sentiment\n",
      "----\n",
      "general team:\n",
      "Position: Sentiment Analysis Specialist, Role: Develop and refine sentiment classification algorithms, Function: Ensure high accuracy in distinguishing between positive and negative sentiments\n",
      "Position: Data Scientist, Role: Analyze and preprocess data to enhance model performance, Function: Implement data augmentation techniques and preprocess data to remove noise\n",
      "Position: Prompt Engineering Expert, Role: Design and optimize LLM prompts for accurate and generalizable classification, Function: Craft effective prompts and fine-tune them to work well across diverse datasets\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"Classify the sentence as positive or negative: {content}\"\n",
    "additional_info = \"This is a classification task with only two classes: positive and negative.\"\n",
    "\n",
    "leader_agent_1 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent_1.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")\n",
    "\n",
    "leader_agent_2 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent_2.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")\n",
    "\n",
    "leader_agent_3 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent_3.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentence as positive or negative: {content}\n",
      "----\n",
      "Classify the sentiment of the following sentence into one of two categories: 'positive' or 'negative'. Focus on the context and nuances of the content provided to determine the sentiment accurately. Provide your classification based on the overall sentiment conveyed by the sentence. Sentence: {content}\n",
      "----\n",
      "Classify the sentence provided in {content} as either 'positive' or 'negative' based on its sentiment. For this task, 'positive' sentiment indicates expressions of happiness, approval, or any favorable emotions, while 'negative' sentiment denotes expressions of sadness, disapproval, or any unfavorable emotions. Ensure the classification is strictly 'positive' or 'negative' and do not consider any ambiguous sentiments.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming leader_agent is already defined and initialized\n",
    "def run_optimisation(agent: LeaderAgent):\n",
    "    return agent.optimise_prompt()\n",
    "\n",
    "# Run 3 concurrent instances\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(run_optimisation, agent) for agent in [leader_agent_1, leader_agent_2, leader_agent_3]]\n",
    "    results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    print(\"----\")\n",
    "\n",
    "class PromptMerge(BaseModel):\n",
    "    \"\"\"Merged prompt based on the best parts of each prompt.\"\"\"\n",
    "    final_prompt: str = Field(description=\"Result of merging prompts\")\n",
    "\n",
    "# OpenAI Agent to pull togther best parts of each result\n",
    "def merge_results(results):\n",
    "    \"\"\"\n",
    "    Agent to merge best parts of each prompt\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=1.0,\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    system_message = \"\"\"You are an experienced AI prompt engineer. Your role is to combine prompts to create a more effective prompt.\n",
    "You have in-depth knowledge regarding large language models and their associated architectures, as well as prompt engineering best practices.\"\"\"\n",
    "\n",
    "    template = \"\"\"I am going to tip $300K for a better prompt!\n",
    "Given the prompts below, your task is to merge the best parts of each prompt to create the most effective prompt.\n",
    "Carefully consider the strengths of each prompt and how they can be combined to create a better prompt.\n",
    "Aspects of the prompts to consider:\n",
    "- Conciseness and clarity\n",
    "- Contextual relevance\n",
    "- Task alignment\n",
    "- Example Demonstrations\n",
    "- Avoiding bias\n",
    "- Incremental prompting\n",
    "Placeholders are notated using curly braces. You must not remove placeholders or add additional placeholders.\n",
    "I repeat, you must not remove placeholders or add additional placeholders.\n",
    "Do not make assumptions on what the placeholders represent.\n",
    "You will be penalized if the prompt is repetitive, lacks clarity or is incoherent.\n",
    "Ensure that your answer is unbiased.\n",
    "\n",
    "Prompts: {results}\n",
    "\n",
    "Return only the next worker to process or 'FINISH' in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"final_prompt\": \"Result of merging prompts\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "    pydantic_parser = PydanticOutputParser(pydantic_object=PromptMerge)\n",
    "    prompt_template = PromptTemplate(\n",
    "        system_message=system_message,\n",
    "        template=template,\n",
    "        input_variables=[\"results\"],\n",
    "        partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "    )\n",
    "    chain = prompt_template | llm | pydantic_parser\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            output = chain.invoke({\"results\": results})\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"Exception occurred:\", e)\n",
    "            continue\n",
    "    return output.final_prompt\n",
    "\n",
    "final_result = merge_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentiment of the following sentence into one of two categories: 'positive' or 'negative'. Focus on the context and nuances of the content provided to determine the sentiment accurately. For this task, 'positive' sentiment indicates expressions of happiness, approval, or any favorable emotions, while 'negative' sentiment denotes expressions of sadness, disapproval, or any unfavorable emotions. Ensure the classification is strictly 'positive' or 'negative' and do not consider any ambiguous sentiments. Sentence: {content}\n"
     ]
    }
   ],
   "source": [
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

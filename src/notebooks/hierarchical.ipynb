{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts.chat import SystemMessage, _convert_to_message\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "from langgraph.graph import END, StateGraph, MessageGraph\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import List, Sequence, TypedDict, Annotated\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = \"Hierarchical Optimisation\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import Client\n",
    "\n",
    "# client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorePrinciples:\n",
    "    def __init__(self, core_principles: List[str]):\n",
    "        self.core_principles = core_principles\n",
    "    \n",
    "    def add_principle(self, principle: str):\n",
    "        \"\"\"\n",
    "        Adds a principle to the core principles list.\n",
    "        \n",
    "        :param principle: The principle to be added.\n",
    "        \"\"\"\n",
    "        self.core_principles.append(principle)\n",
    "        \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation of the core principles, each principle is listed on a new line with a preceding dash.\n",
    "        \n",
    "        Example:\n",
    "        - principle 1\n",
    "        - principle 2\n",
    "        ...\n",
    "        \"\"\"\n",
    "        return \"\\n\".join([f\"- {principle}\" for principle in self.core_principles])\n",
    "\n",
    "class WorkerAgent:\n",
    "    \"\"\"\n",
    "    Worker Agent class defining agents that provide feedback on prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, position: str, core_principles: CorePrinciples, llm = ChatOpenAI(temperature=1.0, model=\"gpt-4o\")):\n",
    "        self.position = position\n",
    "        self.core_principles = str(core_principles)\n",
    "        self.system_message = f\"\"\"You are an experienced: {self.position}. Your core principles are:\n",
    "{self.core_principles}\"\"\"      \n",
    "        self.llm = llm\n",
    "\n",
    "    def review_prompt(self, state: Sequence[BaseMessage], criteria: str):\n",
    "        \"\"\"\n",
    "        Generates a review of the prompt.\n",
    "        \"\"\"\n",
    "        prompt_text = f\"\"\"Your task is to review the conversation above and think outside the box to provide feedback on the prompt.\n",
    "Offer creative recommendations on how to improve it in light of your core principles.\n",
    "\n",
    "The success criteria for the updated prompt are as follows:\n",
    "{criteria}\n",
    "You must use this information to inform your feedback.\n",
    "\n",
    "Below are strict guidelines that MUST be followed if making changes to the prompt:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces.\n",
    "- ALWAYS treat placeholders as the actual content.\n",
    "Check that that the prompt adheres to these guidelines.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt carefully as an expert {self.position}. \n",
    "2. Explcitly go through each success criteria and ensure the prompt meets them. If not, mention the criteria that was not met in your feedback.\n",
    "3. Explicitly go through each guideline and ensure the changes adhere to them. If not, mention the guideline that was not followed in your feedback.\n",
    "4. Explicitly list the creative recommendations you have for improving the most critical aspects of the prompt.\n",
    "5. Submit your feedback.\n",
    "\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.system_message),\n",
    "                MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                (\"system\", prompt_text)\n",
    "            ]\n",
    "        )\n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"messages\": state})       \n",
    "        return {\"messages\": [HumanMessage(content=result.content, name=self.position)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamLeaderAgent:\n",
    "    \"\"\"\n",
    "    TeamLeaderAgent class defining an agent that manages a team of worker agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, position: str, core_principles: CorePrinciples, prompt: str, criteria: str = None, llm = ChatOpenAI(temperature=1.0, model=\"gpt-4o\"), workforce: List[WorkerAgent] = None):\n",
    "        self.position = position\n",
    "        self.core_principles = str(core_principles)\n",
    "        self.system_message = f\"\"\"You are an experienced: {self.position}. Your core principles are:\n",
    "{self.core_principles}\"\"\"\n",
    "        self.prompt = prompt\n",
    "        self.criteria = criteria\n",
    "        self.llm = llm\n",
    "        self.workforce = workforce\n",
    "        self.iterations = 0\n",
    "\n",
    "    def leader_decision(self, state: Sequence[BaseMessage]):\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next team or to finish.\n",
    "        \"\"\"\n",
    "        self.iterations += 1\n",
    "        if self.iterations > 3:\n",
    "            return \"FINISH\"\n",
    "        else:\n",
    "            options = [\"FINISH\"] + [worker.position for worker in self.workforce]\n",
    "            # shuffle the options to avoid positional bias\n",
    "            random.shuffle(options)\n",
    "            # options = [\"FINISH\"] + positions\n",
    "            function_def = {\n",
    "                \"name\": \"route\",\n",
    "                \"description\": \"Select the next role.\",\n",
    "                \"parameters\": {\n",
    "                    \"title\": \"routeSchema\",\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"next\": {\n",
    "                            \"title\": \"Next\",\n",
    "                            \"anyOf\": [\n",
    "                                {\"enum\": options},\n",
    "                            ],\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"next\"],\n",
    "                },\n",
    "            }\n",
    "            prompt_text = f\"\"\"Your task is to review the conversation above and decide the next worker to provide feedback or to FINISH.\n",
    "\n",
    "The success criteria for the updated prompt are as follows:\n",
    "{self.criteria}\n",
    "You must use this information to inform your decision.\n",
    "\n",
    "Select one of the below workers to provide feedback on how to improve the prompt: \n",
    "{options}\n",
    "\n",
    "Think carefully about which aspects of the prompt need improvement and which worker would be best suited to provide feedback on those aspects.\n",
    "If you think multiple aspects of the prompt need improvement, select the most suitable worker to provide feedback on the most critical aspect of the prompt.\n",
    "You must only FINISH if you think your team can no longer provide valuable feedback on the prompt.\n",
    "\"\"\"\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_message),\n",
    "                    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                    (\"system\", prompt_text),\n",
    "                ]\n",
    "            )\n",
    "            chain = (\n",
    "                prompt\n",
    "                | self.llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "                | JsonOutputFunctionsParser()\n",
    "            )\n",
    "            result = chain.invoke({\"messages\": state})\n",
    "            print(result[\"next\"])\n",
    "            return result[\"next\"]\n",
    "\n",
    "    def update_prompt(self, state: Sequence[BaseMessage]):\n",
    "        \"\"\"\n",
    "        Updates the prompt with the feedback from the team agent.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(state) == 1:\n",
    "            return {\"next\": self.leader_decision(state)}\n",
    "        \n",
    "        prompt_text = f\"\"\"Your task is to review the conversation above and improve the prompt in light of your core principles.\n",
    "If you recieve feedback and recommendations for the prompt, respond with a revised version of your previous attempts actioning the feedback.\n",
    "\n",
    "The success criteria for the prompt are as follows:\n",
    "{self.criteria}\n",
    "You will be penalized if the prompt does not meet this criteria.\n",
    "\n",
    "Below are strict guidelines that you MUST follow if making changes to the prompt:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces.\n",
    "- ALWAYS treat placeholders as the actual content.\n",
    "You will be penalized if you do not follow these guidelines.\n",
    "\n",
    "Your update process should be as follows:\n",
    "1. Review the conversation carefully as an expert Head AI Engineer.\n",
    "2. Think carefully about how you can implement the user's feedback (if any) to improve the prompt.\n",
    "3. Revise the prompt in light of your core principles and the feedback you have received (if any).\n",
    "4. Submit your revised prompt.\n",
    "\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.system_message),\n",
    "                MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                (\"system\", prompt_text),\n",
    "            ]\n",
    "        )\n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"messages\": state})\n",
    "        return {\"messages\": [HumanMessage(content=result.content, name=self.position)], \"next\": self.leader_decision(state)}\n",
    "    \n",
    "    def approval(self, state: Sequence[BaseMessage], criteria: str):\n",
    "        \"\"\"\n",
    "        Agent to approve or reject the prompt.\n",
    "        \"\"\"\n",
    "        function_def = {\n",
    "        \"name\": \"approval\",\n",
    "        \"description\": \"Submit approval decision for the prompt.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"team\": {\"type\": \"string\", \"enum\": [self.position]},\n",
    "                \"decision\": {\"type\": \"string\", \"enum\": [\"True\", \"False\"]},\n",
    "            },\n",
    "            \"required\": [\"decision\", \"team_name\"],\n",
    "        },\n",
    "        }\n",
    "        prompt_text = f\"\"\"Your task is to review the conversation above and decide if the prompt is optimal in light of your core principles and the success criteria.\n",
    "\n",
    "The success criteria for the prompt are as follows:\n",
    "{criteria}\n",
    "You must use this information to inform your decision.\n",
    "\n",
    "If you think the prompt sufficiently meets the success criteria, return True. \n",
    "If you think the prompt needs improvements, in light of your core pirnciples, to better meet the success criteria, return False.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt carefully as an expert {self.position}.\n",
    "2. Determine whether the prompt needs improvements or meets the success criteria.\n",
    "3. Submit your decision.\n",
    "\"\"\"\n",
    "        messages = [\n",
    "            (\"system\", self.system_message),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\"system\", prompt_text),\n",
    "        ]\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "        chain = (\n",
    "            prompt\n",
    "            | self.llm.bind_functions(functions=[function_def], function_call=\"approval\")\n",
    "            | JsonOutputFunctionsParser()\n",
    "        )\n",
    "        result = chain.invoke({\"messages\": state})\n",
    "        return result\n",
    "    \n",
    "    def construct_team_graph(self):\n",
    "        \"\"\"\n",
    "        Constructs a graph of team agents based on their roles and functions.\n",
    "        \"\"\"\n",
    "\n",
    "        def worker_node(state, agent):\n",
    "            return agent.review_prompt(state[\"messages\"], self.criteria)\n",
    "        \n",
    "        def leader_node(state):\n",
    "            return self.update_prompt(state[\"messages\"]) \n",
    "        \n",
    "        # The agent state is the input to each node in the graph\n",
    "        class AgentState(TypedDict):\n",
    "            messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "            next: str\n",
    "\n",
    "        workflow = StateGraph(AgentState)\n",
    "        for worker in self.workforce:\n",
    "            # Create a node for each team agent\n",
    "            node = functools.partial(worker_node, agent=worker)\n",
    "            workflow.add_node(worker.position, node)\n",
    "        workflow.add_node(self.position, leader_node)\n",
    "\n",
    "        members = [worker.position for worker in self.workforce]\n",
    "        for member in members:\n",
    "            # We want our teams to ALWAYS \"report back\" to the leader when done\n",
    "            workflow.add_edge(member, self.position)\n",
    "        # The leader populates the \"next\" field in the graph state with routes to a node or finishes\n",
    "        conditional_map = {k: k for k in members}\n",
    "        conditional_map[\"FINISH\"] = END\n",
    "        workflow.add_conditional_edges(self.position, lambda x: x[\"next\"], conditional_map)\n",
    "        workflow.set_entry_point(self.position)\n",
    "\n",
    "        memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "        graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeaderAgent:\n",
    "    \"\"\"\n",
    "    LeaderAgent class defining an agent that generates and communicates worker agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_prompt: str, criteria: str = None, llm = ChatOpenAI(temperature=1.0, model=\"gpt-4o\"), team_leaders: List[TeamLeaderAgent] = None):\n",
    "        self.base_prompt = base_prompt\n",
    "        self.system_message = f\"\"\"You are an experienced: Head AI Prompt Engineer. Your core principles are:\n",
    "- Always pay attention to detail in prompts\n",
    "- Always be critical of prompts\n",
    "- Always make informed decisions with regards to prompts\"\"\"\n",
    "        self.criteria = criteria\n",
    "        self.llm = llm\n",
    "        self.team_leaders = team_leaders\n",
    "        self.iterations = 0\n",
    "    \n",
    "    def run_approval(self, state: Sequence[BaseMessage]) -> List[bool]:\n",
    "        \"\"\"\n",
    "        Run the approval process for the prompt. Run concurrently\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(team.approval, state, self.criteria) for team in self.team_leaders]\n",
    "            results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "        return results\n",
    "    \n",
    "    def leader_decision(self, state: Sequence[BaseMessage]):\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next team or to finish.\n",
    "        \"\"\"\n",
    "        self.iterations += 1\n",
    "        approval_results = self.run_approval(state)\n",
    "        print(\"Approval results:\", approval_results)\n",
    "        # print(\"Approval results:\", approval_results)\n",
    "        # Extract decisions from the results\n",
    "        approval_results = [result[\"decision\"] == \"True\" for result in approval_results]\n",
    "        if all(approval_results) or self.iterations > 10:\n",
    "            return \"FINISH\"\n",
    "        else:\n",
    "            # Only ask for advise from teams that disapproved the prompt\n",
    "            disapproved_teams = [team for team, result in zip(self.team_leaders, approval_results) if not result]\n",
    "            disapproved_teams_details = [f\"{team.position}:\\n{team.core_principles}\\n\\n\" for team in self.team_leaders]\n",
    "            options = [team.position for team in disapproved_teams]\n",
    "            # shuffle the options to avoid positional bias\n",
    "            random.shuffle(options)\n",
    "            # options = [\"FINISH\"] + positions\n",
    "            function_def = {\n",
    "                \"name\": \"route\",\n",
    "                \"description\": \"Select the next role.\",\n",
    "                \"parameters\": {\n",
    "                    \"title\": \"routeSchema\",\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"next\": {\n",
    "                            \"title\": \"Next\",\n",
    "                            \"anyOf\": [\n",
    "                                {\"enum\": options},\n",
    "                            ],\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"next\"],\n",
    "                },\n",
    "            }\n",
    "            prompt_text = f\"\"\"Your task is to review the conversation above in light of your core principles and decide the next team to provide feedback.\n",
    "\n",
    "The success criteria for the updated prompt are as follows:\n",
    "{self.criteria}\n",
    "You must use this information to inform your decision.\n",
    "\n",
    "The details of all teams are their core principles are as follows: \n",
    "{disapproved_teams_details}\n",
    "\n",
    "Select one of the below teams that disapproved the prompt to provide feedback on how to improve it: \n",
    "{options}\n",
    "\n",
    "Think carefully about which aspects of the prompt need improvement and which team would be best suited to provide feedback on those aspects.\n",
    "If you think multiple aspects of the prompt need improvement, select the most suitable team to provide feedback on the most critical aspect of the prompt.\n",
    "\"\"\"\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", self.system_message),\n",
    "                    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                    (\"system\", prompt_text),\n",
    "                ]\n",
    "            )\n",
    "            chain = (\n",
    "                prompt\n",
    "                | self.llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "                | JsonOutputFunctionsParser()\n",
    "            )\n",
    "            result = chain.invoke({\"messages\": state})\n",
    "            # print(result[\"next\"])\n",
    "            return result[\"next\"]\n",
    "\n",
    "    def review_prompt(self, state: Sequence[BaseMessage]) -> str:\n",
    "        \"\"\"\n",
    "        Updates the prompt with the feedback from the team agent.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(state) == 1:\n",
    "            return {\"next\": self.leader_decision(state)}\n",
    "        \n",
    "        prompt_text = f\"\"\"Your task is to thoroughly review the conversation above in light of your core principles and check the prompt meets the success criteria and adheres to the strict guidelines.\n",
    "If the success criteria are not met, or the strict guidlines not followed, provide a carefully revised version of the prompt.\n",
    "You may also revise the prompt if you think it can be improved to better meet the success criteria.\n",
    "\n",
    "The success criteria for the prompt are as follows:\n",
    "{self.criteria}\n",
    "\n",
    "The strict guidelines for the prompt are as follows:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces. IT IS ESSENTIAL PLACEHOLDERS REMAIN IN PLACE.\n",
    "- ALWAYS treat placeholders as the actual content.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Review the conversation carefully as an expert Head AI Engineer.\n",
    "2. Explcitly go through each success criteria and ensure the prompt meets them. If not, repeat from step 1.\n",
    "3. Explicitly go through each guideline and ensure changes made adhere to them. If not, repeat from step 1.\n",
    "4. If the prompt meets the success criteria and adheres to the strict guidelines, submit the prompt. Otherwise, provide a revised version of the prompt.\n",
    "\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.system_message),\n",
    "                MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                (\"system\", prompt_text),\n",
    "            ]\n",
    "        )\n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"messages\": state})\n",
    "        return {\"messages\": [AIMessage(content=result.content, name=\"Leader\")], \"next\": self.leader_decision(state)}\n",
    "\n",
    "    def construct_team_graph(self):\n",
    "        \"\"\"\n",
    "        Constructs a graph of team agents based on their roles and functions.\n",
    "        \"\"\"\n",
    "\n",
    "        # The agent state is the input to each node in the graph\n",
    "        class AgentState(TypedDict):\n",
    "            messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "            next: str\n",
    "\n",
    "        def enter_chain(message: str):\n",
    "            results = {\n",
    "                \"messages\": [HumanMessage(content=message)],\n",
    "            }\n",
    "            return results\n",
    "        \n",
    "        def get_last_message(state: AgentState) -> str:\n",
    "            return state[\"messages\"][-1].content\n",
    "\n",
    "        def join_graph(response: dict):\n",
    "            return {\"messages\": [response[\"messages\"][-1]]}\n",
    "\n",
    "        def leader_node(state):\n",
    "            return self.review_prompt(state[\"messages\"])\n",
    "\n",
    "        workflow = StateGraph(AgentState)\n",
    "        for team in self.team_leaders:\n",
    "            # Create a node for each team agent\n",
    "            graph = team.construct_team_graph()\n",
    "            chain = enter_chain | graph\n",
    "            workflow.add_node(team.position, get_last_message | chain | join_graph)\n",
    "        workflow.add_node(\"Leader\", leader_node)\n",
    "\n",
    "        members = [team.position for team in self.team_leaders]\n",
    "        for member in members:\n",
    "            # We want our teams to ALWAYS \"report back\" to the leader when done\n",
    "            workflow.add_edge(member, \"Leader\")\n",
    "        # The leader populates the \"next\" field in the graph state with routes to a node or finishes\n",
    "        conditional_map = {k: k for k in members}\n",
    "        conditional_map[\"FINISH\"] = END\n",
    "        workflow.add_conditional_edges(\"Leader\", lambda x: x[\"next\"], conditional_map)\n",
    "        workflow.set_entry_point(\"Leader\")\n",
    "\n",
    "        memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "        graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "        return graph\n",
    "    \n",
    "    def optimise_prompt(self):\n",
    "        \"\"\"\n",
    "        Optimises a prompt by invoking a graph of worker agents.\n",
    "        \"\"\"\n",
    "        # Initial state\n",
    "        initial_state = {\n",
    "            \"messages\": [HumanMessage(content=f\"{self.base_prompt}\", name=\"User\")],\n",
    "            \"prompt\": self.base_prompt,\n",
    "            \"next\": \"leader\",\n",
    "        }\n",
    "\n",
    "        # Construct the graph\n",
    "        graph = self.construct_team_graph()\n",
    "        # display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "        n = random.randint(0, 1000)\n",
    "        config = {\n",
    "            \"configurable\": {\"thread_id\": str(n)},\n",
    "            \"recursion_limit\": 50,\n",
    "            }    \n",
    "\n",
    "        # Run the graph\n",
    "        for s in graph.stream(\n",
    "            initial_state,\n",
    "            config,\n",
    "            stream_mode=\"values\",\n",
    "            ):\n",
    "            if \"__end__\" not in s:\n",
    "                if len(s[\"messages\"]) > 1:\n",
    "                    s[\"messages\"][-1].pretty_print()\n",
    "                continue\n",
    "\n",
    "        # if not os.path.exists(\"prompt_history_hierarchical.json\"):\n",
    "        #     with open(\"prompt_history_hierarchical.json\", \"w\") as f:\n",
    "        #         json.dump([], f)\n",
    "        \n",
    "        # with open(\"prompt_history_hierarchical.json\", \"r\") as f:\n",
    "        #     data = json.load(f)\n",
    "        #     data.append(self.prompt_history)\n",
    "            \n",
    "        # with open(\"prompt_history_hierarchical.json\", \"w\") as f:\n",
    "        #     json.dump(data, f, indent=4)\n",
    "                \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatAnthropic(temperature=1.0, model=\"claude-3-5-sonnet-20240620\")\n",
    "llm = ChatOpenAI(temperature=1.0, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt design team members\n",
    "style_and_structure_principles = CorePrinciples([\n",
    "    \"Always structure prompts logically for the task\",\n",
    "    \"Always use a style and tone in prompts that is appropriate for the task\",\n",
    "    \"Always design prompts appropriately for the task's complexity\",\n",
    "])\n",
    "style_and_structure_expert = WorkerAgent(\"Style_and_Structure_Expert\", style_and_structure_principles, llm)\n",
    "\n",
    "conciseness_and_clarity_principles = CorePrinciples([\n",
    "    \"Always write clear and concise prompts\",\n",
    "    \"Always use simple and direct language in prompts\",\n",
    "    \"Always avoid ambiguity in prompts\",\n",
    "])\n",
    "conciseness_and_clarity_expert = WorkerAgent(\"Conciseness_and_Clarity_Expert\", conciseness_and_clarity_principles, llm)\n",
    "\n",
    "contextual_relevance_principles = CorePrinciples([\n",
    "    \"Always provide context to help the model understand the task\",\n",
    "    \"Always write prompts informed by the context of the task\",\n",
    "    \"Always design contextually relevant personas and roles in prompts\",\n",
    "])\n",
    "contextual_relevance_expert = WorkerAgent(\"Contextual_Relevance_Expert\", contextual_relevance_principles, llm)\n",
    "\n",
    "task_alignment_principles = CorePrinciples([\n",
    "    \"Always write prompts that align with the task criteria\",\n",
    "    \"Always tailor instructions to the task to guide the model\",\n",
    "    \"Always make the task abundantly clear to the model in the prompt\"\n",
    "])\n",
    "task_alignment_expert = WorkerAgent(\"Task_Alignment_Expert\", task_alignment_principles, llm)\n",
    "\n",
    "example_demonstration_principal = CorePrinciples([\n",
    "    \"Always provide examples to help the model understand the task\",\n",
    "    \"Always provide examples that cover a range of complexities\",\n",
    "    \"Always demonstrate the expected output of the model\",\n",
    "])\n",
    "example_demonstration_expert = WorkerAgent(\"Example_Demonstration_Expert\", example_demonstration_principal, llm)\n",
    "\n",
    "avoiding_bias_principles = CorePrinciples([\n",
    "    \"Always avoid bias in prompts\",\n",
    "    \"Always consider the ethical implications of prompts\",\n",
    "])\n",
    "avoiding_bias_expert = WorkerAgent(\"Avoiding_Bias_Expert\", avoiding_bias_principles)\n",
    "\n",
    "incremental_prompting_principles = CorePrinciples([\n",
    "    \"Always write clear step-by-step instructions to guide the model\",\n",
    "    \"Always write instructions tailored to an AI model's learning process\",\n",
    "    \"Always write instructions appropriate for the task complexity\",\n",
    "])\n",
    "incremental_prompting_expert = WorkerAgent(\"Incremental_Prompting_Expert\", incremental_prompting_principles, llm)\n",
    "\n",
    "programming_logic_principles = CorePrinciples([\n",
    "    \"Always write pormpts following programming logic principles (loops, conditionals, functions, pseudo-code, etc.)\",\n",
    "    \"Always structure prompts as if you were writing code\",\n",
    "    \"Always leave comments in plain english to explain programming logic\",\n",
    "])\n",
    "programming_logic_expert = WorkerAgent(\"Programming_Logic_Expert\", programming_logic_principles, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain team members\n",
    "mathematics_principles = CorePrinciples([\n",
    "    \"Always stop to think and develop a mathetcically sound plan to solve problems\",\n",
    "    \"Always make an initial estimate of the answer before solving the problem\",\n",
    "    \"Always use mathetical operators (addition, subtraction, multiplication, division) correctly\",\n",
    "    \"Always double-check mathematical calculations\",\n",
    "])\n",
    "mathematician = WorkerAgent(\"Mathematician\", mathematics_principles, llm)\n",
    "\n",
    "word_problem_solving_principles = CorePrinciples([\n",
    "    \"Always read the problem slowly and carefully to identify what the problem is asking you to find\",\n",
    "    \"Always list the given facts and unknown facts\",\n",
    "    \"Always rewrite the problem and facts in a more organized manner\",\n",
    "    \"Always consider multiple approaches to solving problems\",\n",
    "])\n",
    "word_problem_solver = WorkerAgent(\"Word_Problem_Solver\", word_problem_solving_principles, llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams and members:\n",
      "Lead_Prompt_Writer team:\n",
      "Position: Style_and_Structure_Expert, Core Principles: \n",
      "- Always structure prompts logically for the task\n",
      "- Always use a style and tone in prompts that is appropriate for the task\n",
      "- Always design prompts appropriately for the task's complexity\n",
      "Position: Conciseness_and_Clarity_Expert, Core Principles: \n",
      "- Always write clear and concise prompts\n",
      "- Always use simple and direct language in prompts\n",
      "- Always avoid ambiguity in prompts\n",
      "Position: Contextual_Relevance_Expert, Core Principles: \n",
      "- Always provide context to help the model understand the task\n",
      "- Always write prompts informed by the context of the task\n",
      "- Always design contextually relevant personas and roles in prompts\n",
      "Position: Task_Alignment_Expert, Core Principles: \n",
      "- Always write prompts that align with the task criteria\n",
      "- Always tailor instructions to the task to guide the model\n",
      "- Always make the task abundantly clear to the model in the prompt\n",
      "Position: Example_Demonstration_Expert, Core Principles: \n",
      "- Always provide examples to help the model understand the task\n",
      "- Always provide examples that cover a range of complexities\n",
      "- Always demonstrate the expected output of the model\n",
      "Position: Incremental_Prompting_Expert, Core Principles: \n",
      "- Always write clear step-by-step instructions to guide the model\n",
      "- Always write instructions tailored to an AI model's learning process\n",
      "- Always write instructions appropriate for the task complexity\n",
      "----\n",
      "Lead_Problem_Solver team:\n",
      "Position: Word_Problem_Solver, Core Principles: \n",
      "- Always read the problem slowly and carefully to identify what the problem is asking you to find\n",
      "- Always list the given facts and unknown facts\n",
      "- Always rewrite the problem and facts in a more organized manner\n",
      "- Always consider multiple approaches to solving problems\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"{content}\\nPlease output your answer at the end as ##<your answer (among A through C)>.\"\n",
    "criteria = \"\"\"- The prompt MUST instruct the LLM to solve the object tracking problem.\n",
    "- The prompt MUST include the content placeholder (this is where the object tracking problem will be).\n",
    "- The prompt MUST instruct the LLM to provide the answer at the end of the output exactly as ##<answer (among A through C)>.\n",
    "- The prompt MUST instruct the LLM to provide the answer with no spaces between the ## and the answer.\"\"\"\n",
    "\n",
    "prompt_design_team = TeamLeaderAgent(\n",
    "    \"Lead_Prompt_Writer\",\n",
    "    CorePrinciples([\n",
    "        \"Always pay close attention to prompt design details\",\n",
    "        \"Always make informed decisions with regards to prompt design\",\n",
    "        \"Always be open-minded to feedback\",\n",
    "    ]),\n",
    "    base_prompt,\n",
    "    criteria,\n",
    "    workforce=[\n",
    "        style_and_structure_expert,\n",
    "        conciseness_and_clarity_expert,\n",
    "        contextual_relevance_expert,\n",
    "        task_alignment_expert,\n",
    "        example_demonstration_expert,\n",
    "        incremental_prompting_expert,\n",
    "    ]\n",
    ")\n",
    "domain_team = TeamLeaderAgent(\n",
    "    \"Lead_Problem_Solver\",\n",
    "    CorePrinciples([\n",
    "        \"Always read the problem carefully to identify the domain of the problem\",\n",
    "        \"Always highlight key information in the problem\",\n",
    "        \"Always double-check your work\",\n",
    "        \"Always be open-minded to feedback\",\n",
    "    ]),\n",
    "    base_prompt,\n",
    "    criteria,\n",
    "    workforce=[\n",
    "        # mathematician,\n",
    "        word_problem_solver,\n",
    "    ]\n",
    ")\n",
    "\n",
    "leader_agent = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    criteria=criteria,\n",
    "    team_leaders=[prompt_design_team, domain_team]\n",
    ")\n",
    "\n",
    "# leader_agent.generate_teams()\n",
    "# print teams and members\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent.team_leaders:\n",
    "    print(f\"{team_leader.position} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Core Principles: \\n{worker.core_principles}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approval results: [{'team': 'Lead_Prompt_Writer', 'decision': 'False'}, {'team': 'Lead_Problem_Solver', 'decision': 'True'}]\n",
      "Style_and_Structure_Expert\n",
      "Task_Alignment_Expert\n",
      "Conciseness_and_Clarity_Expert\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lead_Prompt_Writer\n",
      "\n",
      "### Revised Prompt\n",
      "\n",
      "Based on the extensive feedback and recommendations aimed at improving clarity, conciseness, structure, and readability, the following prompt revision addresses all the requirements while adhering strictly to the provided guidelines:\n",
      "\n",
      "```\n",
      "Solve the object tracking problem below:\n",
      "\n",
      "{content}\n",
      "\n",
      "Submit your answer at the end in the format ##<answer (among A through C)> without spaces.\n",
      "```\n",
      "\n",
      "### Explanation\n",
      "\n",
      "1. **Instruction to Solve the Object Tracking Problem:**\n",
      "   - The revised version of the prompt starts with a clear instruction: \"Solve the object tracking problem below.\"\n",
      "\n",
      "2. **Inclusion of Content Placeholder:**\n",
      "   - The placeholder `{content}` remains in place and unchanged, ensuring the problem statement can be dynamically populated.\n",
      "\n",
      "3. **Instruction to Provide the Answer with Specific Format:**\n",
      "   - The prompt specifies that the answer should be in the format ##<answer (among A through C)>.\n",
      "   - It explicitly states that no spaces should be present between the ## and the answer for clarity.\n",
      "\n",
      "### Summary\n",
      "\n",
      "- **Clarity:** The language is straightforward and unambiguous, meeting the criterion for instructions.\n",
      "- **Conciseness:** Redundant phrases have been removed to keep instructions brief and to the point.\n",
      "- **Structure:** The prompt is logically structured to ensure the LLM focuses on solving the problem and providing the answer in the specified format.\n",
      "\n",
      "This updated version of the prompt adheres to all success criteria and strict guidelines while incorporating feedback to enhance clarity and conciseness.\n",
      "Approval results: [{'team': 'Lead_Prompt_Writer', 'decision': 'True'}, {'team': 'Lead_Problem_Solver', 'decision': 'True'}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Leader\n",
      "\n",
      "Let's review the conversation step-by-step based on both the success criteria and the strict guidelines:\n",
      "\n",
      "### Success Criteria Review\n",
      "\n",
      "1. **The prompt MUST instruct the LLM to solve the object tracking problem:**\n",
      "   - The revised prompt starts with \"Solve the object tracking problem below:\" which instructs the LLM to solve the problem.\n",
      "\n",
      "2. **The prompt MUST include the content placeholder:**\n",
      "   - The placeholder `{content}` is correctly included in the revised prompt.\n",
      "  \n",
      "3. **The prompt MUST instruct the LLM to provide the answer at the end of the output exactly as ##<answer (among A through C)>:**\n",
      "   - The revised prompt specifies \"Submit your answer at the end in the format ##<answer (among A through C)>\".\n",
      "  \n",
      "4. **The prompt MUST instruct the LLM to provide the answer with no spaces between the ## and the answer:**\n",
      "   - The revised prompt explicitly states \"without spaces.\"\n",
      "\n",
      "### Strict Guidelines Review\n",
      "\n",
      "1. **DO NOT modify existing restrictions:**\n",
      "   - There are no modifications to restrictions in the revised prompt.\n",
      "\n",
      "2. **DO NOT modify or remove negations:**\n",
      "   - There are no negations modified or removed in the revised prompt.\n",
      "\n",
      "3. **DO NOT add, modify or remove placeholders denoted by curly braces:**\n",
      "   - The placeholder `{content}` remains untouched in the revised prompt.\n",
      "\n",
      "4. **ALWAYS treat placeholders as the actual content:**\n",
      "   - The placeholder has been treated appropriately to represent the actual content.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The revised prompt meets all success criteria and adheres strictly to the guidelines. However, I believe some minor improvements can be made to further enhance clarity and conciseness:\n",
      "\n",
      "### Final Revised Prompt\n",
      "\n",
      "```\n",
      "Solve the object tracking problem below:\n",
      "\n",
      "{content}\n",
      "\n",
      "Submit your answer in the format ##<answer (among A through C)> without spaces.\n",
      "```\n",
      "\n",
      "This version retains all necessary details and instructions while being as clear and concise as possible. This prompt revision:\n",
      "\n",
      "1. Clearly instructs on what needs to be solved.\n",
      "2. Includes the placeholder for content.\n",
      "3. Specifies the required answer format and ensures no spaces between the `##` and the answer.\n",
      "\n",
      "This ensures that all criteria are met and follows all guidelines strictly.\n"
     ]
    }
   ],
   "source": [
    "result = leader_agent.optimise_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Leader\n",
      "\n",
      "Let's review the conversation step-by-step based on both the success criteria and the strict guidelines:\n",
      "\n",
      "### Success Criteria Review\n",
      "\n",
      "1. **The prompt MUST instruct the LLM to solve the object tracking problem:**\n",
      "   - The revised prompt starts with \"Solve the object tracking problem below:\" which instructs the LLM to solve the problem.\n",
      "\n",
      "2. **The prompt MUST include the content placeholder:**\n",
      "   - The placeholder `{content}` is correctly included in the revised prompt.\n",
      "  \n",
      "3. **The prompt MUST instruct the LLM to provide the answer at the end of the output exactly as ##<answer (among A through C)>:**\n",
      "   - The revised prompt specifies \"Submit your answer at the end in the format ##<answer (among A through C)>\".\n",
      "  \n",
      "4. **The prompt MUST instruct the LLM to provide the answer with no spaces between the ## and the answer:**\n",
      "   - The revised prompt explicitly states \"without spaces.\"\n",
      "\n",
      "### Strict Guidelines Review\n",
      "\n",
      "1. **DO NOT modify existing restrictions:**\n",
      "   - There are no modifications to restrictions in the revised prompt.\n",
      "\n",
      "2. **DO NOT modify or remove negations:**\n",
      "   - There are no negations modified or removed in the revised prompt.\n",
      "\n",
      "3. **DO NOT add, modify or remove placeholders denoted by curly braces:**\n",
      "   - The placeholder `{content}` remains untouched in the revised prompt.\n",
      "\n",
      "4. **ALWAYS treat placeholders as the actual content:**\n",
      "   - The placeholder has been treated appropriately to represent the actual content.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The revised prompt meets all success criteria and adheres strictly to the guidelines. However, I believe some minor improvements can be made to further enhance clarity and conciseness:\n",
      "\n",
      "### Final Revised Prompt\n",
      "\n",
      "```\n",
      "Solve the object tracking problem below:\n",
      "\n",
      "{content}\n",
      "\n",
      "Submit your answer in the format ##<answer (among A through C)> without spaces.\n",
      "```\n",
      "\n",
      "This version retains all necessary details and instructions while being as clear and concise as possible. This prompt revision:\n",
      "\n",
      "1. Clearly instructs on what needs to be solved.\n",
      "2. Includes the placeholder for content.\n",
      "3. Specifies the required answer format and ensures no spaces between the `##` and the answer.\n",
      "\n",
      "This ensures that all criteria are met and follows all guidelines strictly.\n"
     ]
    }
   ],
   "source": [
    "result['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

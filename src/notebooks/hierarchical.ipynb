{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, StateGraph, MessageGraph\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import List, Sequence, TypedDict, Annotated\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = \"Hierarchical Optimisation\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import Client\n",
    "\n",
    "# client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptReview(BaseModel):\n",
    "    \"\"\"Review of the prompt\"\"\"\n",
    "    # prompt: str = Field(description=\"Most recent prompt\")\n",
    "    feedback: str = Field(description=\"Feedback on the most recent prompt\")\n",
    "\n",
    "class WorkerPrinciples:\n",
    "    def __init__(self, core_principles: List[str]):\n",
    "        self.core_principles = core_principles\n",
    "    \n",
    "    def add_principle(self, principle: str):\n",
    "        \"\"\"\n",
    "        Adds a principle to the core principles list.\n",
    "        \n",
    "        :param principle: The principle to be added.\n",
    "        \"\"\"\n",
    "        self.core_principles.append(principle)\n",
    "        \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation of the core principles, each principle is listed on a new line with a preceding dash.\n",
    "        \n",
    "        Example:\n",
    "        - principle 1\n",
    "        - principle 2\n",
    "        ...\n",
    "        \"\"\"\n",
    "        return \"\\n\".join([f\"- {principle}\" for principle in self.core_principles])\n",
    "\n",
    "class WorkerAgent:\n",
    "    \"\"\"\n",
    "    Worker Agent class defining agents that provide feedback on prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, position: str, core_principles: WorkerPrinciples, temp: float = 1.0, model: str = \"gpt-4o\"):\n",
    "        self.position = position\n",
    "        self.core_principles = str(core_principles)\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an experienced: {self.position}. Your core principles are:\n",
    "{self.core_principles}\n",
    "You must use your expertise and core principles to guide all your thinking. You must speak only as an expert in your field.\"\"\")        \n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "\n",
    "    def review_prompt(self, prompt: str, additional_info: str) -> PromptReview:\n",
    "        \"\"\"\n",
    "        Generates a review of the prompt.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Your task is to think outside the box and provide feedback on the prompt below with creative recommendations on how to improve it in light of your core principles:\n",
    "{prompt}\n",
    "\n",
    "Your feedback must be less than 100 words so think carefully about the most critical aspects of the prompt that need improvement.\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do:\n",
    "{additional_info}\n",
    "\n",
    "Below are strict guidelines that you MUST follow when providing feedback and recommendations:\n",
    "- DO NOT suggest modifying existing restrictions.\n",
    "- DO NOT suggest modifying or removing negations.\n",
    "- DO NOT suggest adding, modifying or removing placeholders denoted by curly braces. IT IS ESSENTIAL PLACEHOLDERS REMAIN UNCHANGED.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt carefully as an expert {position}. \n",
    "2. Identify the most critical aspects of the prompt that need improvement. \n",
    "3. Think outside the box to provide creative feedback with recommendations on how to improve the prompt in light of your core principles.\n",
    "4. Ensure that your feedback is less than 100 words.\n",
    "5. Ensure that your feedback follows the strict guidelines provided above.\n",
    "6. Submit your feedback.\n",
    "\n",
    "Return only your feedback in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"feedback\": \"Feedback on the original prompt\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=PromptReview)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"position\", \"prompt\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                completion = chain.invoke({\"position\": self.position, \"prompt\": prompt, \"additional_info\": additional_info})\n",
    "                # Validate the output before returning\n",
    "                if completion.feedback:\n",
    "                    return completion\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", completion)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        else:\n",
    "            raise Exception(\"Failed to parse output after 3 attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Workforce(BaseModel):\n",
    "    \"\"\"Details of workforce generated by the leader agent.\"\"\"\n",
    "    positions: List[str] = Field(description=\"Positions of the workers in the workforce\")\n",
    "    core_principles: List[List[str]] = Field(description=\"Core principles of the workers in the workforce\")\n",
    "    \n",
    "\n",
    "class FeedbackSummary(BaseModel):\n",
    "    \"\"\"Summary of feedback from the worker agents.\"\"\"\n",
    "    feedback_summary: str = Field(description=\"Collated and summarised feedback from the workforce\")\n",
    "\n",
    "\n",
    "class ApprovalDecision(BaseModel):\n",
    "    \"\"\"Decision of the leader agent to approve or disapprove the prompt.\"\"\"\n",
    "    approved: bool = Field(description=\"Decision to approve or disapprove the prompt\")\n",
    "    explanation: str = Field(description=\"A detailed explanation of why the prompt was approved or not\")\n",
    "\n",
    "\n",
    "class TeamLeaderAgent:\n",
    "    \"\"\"\n",
    "    TeamLeaderAgent class defining an agent that manages a team of worker agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, team: str, team_role: str, prompt: str, additional_info: str = None, temp: float = 1.0, model: str = \"gpt-4o\", workforce: List[WorkerAgent] = None):\n",
    "        self.team = team\n",
    "        self.team_role = team_role\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an experienced {team} team leader with expertise in leading a team with the role: {team_role}. \n",
    "You must use your expertise to guide all your thinking. You must speak only as an expert in your field.\"\"\")\n",
    "        self.prompt = prompt\n",
    "        self.additional_info = additional_info\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "        self.workforce = workforce\n",
    "\n",
    "    def leader_feedback(self, prompt: str, feedback: list) -> str:\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next worker or to finish.\n",
    "        \"\"\"\n",
    "        # All workers except the current worker\n",
    "        template = \"\"\"Your task is to refine and summarise the feedback below:\n",
    "{feedback}\n",
    "\n",
    "You must capture the important aspects of the feedback and recommendations provided by your team.\n",
    "Your summary must be actionable and precise, providing clear recommendations for improvements to the prompt below:\n",
    "{prompt}\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do:\n",
    "{additional_info}\n",
    "\n",
    "Below are strict guidelines that you MUST follow when summarising feedback and recommendations:\n",
    "- DO NOT suggest modifying existing restrictions.\n",
    "- DO NOT suggest modifying or removing negations.\n",
    "- DO NOT suggest adding, modifying or removing placeholders denoted by curly braces. IT IS ESSENTIAL PLACEHOLDERS REMAIN UNCHANGED.\n",
    "\n",
    "Your summarisation process should be as follows:\n",
    "1. Read the feedback carefully as an experienced {team} team leader.\n",
    "2. Identify the important aspects of the feedback and recommendations provided by your team.\n",
    "3. Refine and summarise the feedback and recommendations into a concise and actionable summary.\n",
    "4. Ensure that your summary adheres to the strict guidelines provided above.\n",
    "5. Ensure that your summary is actionable and precise, providing clear recommendations for improvements to the prompt.\n",
    "6. Submit your summary.\n",
    "\n",
    "Return only the feedback summary in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"feedback_summary\": \"Feedback summary\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=FeedbackSummary)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"feedback\", \"prompt\", \"additional_info\", \"team\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"feedback\": feedback, \"prompt\": prompt, \"additional_info\": self.additional_info, \"team\": self.team})\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        return output.feedback_summary\n",
    "       \n",
    "    def get_feedback(self, state):\n",
    "        \"\"\"\n",
    "        Get feedback from wokers. Feedback collected concurrently.\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "            futures = [executor.submit(worker.review_prompt, state['prompt'], self.additional_info) for worker in self.workforce]\n",
    "            results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "            # feedback = [result[-1].content for result in results]\n",
    "            feedback = [result.feedback for result in results]\n",
    "\n",
    "        summary = self.leader_feedback(state[\"prompt\"], feedback)\n",
    "\n",
    "        return summary\n",
    "    \n",
    "    def get_approval(self, prompt: str):\n",
    "        \"\"\"\n",
    "        Agent to approve or reject the prompt.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Your task is to review the prompt below and decide whether or not it should be approved in light of your team and team role:\n",
    "{prompt}\n",
    "\n",
    "Return the boolean value \"True\" if you approve and think the prompt already optimal in the aspects your team:, {members} specialises in. \n",
    "Return the boolean value \"False\" if you disapprove and think the prompt could be improved with the insights of your team.\n",
    "You must provide a detailed explanation of why you approve or disapprove of the prompt.\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do:\n",
    "{additional_info}\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt carefully as an expert in {team}\n",
    "2. Determine whether the prompt will be effective in instructing the model to perform the desired task.\n",
    "3. If you believe the prompt is effective, approve it for use by the model.\n",
    "4. Submit your decision.\n",
    "    \n",
    "Return only the approval decision and explanation in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"approved\": \"True/False\"\n",
    "    \"explanation\": \"Detailed explanation of why the prompt was approved or not\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=ApprovalDecision)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"prompt\", \"members\", \"additional_info\", \"team\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                completion = chain.invoke({\"prompt\": prompt, \"members\": [worker.position for worker in self.workforce], \"additional_info\": self.additional_info, \"team\": self.team})\n",
    "                # Validate the output before returning\n",
    "                if completion.approved is not None and completion.explanation:\n",
    "                    return completion.approved\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", completion)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "        else:\n",
    "            raise Exception(\"Failed to parse output after 3 attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Domain(BaseModel):\n",
    "    \"\"\"Domain of the prompt.\"\"\"\n",
    "    domain: str = Field(description=\"Domain of the prompt\")\n",
    "    description: str = Field(description=\"Description of the domain team role\")\n",
    "\n",
    "\n",
    "class RouteDecision(BaseModel):\n",
    "    \"\"\"Decision on the next worker to process.\"\"\"\n",
    "    next: str = Field(description=\"The next team to process\")\n",
    "\n",
    "\n",
    "class UpdatedPrompt(BaseModel):\n",
    "    \"\"\"Updated prompt based on feedback from the team leader.\"\"\"\n",
    "    updated_prompt: str = Field(description=\"Updated prompt based on feedback\")\n",
    "\n",
    "\n",
    "class LeaderAgent:\n",
    "    \"\"\"\n",
    "    LeaderAgent class defining an agent that generates and communicates worker agents to help optimise prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_prompt: str, additional_info: str = None, temp: float = 1.0, model: str = \"gpt-4o\", team_leaders: List[TeamLeaderAgent] = None):\n",
    "        self.system_message = SystemMessage(content=f\"\"\"You are an experienced senior AI professional. You specialise in prompt engineering. \n",
    "You have in-depth knowledge of large language models and prompt engineering best practices. Use this knowledge to inform all your decisions.\"\"\")\n",
    "        self.base_prompt = base_prompt\n",
    "        self.prompt = base_prompt\n",
    "        self.additional_info = additional_info\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temp,\n",
    "            model=model,\n",
    "        )\n",
    "        self.team_leaders = team_leaders\n",
    "        self.team_roles_dict = {team_leader.team: team_leader.team_role for team_leader in self.team_leaders}\n",
    "        self.iterations = 0\n",
    "    \n",
    "    def run_approval(self, prompt: str) -> List[bool]:\n",
    "        \"\"\"\n",
    "        Run the approval process for the prompt. Run concurrently\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(team_leader.get_approval, prompt) for team_leader in self.team_leaders]\n",
    "            results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "        return results\n",
    "    \n",
    "    def leader_decision(self, state: dict) -> RouteDecision:\n",
    "        \"\"\"\n",
    "        LeaderAgent to decide the next worker or to finish.\n",
    "        \"\"\"\n",
    "        self.iterations += 1\n",
    "        approval_results = self.run_approval(state[\"prompt\"])\n",
    "        print(\"Approval results:\", approval_results)\n",
    "        if all(approval_results) or (self.iterations > 10):\n",
    "            return {\"next\": \"FINISH\", \"prompt\": state[\"prompt\"], \"messages\": state[\"messages\"]} \n",
    "        else:\n",
    "            self.iterations += 1\n",
    "            disapproved_team_leaders = [team_leader for i, team_leader in enumerate(self.team_leaders) if not approval_results[i]]\n",
    "            options = [team_leaders.team for team_leaders in disapproved_team_leaders]\n",
    "            # shuffle options to avoid positional bias\n",
    "            random.shuffle(options)\n",
    "            # options = [\"FINISH\"] + members\n",
    "            template = \"\"\"Your task is to review the prompt below and decide the next team to provide feedback:\n",
    "{prompt}\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do: \n",
    "{additional_info}\n",
    "\n",
    "The details of the teams and their roles are as follows: \n",
    "{team_roles}\n",
    "\n",
    "Select one of the following teams to provide feedback on the prompt: \n",
    "{options}\n",
    "\n",
    "Think carefully about pairing the aspects of the prompt that need improvement and how they relate to the expertise of each team.\n",
    "If you think multiple aspects of the prompt need improvement, select the most suitable team to provide feedback on the most critical aspects of the prompt.\n",
    "\n",
    "Return only the next team name to process in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"next\": \"Next team\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "            pydantic_parser = PydanticOutputParser(pydantic_object=RouteDecision)\n",
    "            prompt_template = PromptTemplate(\n",
    "                system_message=self.system_message,\n",
    "                template=template,\n",
    "                input_variables=[\"prompt\", \"additional_info\", \"team_roles\", \"options\"],\n",
    "                partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "            )\n",
    "            chain = prompt_template | self.llm | pydantic_parser\n",
    "            for _ in range(3):\n",
    "                try:\n",
    "                    output = chain.invoke({\"prompt\": state[\"prompt\"], \"additional_info\": self.additional_info, \"team_roles\": str(self.team_roles_dict), \"options\": str(options)})\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(\"Exception occurred:\", e)\n",
    "                    continue\n",
    "            return {\"next\": output.next, \"prompt\": state[\"prompt\"], \"messages\": state[\"messages\"]}\n",
    "\n",
    "    def update_prompt(self, prompt: str, feedback: str, history) -> str:\n",
    "        \"\"\"\n",
    "        Updates the prompt with the feedback from the worker agent.\n",
    "        \"\"\"\n",
    "        template = \"\"\"Your task is to implement feedback to improve the prompt below:\n",
    "{prompt}\n",
    "\n",
    "The feedback is as follows:\n",
    "{feedback} \n",
    "\n",
    "You must also consider the discussion history below prior to making changes to the prompt to ensure you do not repeat any mistakes: \n",
    "{history}\n",
    "\n",
    "Below are details of what the prompt is expected to instruct the model to do:\n",
    "{additional_info}\n",
    "\n",
    "Below are strict guidelines that you MUST follow if making changes to the prompt:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces. IT IS ESSENTIAL PLACEHOLDERS REMAIN UNCHANGED.\n",
    "\n",
    "Your update process should be as follows:\n",
    "1. Read the prompt and feedback carefully.\n",
    "2. Review the discussion history to ensure you do not repeat any mistakes.\n",
    "3. Implement the feedback provided to help the prompt better achieve what is expected.\n",
    "4. Ensure that your update follows the strict guidelines provided above.\n",
    "5. Submit your updated prompt.\n",
    "\n",
    "Return only the updated prompt in JSON format:\n",
    "\n",
    "{{\n",
    "    \"prompt\": \"Updated prompt\"\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=UpdatedPrompt)\n",
    "        prompt_template = PromptTemplate(\n",
    "            system_message=self.system_message,\n",
    "            template=template,\n",
    "            input_variables=[\"prompt\", \"feedback\", \"history\", \"additional_info\"],\n",
    "            partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "        )\n",
    "        chain = prompt_template | self.llm | pydantic_parser\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = chain.invoke({\"prompt\": prompt, \"feedback\": feedback, \"history\": history, \"additional_info\": self.additional_info})\n",
    "                if output.updated_prompt:\n",
    "                    return output.updated_prompt\n",
    "                else:\n",
    "                    print(\"Validation failed: Missing required fields in completion\")\n",
    "                    print(\"Raw output:\", output)\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred:\", e)\n",
    "                continue\n",
    "\n",
    "    def construct_team_graph(self):\n",
    "        \"\"\"\n",
    "        Constructs a graph of team leader agents.\n",
    "        \"\"\"\n",
    "        # The agent state is the input to each node in the graph\n",
    "        class TeamState(TypedDict):\n",
    "            # The annotation tells the graph that new messages will always be added to the current states\n",
    "            messages: Sequence[BaseMessage]\n",
    "            prompt: str\n",
    "            next: str\n",
    "\n",
    "        def team_node(state, team_leader):\n",
    "            try:\n",
    "                feedback = team_leader.get_feedback(state)\n",
    "                updated_prompt = self.update_prompt(state[\"prompt\"], feedback, state[\"messages\"])\n",
    "                # updated_prompt = output[-1].content \n",
    "                self.prompt = updated_prompt\n",
    "                return {\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(content=f\"Feedback: {feedback}\", name=team_leader.team),\n",
    "                        AIMessage(content=f\"Updated Prompt: {updated_prompt}\", name=\"Leader\")\n",
    "                    ],\n",
    "                    \"prompt\": updated_prompt,\n",
    "                }\n",
    "            except Exception as e:\n",
    "                # Log the error and return to leader with the most recent prompt\n",
    "                print(f\"Parsing failed for {team_leader.team}: {e}\")\n",
    "                return {\n",
    "                    \"messages\": state[\"messages\"] + [\n",
    "                        HumanMessage(content=f\"Error: Parsing failed for {team_leader} - {e}\", name=team_leader.team),\n",
    "                        AIMessage(content=f\"Updated Prompt: {updated_prompt}\", name=\"Leader\")\n",
    "                    ],                    \n",
    "                    \"prompt\": state[\"prompt\"],\n",
    "                    \"next\": \"leader\",\n",
    "                }\n",
    "\n",
    "        workflow = StateGraph(TeamState)\n",
    "        for team_leader in self.team_leaders:\n",
    "            # Create a node for each team leader agent\n",
    "            # team_leader.construct_worker_graph()\n",
    "            node = functools.partial(team_node, team_leader=team_leader)\n",
    "            workflow.add_node(team_leader.team, node)\n",
    "        workflow.add_node(\"leader\", self.leader_decision)\n",
    "\n",
    "        members = [team_leader.team for team_leader in self.team_leaders]\n",
    "        for member in members:\n",
    "            # We want our workers to ALWAYS \"report back\" to the leader when done\n",
    "            workflow.add_edge(member, \"leader\")\n",
    "        # The leader populates the \"next\" field in the graph state with routes to a node or finishes\n",
    "        conditional_map = {k: k for k in members}\n",
    "        conditional_map[\"FINISH\"] = END\n",
    "        workflow.add_conditional_edges(\"leader\", lambda x: x[\"next\"], conditional_map)\n",
    "        # Finally, add entrypoint\n",
    "        workflow.set_entry_point(\"leader\")\n",
    "        graph = workflow.compile()\n",
    "        \n",
    "        return graph\n",
    "    \n",
    "    def optimise_prompt(self):\n",
    "        \"\"\"\n",
    "        Optimises a prompt by invoking a graph of worker agents.\n",
    "        \"\"\"\n",
    "        # Initial state\n",
    "        initial_state = {\n",
    "            \"messages\": [HumanMessage(content=f\"{self.base_prompt}\", name=\"User\")],\n",
    "            \"prompt\": self.base_prompt,\n",
    "            \"next\": \"leader\",\n",
    "        }\n",
    "\n",
    "        # Construct the graph\n",
    "        graph = self.construct_team_graph()\n",
    "        # display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "        # Run the graph\n",
    "        for s in graph.stream(\n",
    "            initial_state,\n",
    "            {\"recursion_limit\": 50}\n",
    "            ):\n",
    "            if \"__end__\" not in s:\n",
    "                print(s)\n",
    "                print(\"----\")\n",
    "                continue\n",
    "\n",
    "        # if not os.path.exists(\"prompt_history_hierarchical.json\"):\n",
    "        #     with open(\"prompt_history_hierarchical.json\", \"w\") as f:\n",
    "        #         json.dump([], f)\n",
    "        \n",
    "        # with open(\"prompt_history_hierarchical.json\", \"r\") as f:\n",
    "        #     data = json.load(f)\n",
    "        #     data.append(self.prompt_history)\n",
    "            \n",
    "        # with open(\"prompt_history_hierarchical.json\", \"w\") as f:\n",
    "        #     json.dump(data, f, indent=4)\n",
    "                \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iwatson/Documents/Research Project/prompt-optimisation/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Prompt design team members\n",
    "conciseness_and_clarity_principles = WorkerPrinciples([\n",
    "    \"Always write clear and concise prompts\",\n",
    "    \"Always use simple and direct language to communicate ideas\",\n",
    "    \"Always consider the task requirements when formatting and structuring prompts\",\n",
    "])\n",
    "conciseness_and_clarity_expert = WorkerAgent(\"Conciseness and Clarity Expert\", conciseness_and_clarity_principles)\n",
    "\n",
    "contextual_relevance_principles = WorkerPrinciples([\n",
    "    \"Always provide context to help the model understand the task\",\n",
    "    \"Always consider the context in which prompts will be used\",\n",
    "])\n",
    "contextual_relevance_expert = WorkerAgent(\"Contextual Relevance Expert\", contextual_relevance_principles)\n",
    "\n",
    "task_alignment_principles = WorkerPrinciples([\n",
    "    \"Always ensure that prompts align with the task requirements\",\n",
    "    \"Always tailor instructions to the task to guide the model\",\n",
    "    \"Always consider the expected output of the model\",\n",
    "])\n",
    "task_alignment_expert = WorkerAgent(\"Task Alignment Expert\", task_alignment_principles)\n",
    "\n",
    "example_demonstration_principal = WorkerPrinciples([\n",
    "    \"Always provide examples to help the model understand the task\",\n",
    "    \"Always ensure examples are relevant and clear\",\n",
    "    \"Always demonstrate the expected output of the model\",\n",
    "])\n",
    "example_demonstration_expert = WorkerAgent(\"Example Demonstration Expert\", example_demonstration_principal)\n",
    "\n",
    "avoiding_bias_principles = WorkerPrinciples([\n",
    "    \"Always avoid bias in prompts\",\n",
    "    \"Always consider the ethical implications of prompts\",\n",
    "])\n",
    "avoiding_bias_expert = WorkerAgent(\"Avoiding Bias Expert\", avoiding_bias_principles)\n",
    "\n",
    "incremental_prompting_principles = WorkerPrinciples([\n",
    "    \"Always provide clear step-by-step instructions to guide the model\",\n",
    "    \"Always consider the complexity of the task when providing incremental instructions\",\n",
    "])\n",
    "incremental_prompting_expert = WorkerAgent(\"Incremental Prompting Expert\", incremental_prompting_principles)\n",
    "\n",
    "programming_logic_principles = WorkerPrinciples([\n",
    "    \"Always ensure that prompts are logically structured, similar to programming logic\",\n",
    "    \"Always consider the logical flow of instructions in prompts\",\n",
    "    \"Always consider the usefulness of programming logic to the task\",\n",
    "])\n",
    "programming_logic_expert = WorkerAgent(\"Programming Logic Expert\", programming_logic_principles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain team members\n",
    "mathematics_principles = WorkerPrinciples([\n",
    "    \"Always think with a mathematical mindset\",\n",
    "    \"Always use mathetical operators correctly\",\n",
    "    \"Always adhere to mathematical rules\",\n",
    "])\n",
    "mathematician = WorkerAgent(\"Mathematician\", mathematics_principles)\n",
    "\n",
    "word_problem_solving_principles = WorkerPrinciples([\n",
    "    \"Always pay attention to the keywords in the problem\",\n",
    "    \"Always approach problems systematically\",\n",
    "    \"Always consider multiple approaches to solving problems\",\n",
    "])\n",
    "word_problem_solver = WorkerAgent(\"Word Problem Solver\", word_problem_solving_principles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams and members:\n",
      "Prompt Design team:\n",
      "Team Role: Formulate prompts and instructions to elicit high-quality responses from large language models. The focus is to utilise input from prompt experts to improve the prompt.\n",
      "Position: Conciseness and Clarity Expert, Core Principles: - Always write clear and concise prompts\n",
      "- Always use simple and direct language to communicate ideas\n",
      "- Always consider the task requirements when formatting and structuring prompts\n",
      "Position: Contextual Relevance Expert, Core Principles: - Always provide context to help the model understand the task\n",
      "- Always consider the context in which prompts will be used\n",
      "Position: Task Alignment Expert, Core Principles: - Always ensure that prompts align with the task requirements\n",
      "- Always tailor instructions to the task to guide the model\n",
      "- Always consider the expected output of the model\n",
      "Position: Example Demonstration Expert, Core Principles: - Always provide examples to help the model understand the task\n",
      "- Always ensure examples are relevant and clear\n",
      "- Always demonstrate the expected output of the model\n",
      "Position: Avoiding Bias Expert, Core Principles: - Always avoid bias in prompts\n",
      "- Always consider the ethical implications of prompts\n",
      "Position: Incremental Prompting Expert, Core Principles: - Always provide clear step-by-step instructions to guide the model\n",
      "- Always consider the complexity of the task when providing incremental instructions\n",
      "Position: Programming Logic Expert, Core Principles: - Always ensure that prompts are logically structured, similar to programming logic\n",
      "- Always consider the logical flow of instructions in prompts\n",
      "- Always consider the usefulness of programming logic to the task\n",
      "----\n",
      "Mathematics team:\n",
      "Team Role: Formulate prompts and instructions help large language models solve mathematical problems. The focus is to utilise input from domain experts to improve the prompt.\n",
      "Position: Mathematician, Core Principles: - Always think with a mathematical mindset\n",
      "- Always use mathetical operators correctly\n",
      "- Always adhere to mathematical rules\n",
      "Position: Word Problem Solver, Core Principles: - Always pay attention to the keywords in the problem\n",
      "- Always approach problems systematically\n",
      "- Always consider multiple approaches to solving problems\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"{content}. Please output your answer at the end as ##<your answer (arabic numerals)>.\"\n",
    "additional_info = \"- Solve the math word problem.\\n- Output the answer at the end as ##<your answer (arabic numerals)> with no spaces or units.\"\n",
    "\n",
    "prompt_design_team = TeamLeaderAgent(\n",
    "    \"Prompt Design\",\n",
    "    \"Formulate prompts and instructions to elicit high-quality responses from large language models. The focus is to utilise input from prompt experts to improve the prompt.\",\n",
    "    base_prompt,\n",
    "    additional_info,\n",
    "    workforce=[\n",
    "        conciseness_and_clarity_expert,\n",
    "        contextual_relevance_expert,\n",
    "        task_alignment_expert,\n",
    "        example_demonstration_expert,\n",
    "        avoiding_bias_expert,\n",
    "        incremental_prompting_expert,\n",
    "        programming_logic_expert,\n",
    "    ]\n",
    ")\n",
    "domain_team = TeamLeaderAgent(\n",
    "    \"Mathematics\",\n",
    "    \"Formulate prompts and instructions help large language models solve mathematical problems. The focus is to utilise input from domain experts to improve the prompt.\",\n",
    "    base_prompt,\n",
    "    additional_info,\n",
    "    workforce=[\n",
    "        mathematician,\n",
    "        word_problem_solver,\n",
    "    ]\n",
    ")\n",
    "\n",
    "leader_agent = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    "    team_leaders=[prompt_design_team, domain_team]\n",
    ")\n",
    "\n",
    "# leader_agent.generate_teams()\n",
    "# print teams and members\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    print(f\"Team Role: {team_leader.team_role}\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Core Principles: {worker.core_principles}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred: Invalid json output: {\n",
      "    \"approved\": False,\n",
      "    \"explanation\": \"The prompt provided is not clear enough in its instructions. As a Mathematician and Word Problem Solver, I noticed that the instruction to solve the math word problem and output the answer in a specific format (##<your answer (arabic numerals)>= with no spaces or units) could be misinterpreted. For precise communication, it should specify that the answer should be given directly as a number enclosed in double hash symbols with no surrounding text, e.g., ##42##. This ensures clarity and maintains consistency in the format required. Therefore, I disapprove the current version of the prompt and suggest it includes this explicit example.\"\n",
      "}\n",
      "Exception occurred: Invalid json output: ```json\n",
      "{\n",
      "    \"approved\": False,\n",
      "    \"explanation\": \"The prompt requires some improvements to meet the criteria set by the team's specializations. While the prompt is concise and clear, it lacks detailed instructions and example demonstrations that could help the model better understand the task. Additionally, ensuring that no biases or ambiguities are present in the problem description is crucial, and without a specific example, it is difficult to assess that. Furthermore, it doesn't provide incremental guidance if the math word problem is complex. Therefore, it would be beneficial to include an example problem and output format to demonstrate the required structure and help avoid errors.\"\n",
      "}\n",
      "```\n",
      "Approval results: [False, False]\n",
      "{'leader': {'messages': [HumanMessage(content='{content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', name='User')], 'prompt': '{content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', 'next': 'Mathematics'}}\n",
      "----\n",
      "{'Mathematics': {'messages': [HumanMessage(content='{content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content='Feedback: The prompt should explicitly instruct to include all necessary reasoning steps before the final answer to ensure comprehensiveness. Enhance clarity by using bold or bullet points for key instructions and explicitly state to avoid explanatory text, units, or extra spaces. Include an example of correctly formatted output for better understanding.', name='Mathematics'), AIMessage(content=\"Updated Prompt: {content}. **Include all necessary reasoning steps before the final answer to ensure comprehensiveness.** **Avoid explanatory text, units, or extra spaces.** **Output the answer in the format: ##<your answer (arabic numerals)>**. Example of correctly formatted output: '##42'\", name='Leader')], 'prompt': \"{content}. **Include all necessary reasoning steps before the final answer to ensure comprehensiveness.** **Avoid explanatory text, units, or extra spaces.** **Output the answer in the format: ##<your answer (arabic numerals)>**. Example of correctly formatted output: '##42'\"}}\n",
      "----\n",
      "Exception occurred: Invalid json output: ```json\n",
      "{\n",
      "    \"approved\": False,\n",
      "    \"explanation\": \"The prompt is generally well-structured but has some areas that need improvement for optimal clarity and effectiveness. \n",
      "    1. **Conciseness and Clarity Expert**: The prompt is mostly concise but could be more explicit about requiring a logical step-by-step breakdown before the final answer.\n",
      "    2. **Contextual Relevance Expert**: The context seems relevant, but it should specify that the math word problem needs to be solved step-by-step.\n",
      "    3. **Task Alignment Expert**: The task alignment is good, but specifying 'step-by-step' ensures better alignment and detailed debugging if necessary.\n",
      "    4. **Example Demonstration Expert**: The example provided is adequate but adding another example demonstrating step-by-step reasoning will be more illustrative.\n",
      "    5. **Avoiding Bias Expert**: No evident bias in the prompt.\n",
      "    6. **Incremental Prompting Expert**: The prompt is not leveraging step-by-step tasks sufficiently.\n",
      "    7. **Programming Logic Expert**: The format is specified correctly, but a requirement for detailed step-by-step solutions will improve logic consistency.\n",
      "   \n",
      "    Therefore, the prompt could be improved slightly to better align with the assistance requirements.\"\n",
      "}\n",
      "```\n",
      "Exception occurred: Invalid json output: ```json\n",
      "{\n",
      "    \"approved\": False,\n",
      "    \"explanation\": \"The prompt is mostly effective but includes certain areas that require improvements to meet the standards of all specified expert criteria. Firstly, it requires a conciseness and clarity review to ensure the instructions are clear and unambiguous. Secondly, contextual relevance needs to be checked to ensure that only relevant instructions are provided without any potential distractions. Thirdly, task alignment should be revised to ensure the mentioning of 'math word problem' is explicitly clear in the context. Additionally, the prompt might benefit from a slight rephrasing, such as specifying the format for the math problem input or format. Finally, while the example is clear, it may benefit from revision to ensure it demonstrates avoidance of bias and logical progression as per programming logic principles.\"\n",
      "}\n",
      "```\n",
      "Approval results: [False, False]\n",
      "{'leader': {'messages': [HumanMessage(content='{content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content='Feedback: The prompt should explicitly instruct to include all necessary reasoning steps before the final answer to ensure comprehensiveness. Enhance clarity by using bold or bullet points for key instructions and explicitly state to avoid explanatory text, units, or extra spaces. Include an example of correctly formatted output for better understanding.', name='Mathematics'), AIMessage(content=\"Updated Prompt: {content}. **Include all necessary reasoning steps before the final answer to ensure comprehensiveness.** **Avoid explanatory text, units, or extra spaces.** **Output the answer in the format: ##<your answer (arabic numerals)>**. Example of correctly formatted output: '##42'\", name='Leader')], 'prompt': \"{content}. **Include all necessary reasoning steps before the final answer to ensure comprehensiveness.** **Avoid explanatory text, units, or extra spaces.** **Output the answer in the format: ##<your answer (arabic numerals)>**. Example of correctly formatted output: '##42'\", 'next': 'Mathematics'}}\n",
      "----\n",
      "{'Mathematics': {'messages': [HumanMessage(content='{content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content='Feedback: The prompt should explicitly instruct to include all necessary reasoning steps before the final answer to ensure comprehensiveness. Enhance clarity by using bold or bullet points for key instructions and explicitly state to avoid explanatory text, units, or extra spaces. Include an example of correctly formatted output for better understanding.', name='Mathematics'), AIMessage(content=\"Updated Prompt: {content}. **Include all necessary reasoning steps before the final answer to ensure comprehensiveness.** **Avoid explanatory text, units, or extra spaces.** **Output the answer in the format: ##<your answer (arabic numerals)>**. Example of correctly formatted output: '##42'\", name='Leader'), HumanMessage(content=\"Feedback: To enhance the prompt's comprehensiveness and clarity, specify that the reasoning steps should be detailed and complete, and require the explicit stating of any assumptions made. Providing a direct example of reasoning steps for a simplified math problem could help in setting clear expectations for structuring the solution. Lastly, clarify that 'Avoid explanatory text' means the steps should be purely mathematical without descriptive annotations.\", name='Mathematics'), AIMessage(content=\"Updated Prompt: {content}. **Include all necessary reasoning steps before the final answer to ensure comprehensiveness.** **Detail all steps and state any assumptions made.** **Avoid explanatory text, units, or extra spaces.** **Output the answer in the format: ##<your answer (arabic numerals)>**. Example of correctly formatted output: '##42'. Example of reasoning steps: 'Simplify the expression 2 + 2: 2 + 2 = 4, therefore the answer is ##4.'\", name='Leader')], 'prompt': \"{content}. **Include all necessary reasoning steps before the final answer to ensure comprehensiveness.** **Detail all steps and state any assumptions made.** **Avoid explanatory text, units, or extra spaces.** **Output the answer in the format: ##<your answer (arabic numerals)>**. Example of correctly formatted output: '##42'. Example of reasoning steps: 'Simplify the expression 2 + 2: 2 + 2 = 4, therefore the answer is ##4.'\"}}\n",
      "----\n",
      "Approval results: [True, True]\n",
      "{'leader': {'messages': [HumanMessage(content='{content}. Please output your answer at the end as ##<your answer (arabic numerals)>.', name='User'), HumanMessage(content='Feedback: The prompt should explicitly instruct to include all necessary reasoning steps before the final answer to ensure comprehensiveness. Enhance clarity by using bold or bullet points for key instructions and explicitly state to avoid explanatory text, units, or extra spaces. Include an example of correctly formatted output for better understanding.', name='Mathematics'), AIMessage(content=\"Updated Prompt: {content}. **Include all necessary reasoning steps before the final answer to ensure comprehensiveness.** **Avoid explanatory text, units, or extra spaces.** **Output the answer in the format: ##<your answer (arabic numerals)>**. Example of correctly formatted output: '##42'\", name='Leader'), HumanMessage(content=\"Feedback: To enhance the prompt's comprehensiveness and clarity, specify that the reasoning steps should be detailed and complete, and require the explicit stating of any assumptions made. Providing a direct example of reasoning steps for a simplified math problem could help in setting clear expectations for structuring the solution. Lastly, clarify that 'Avoid explanatory text' means the steps should be purely mathematical without descriptive annotations.\", name='Mathematics'), AIMessage(content=\"Updated Prompt: {content}. **Include all necessary reasoning steps before the final answer to ensure comprehensiveness.** **Detail all steps and state any assumptions made.** **Avoid explanatory text, units, or extra spaces.** **Output the answer in the format: ##<your answer (arabic numerals)>**. Example of correctly formatted output: '##42'. Example of reasoning steps: 'Simplify the expression 2 + 2: 2 + 2 = 4, therefore the answer is ##4.'\", name='Leader')], 'prompt': \"{content}. **Include all necessary reasoning steps before the final answer to ensure comprehensiveness.** **Detail all steps and state any assumptions made.** **Avoid explanatory text, units, or extra spaces.** **Output the answer in the format: ##<your answer (arabic numerals)>**. Example of correctly formatted output: '##42'. Example of reasoning steps: 'Simplify the expression 2 + 2: 2 + 2 = 4, therefore the answer is ##4.'\", 'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "result = leader_agent.optimise_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{content}. **Include all necessary reasoning steps before the final answer to ensure comprehensiveness.** **Detail all steps and state any assumptions made.** **Avoid explanatory text, units, or extra spaces.** **Output the answer in the format: ##<your answer (arabic numerals)>**. Example of correctly formatted output: '##42'. Example of reasoning steps: 'Simplify the expression 2 + 2: 2 + 2 = 4, therefore the answer is ##4.'\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"leader\"][\"prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrent Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Prompt Engineering Specialist, Role: Design and refine prompts for optimal performance, Function: Develop and test various prompt structures\n",
      "Position: Sentiment Analysis Expert, Role: Ensure accurate classification of sentiment, Function: Review and fine-tune sentiment detection mechanisms\n",
      "Position: Natural Language Processing Scientist, Role: Implement advanced NLP techniques for prompt optimization, Function: Apply state-of-the-art NLP models and methods to enhance prompt effectiveness\n",
      "----\n",
      "generic team:\n",
      "Position: Natural Language Processing Specialist, Role: Develop and fine-tune NLP models, Function: Implement and refine machine learning models for text classification\n",
      "Position: Sentiment Analysis Expert, Role: Design sentiment classification algorithms, Function: Design and validate sentiment analysis methodologies to accurately classify text as positive or negative\n",
      "Position: Prompt Optimization Engineer, Role: Optimize prompt design and structure, Function: Ensure the prompt is general and robust, minimizing ambiguity and maximizing classification accuracy\n",
      "----\n",
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Prompt Engineer, Role: Design Efficient Prompts, Function: Create and refine the initial prompt to maximize clarity and effectiveness.\n",
      "Position: Sentiment Analysis Specialist, Role: Optimize Sentiment Classification, Function: Tailor prompts to encompass a broad range of positive and negative sentiments for better classification accuracy.\n",
      "Position: Linguistic Quality Controller, Role: Ensure Linguistic Accuracy, Function: Review and enhance the linguistic structure of the prompt for better generalization and minimal ambiguity.\n",
      "----\n",
      "general team:\n",
      "Position: Sentiment Analysis Specialist, Role: Design and validate sentiment classification models, Function: Develop algorithms to distinguish between positive and negative sentiments\n",
      "Position: Machine Learning Engineer, Role: Implement and optimize machine learning algorithms, Function: Ensure that the machine learning models are efficient and scalable\n",
      "Position: Data Scientist, Role: Analyze and preprocess data for model training and evaluation, Function: Collect, clean, and preprocess text data to enhance model accuracy\n",
      "----\n",
      "Teams and members:\n",
      "prompt writing team:\n",
      "Position: Senior Prompt Engineer, Role: Designing and refining prompts, Function: Optimize prompts for clarity and efficiency\n",
      "Position: Natural Language Processing Specialist, Role: Enhancing language processing capabilities, Function: Develop algorithms to better interpret sentence context\n",
      "Position: Sentiment Analysis Expert, Role: Expertise in sentiment classification techniques, Function: Create robust classifiers to accurately determine sentiment\n",
      "----\n",
      "general team:\n",
      "Position: Sentiment Analysis Specialist, Role: Develop and refine sentiment classification algorithms, Function: Ensure high accuracy in distinguishing between positive and negative sentiments\n",
      "Position: Data Scientist, Role: Analyze and preprocess data to enhance model performance, Function: Implement data augmentation techniques and preprocess data to remove noise\n",
      "Position: Prompt Engineering Expert, Role: Design and optimize LLM prompts for accurate and generalizable classification, Function: Craft effective prompts and fine-tune them to work well across diverse datasets\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"Classify the sentence as positive or negative: {content}\"\n",
    "additional_info = \"This is a classification task with only two classes: positive and negative.\"\n",
    "\n",
    "leader_agent_1 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent_1.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")\n",
    "\n",
    "leader_agent_2 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent_2.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")\n",
    "\n",
    "leader_agent_3 = LeaderAgent(\n",
    "    base_prompt=base_prompt,\n",
    "    additional_info=additional_info,\n",
    ")\n",
    "print(\"Teams and members:\")\n",
    "for team_leader in leader_agent_3.team_leaders:\n",
    "    print(f\"{team_leader.team} team:\")\n",
    "    for worker in team_leader.workforce:\n",
    "        print(f\"Position: {worker.position}, Role: {worker.role}, Function: {worker.function}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentence as positive or negative: {content}\n",
      "----\n",
      "Classify the sentiment of the following sentence into one of two categories: 'positive' or 'negative'. Focus on the context and nuances of the content provided to determine the sentiment accurately. Provide your classification based on the overall sentiment conveyed by the sentence. Sentence: {content}\n",
      "----\n",
      "Classify the sentence provided in {content} as either 'positive' or 'negative' based on its sentiment. For this task, 'positive' sentiment indicates expressions of happiness, approval, or any favorable emotions, while 'negative' sentiment denotes expressions of sadness, disapproval, or any unfavorable emotions. Ensure the classification is strictly 'positive' or 'negative' and do not consider any ambiguous sentiments.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming leader_agent is already defined and initialized\n",
    "def run_optimisation(agent: LeaderAgent):\n",
    "    return agent.optimise_prompt()\n",
    "\n",
    "# Run 3 concurrent instances\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(run_optimisation, agent) for agent in [leader_agent_1, leader_agent_2, leader_agent_3]]\n",
    "    results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    print(\"----\")\n",
    "\n",
    "class PromptMerge(BaseModel):\n",
    "    \"\"\"Merged prompt based on the best parts of each prompt.\"\"\"\n",
    "    final_prompt: str = Field(description=\"Result of merging prompts\")\n",
    "\n",
    "# OpenAI Agent to pull togther best parts of each result\n",
    "def merge_results(results):\n",
    "    \"\"\"\n",
    "    Agent to merge best parts of each prompt\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=1.0,\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    system_message = \"\"\"You are an experienced AI prompt engineer. Your role is to combine prompts to create a more effective prompt.\n",
    "You have in-depth knowledge regarding large language models and their associated architectures, as well as prompt engineering best practices.\"\"\"\n",
    "\n",
    "    template = \"\"\"I am going to tip $300K for a better prompt!\n",
    "Given the prompts below, your task is to merge the best parts of each prompt to create the most effective prompt.\n",
    "Carefully consider the strengths of each prompt and how they can be combined to create a better prompt.\n",
    "Aspects of the prompts to consider:\n",
    "- Conciseness and clarity\n",
    "- Contextual relevance\n",
    "- Task alignment\n",
    "- Example Demonstrations\n",
    "- Avoiding bias\n",
    "- Incremental prompting\n",
    "Placeholders are notated using curly braces. You must not remove placeholders or add additional placeholders.\n",
    "I repeat, you must not remove placeholders or add additional placeholders.\n",
    "Do not make assumptions on what the placeholders represent.\n",
    "You will be penalized if the prompt is repetitive, lacks clarity or is incoherent.\n",
    "Ensure that your answer is unbiased.\n",
    "\n",
    "Prompts: {results}\n",
    "\n",
    "Return only the next worker to process or 'FINISH' in JSON format below:\n",
    "\n",
    "{{\n",
    "    \"final_prompt\": \"Result of merging prompts\",\n",
    "}}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "You will be penalized if your output cannot be parsed correctly.\"\"\"\n",
    "    pydantic_parser = PydanticOutputParser(pydantic_object=PromptMerge)\n",
    "    prompt_template = PromptTemplate(\n",
    "        system_message=system_message,\n",
    "        template=template,\n",
    "        input_variables=[\"results\"],\n",
    "        partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
    "    )\n",
    "    chain = prompt_template | llm | pydantic_parser\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            output = chain.invoke({\"results\": results})\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"Exception occurred:\", e)\n",
    "            continue\n",
    "    return output.final_prompt\n",
    "\n",
    "final_result = merge_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentiment of the following sentence into one of two categories: 'positive' or 'negative'. Focus on the context and nuances of the content provided to determine the sentiment accurately. For this task, 'positive' sentiment indicates expressions of happiness, approval, or any favorable emotions, while 'negative' sentiment denotes expressions of sadness, disapproval, or any unfavorable emotions. Ensure the classification is strictly 'positive' or 'negative' and do not consider any ambiguous sentiments. Sentence: {content}\n"
     ]
    }
   ],
   "source": [
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

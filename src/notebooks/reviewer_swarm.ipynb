{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt= \"\"\"You are a lead software engineer. You have been tasked with developing a {change_type}. \n",
    "You will be provided with a BDD requirement as well as a set of relevant code snippets and the codebase structure to support your decision making. \n",
    "Your job is to review the requirement and the code snippets and then generate a set of steps to implement the requirement.\n",
    "\n",
    "Your guidelines:\n",
    "- If you are uncertain about whether to edit an exisitng bit of code or generate new one, you should err on the side of generating new code.\n",
    "- You should be specific in your instructions, detailing the variable names/types, method names/return types, etc.\n",
    "- The only actions that can be taken on your instructions are to add new code or edit existing code. No other actions are allowed.\n",
    "- You may not ask for more information about the task. You must complete the task with the information provided.\n",
    "- Each step should only refer to a coding instruction. DO NOT add steps for code reviews or any non-coding tasks.\n",
    "\n",
    "IMPORTANT: You should return a list of steps to implement the requirement.\n",
    "Each step should contain the following fields:\n",
    "    - step_number: The step number (to be carried out in order to avoid compilation errors)\n",
    "    - instruction: A description of what the user carrying out the task should do, be detailed.\n",
    "    - explanation: A explanation of why the step is necessary, why it is independent of the other steps and why it is a correctly sized task.\n",
    "    \n",
    "Example steps you should return:\n",
    "    [\n",
    "        {{\n",
    "            \"step_number\": 1,\n",
    "            \"instruction\": \"Add a price field to the product model. The type should be a double and the default value should be 0.0\",\n",
    "            \"explanation\": \"This step is necessary to store the price of the product. It is independent of the other steps because it does not rely on any other code changes. It is correctly sized because it is a single action that can be taken by a coder.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"step_number\": 2,\n",
    "            \"instruction\": \"Add a query to the product repository to find all products with a price greater than 100.0.\",\n",
    "            \"explanation\": \"This step is necessary to allow the system to query products based on price. It is independent of the other steps because it does not rely on any other code changes. It is correctly sized because it is a single action that can be taken by a coder.\"\n",
    "        }},\n",
    "    ...\n",
    "        {{\n",
    "            \"step_number\": 5,\n",
    "            \"instruction\": \"Add a controller to the codebase that will call the service method you just created.\",\n",
    "            \"explanation\": \"This step is necessary to allow the system to interact with the new functionality. It is independent of the other steps because it does not rely on any other code changes. It is correctly sized because it is a single action that can be taken by a coder.\"\n",
    "        }}\n",
    "    ]\n",
    "\n",
    "Only return json and only return ordered steps in the above format.\n",
    "\n",
    "Here is the BDD requirement:\n",
    "\n",
    "\"{user_request}\"\n",
    "\n",
    "Here is the repo structure and relevant code snippets:\n",
    "\n",
    "\"{repo_tree}\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "import dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# class SuggestedUpdate(BaseModel):\n",
    "#     original: str = Field(..., description=\"The original value of the section of the prompt should be updated\")\n",
    "#     updated: str = Field(..., description=\"The updated value of the section of the prompt should be updated\")\n",
    "    \n",
    "class ApprovalResponse(BaseModel):\n",
    "    original_prompt: str = Field(..., description=\"The original prompt that was reviewed\")\n",
    "    approved: bool = Field(..., description=\"Whether the request was approved or not, True or False\")\n",
    "    explanation: str = Field(..., description=\"A detailed explanation of why the request was approved or not\")\n",
    "    # partial_updates: List[SuggestedUpdate] = Field(..., description=\"The sections of the prompt need to be updated, and the new values\")\n",
    "\n",
    "class PromptReviewPrincipals:\n",
    "    def __init__(self, core_principles: List[str]):\n",
    "        self.core_principles = core_principles\n",
    "    \n",
    "    def add_principle(self, principle: str):\n",
    "        \"\"\"\n",
    "        Adds a principle to the core principles list.\n",
    "        \n",
    "        :param principle: The principle to be added.\n",
    "        \"\"\"\n",
    "        self.core_principles.append(principle)\n",
    "        \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation of the core principles, each principle is listed on a new line with a preceding dash.\n",
    "        \n",
    "        Example:\n",
    "        - principle 1\n",
    "        - principle 2\n",
    "        ...\n",
    "        \"\"\"\n",
    "        return \"\\n\".join([f\"- {principle}\" for principle in self.core_principles])\n",
    "    \n",
    "class PromptReviewAgent:\n",
    "    \"\"\"\n",
    "    This class represents an approval agent that reviews and approves requests based on its persona and core principles.\n",
    "    \"\"\"\n",
    "    def __init__(self, persona_title: str, core_principles: PromptReviewPrincipals, model:str='gpt-4o', temperature: float=1.0):\n",
    "        \"\"\"\n",
    "        Initializes the PromptReviewAgent with a persona title, core principles, model, and temperature.\n",
    "        \n",
    "        :param persona_title: The title of the persona for the agent.\n",
    "        :param core_principles: The core principles of the agent.\n",
    "        :param model: The model to be used by the agent. Default is 'gpt-4o'.\n",
    "        :param temperature: The temperature to be used by the agent. Default is 0.0.\n",
    "        \"\"\"\n",
    "        self.id = uuid4()\n",
    "        self.persona_title = persona_title\n",
    "        self.core_principles = str(core_principles)\n",
    "        self.llm = ChatOpenAI(temperature=temperature,model=model)\n",
    "    \n",
    "    async def review(self, prompt_to_review: str) -> ApprovalResponse:\n",
    "        \"\"\"\n",
    "        Reviews a given prompt and returns an ApprovalResponse.\n",
    "        \n",
    "        :param prompt_to_review: The prompt to be reviewed.\n",
    "        :return: An ApprovalResponse object containing the review results.\n",
    "        \"\"\"\n",
    "        prompt_template = \"\"\"You are a senior {persona_title}. You have been asked to review the following request and provide your approval or disapproval. \n",
    "        You should consider the request in light of your core principles and provide a detailed explanation on why you approve or disapprove of the request.\n",
    "        Be constructive in your feedback and provide suggestions on how the request could be improved.\n",
    "        \n",
    "        **Your core principles are:**\n",
    "        {core_principles}\n",
    "        \n",
    "        **Strict guidelines:**\n",
    "        1. All restrictions already stated in the text being reviewed should not be modified.\n",
    "        2. All negations should be preserved. e.g. \"DO NOT\" should not be changed to \"DO\" or removed entirely.\n",
    "        3. All placeholders denoted by curly braces should not be modified or removed.\n",
    "        4. Adding additional restrictions or negations is allowed.\n",
    "        5. Adding additional placeholders is not allowed.\n",
    "        6. Adding additional instructions to achieve your core principles is allowed.\n",
    "        \n",
    "        **Request to review:**\n",
    "        -------------------------------------\n",
    "        {prompt_to_review}\n",
    "        -------------------------------------\n",
    "        \n",
    "        {format_instructions}\n",
    "        \"\"\"\n",
    "        pydantic_parser = PydanticOutputParser(pydantic_object=ApprovalResponse)\n",
    "        format_instructions = pydantic_parser.get_format_instructions()\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "        messages = prompt.format_messages(persona_title=self.persona_title, prompt_to_review=prompt_to_review,core_principles=self.core_principles, format_instructions=format_instructions)\n",
    "\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                output = self.llm(messages=messages)\n",
    "                approval_summary = pydantic_parser.parse(output.content)\n",
    "                break\n",
    "            except Exception:\n",
    "                continue\n",
    "        else:\n",
    "            raise Exception(\"Failed to parse output after 3 attempts\")\n",
    "        return approval_summary\n",
    "\n",
    "class PromptAgent:\n",
    "    \"\"\"\n",
    "    This class represents a prompt agent that manages the base prompt and updates it based on suggested updates.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_prompt: str):\n",
    "        \"\"\"\n",
    "        Initializes the PromptAgent with a base prompt.\n",
    "        \n",
    "        :param base_prompt: The base prompt to be managed by the agent.\n",
    "        \"\"\"\n",
    "        self.base_prompt = base_prompt\n",
    "        self.llm = ChatOpenAI(model='gpt-4o', temperature=0.5)\n",
    "\n",
    "        \n",
    "    # async def update(self, suggested_update: SuggestedUpdate)->str:\n",
    "    #     \"\"\"\n",
    "    #     Updates the base prompt based on a given SuggestedUpdate and returns the updated prompt.\n",
    "        \n",
    "    #     :param suggested_update: The SuggestedUpdate to be applied to the base prompt.\n",
    "    #     :return: The updated base prompt.\n",
    "    #     \"\"\"\n",
    "    #     for update in suggested_update:\n",
    "    #         self.base_prompt = self.base_prompt.replace(update.original, update.updated)\n",
    "            \n",
    "    #     return self.base_prompt\n",
    "\n",
    "    async def update(self, orgiginal_prompt: str, explanation: str)->str:\n",
    "        \"\"\"\n",
    "        Updates the base prompt based on explanantion given in the ApprovalResponse and generates an improved prompt.\n",
    "        \"\"\"\n",
    "\n",
    "        prompt_template = \"\"\"You are an expert prompt engineer. You have been tasked with updating the following prompt based on the feedback provided by a reviewer.\n",
    "        You should consider the feedback provided and update the prompt accordingly.\n",
    "\n",
    "        **Original Prompt:**\n",
    "        {original_prompt}\n",
    "\n",
    "        **Feedback:**\n",
    "        {explanation}\n",
    "\n",
    "        Output the updated prompt.\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "        messages = prompt.format_messages(original_prompt=orgiginal_prompt, explanation=explanation)\n",
    "\n",
    "        try:\n",
    "            output = self.llm(messages=messages)\n",
    "            self.base_prompt = output.content\n",
    "        except:\n",
    "            return self.base_prompt\n",
    "                \n",
    "        return self.base_prompt\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialPromptReview:\n",
    "    \"\"\"\n",
    "    This class represents a sequential approval process. It registers agents and manages the approval process.\n",
    "    \"\"\"\n",
    "    def __init__(self, prompt_agent: PromptAgent, max_resets: int = 10):\n",
    "        \"\"\"\n",
    "        Initializes the SequentialPromptReview with a prompt agent and a maximum number of resets.\n",
    "        \n",
    "        :param prompt_agent: The agent that provides the prompt for the approval process.\n",
    "        :param max_resets: The maximum number attempts to reach approval consensus.\n",
    "        \"\"\"\n",
    "        self.approvers = []\n",
    "        self.prompt = prompt_agent.base_prompt\n",
    "        self.base_prompt = prompt_agent.base_prompt\n",
    "        self.prompt_agent = prompt_agent\n",
    "        self.approved = {}\n",
    "        self.max_resets = max_resets\n",
    "\n",
    "    def register_approver(self, approver: PromptReviewAgent):\n",
    "        \"\"\"\n",
    "        Registers an approver for the sequential approval process.\n",
    "        \n",
    "        :param approver: The approver to be registered.\n",
    "        \"\"\"\n",
    "        self.approvers.append(approver)\n",
    "\n",
    "    def reset_approval(self):\n",
    "        \"\"\"\n",
    "        Resets the approval process by clearing the approved dictionary.\n",
    "        \"\"\"\n",
    "        self.approved = {}\n",
    "\n",
    "    async def review(self) -> str:\n",
    "        \"\"\"\n",
    "        Executes the approval process. It iterates over the registered approvers and asks them to review the prompt.\n",
    "        If an approver does not approve, the prompt is updated and the approval process is reset.\n",
    "        The process continues until all approvers have approved or the maximum number of resets has been reached.\n",
    "        \n",
    "        :return: The final approved prompt.\n",
    "        \"\"\"\n",
    "        reset_count = 0\n",
    "        while len(self.approved) < len(self.approvers) and reset_count < self.max_resets:\n",
    "            for approver in self.approvers:\n",
    "                if approver.id not in self.approved:\n",
    "                    result = await approver.review(self.prompt)\n",
    "                    if result.approved:\n",
    "                        self.approved[approver.id] = result\n",
    "                    else:\n",
    "                        self.prompt = await self.prompt_agent.update(result.original_prompt, result.explanation)\n",
    "                        self.reset_approval()\n",
    "                        reset_count += 1\n",
    "                        break\n",
    "                    \n",
    "        if reset_count >= self.max_resets:\n",
    "            return self.base_prompt\n",
    "        \n",
    "        return self.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(0):\n",
    "    code_quality_principals = PromptReviewPrincipals([\n",
    "        \"Always write clean code\",\n",
    "        \"Always write tests\",\n",
    "        \"Always write documentation\"\n",
    "        ])\n",
    "    code_quality_reviewer = PromptReviewAgent(\"software engineer\", code_quality_principals)\n",
    "    # result = await code_quality_approver.review(\"write a function that takes in a list of numbers and returns the sum of the numbers, and example output is sum([1,2,3]) = 6\")\n",
    "    result = await code_quality_reviewer.review(base_prompt)\n",
    "\n",
    "    print(json.dumps(result.model_dump(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(0):\n",
    "    architecture_quality_approver = PromptReviewAgent(\"software architect\", \"1. Always design for scalability\\n2. Always design for maintainability\\n3. Always design for performance\")\n",
    "    # result = await code_quality_approver.generate(\"write a function that takes in a list of numbers and returns the sum of the numbers, and example output is sum([1,2,3]) = 6\")\n",
    "    result = await architecture_quality_approver.review(base_prompt)\n",
    "    print(json.dumps(result.model_dump(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_agent = PromptAgent(base_prompt)\n",
    "# code_quality_principals = PromptReviewPrincipals([\n",
    "#     \"Always write clean code\",\n",
    "#     \"Always write tests\",\n",
    "#     \"Always write documentation\"\n",
    "#     ])\n",
    "# code_quality_reviewer = PromptReviewAgent(\"software engineer\", code_quality_principals)\n",
    "\n",
    "# architecture_quality_principals = PromptReviewPrincipals([\n",
    "#     \"Always design for scalability\",\n",
    "#     \"Always design for maintainability\",\n",
    "#     \"Always design for performance\"\n",
    "#     ])\n",
    "# architecture_quality_reviewer = PromptReviewAgent(\"software architect\", architecture_quality_principals)\n",
    "\n",
    "# sequential_prompt_review = SequentialPromptReview(prompt_agent)\n",
    "# sequential_prompt_review.register_approver(code_quality_reviewer)\n",
    "# sequential_prompt_review.register_approver(architecture_quality_reviewer)\n",
    "# final_prompt = await sequential_prompt_review.review()\n",
    "\n",
    "# with open(\"prompt_before.txt\", \"w\") as f:\n",
    "#     f.write(base_prompt)\n",
    "\n",
    "# with open(\"prompt_after.txt\", \"w\") as f:\n",
    "#     f.write(final_prompt)\n",
    "    \n",
    "# print(len(base_prompt),len(final_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"write a function that output the fibonacci sequence up to a given number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iwatson/Documents/Research Project/prompt-optimisation/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/iwatson/Documents/Research Project/prompt-optimisation/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "prompt_agent = PromptAgent(base_prompt)\n",
    "\n",
    "code_quality_principals = PromptReviewPrincipals([\n",
    "    \"Always write clean code\",\n",
    "    \"Always write tests\",\n",
    "    \"Always write documentation\"\n",
    "    ])\n",
    "code_quality_reviewer = PromptReviewAgent(\"software engineer\", code_quality_principals)\n",
    "\n",
    "architecture_quality_principals = PromptReviewPrincipals([\n",
    "    \"Always design for scalability\",\n",
    "    \"Always design for maintainability\",\n",
    "    \"Always design for performance\"\n",
    "    ])\n",
    "architecture_quality_reviewer = PromptReviewAgent(\"software architect\", architecture_quality_principals)\n",
    "\n",
    "writer_quality_principals = PromptReviewPrincipals([\n",
    "    \"Always write clear and concise instructions\",\n",
    "    \"Always write with reference to specific context\",\n",
    "    \"Always write with the end user (an LLM) in mind\"\n",
    "    ])\n",
    "writer_quality_reviewer = PromptReviewAgent(\"writer\", writer_quality_principals)\n",
    "\n",
    "# instructor_quality_principals = PromptReviewPrincipals([\n",
    "#     \"Always provide clear and concise instructions\",\n",
    "#     \"Always provide relevant and useful instructions\"\n",
    "#     ])\n",
    "# instructor_quality_reviewer = PromptReviewAgent(\"instructor\", instructor_quality_principals)\n",
    "\n",
    "# context_quality_principals = PromptReviewPrincipals([\n",
    "#     \"Always provide context to the task\",\n",
    "#     \"Always provide a description of the context\",\n",
    "#     \"Always explain the importance of the context\"\n",
    "#     ])\n",
    "# context_quality_reviewer = PromptReviewAgent(\"context\", context_quality_principals)\n",
    "\n",
    "# examplar_quality_principals = PromptReviewPrincipals([\n",
    "#     \"Always provide clear and concise examples\",\n",
    "#     \"Always provide examples relevant to the task\",\n",
    "#     ])\n",
    "# examplar_quality_reviewer = PromptReviewAgent(\"examplar\", examplar_quality_principals)\n",
    "\n",
    "# stylist_quality_principals = PromptReviewPrincipals([\n",
    "#     \"Always provide output in an appropriate format\",\n",
    "#     \"Always provide instructions with an appropriate tone\",\n",
    "#     \"Always use appropriate syntax and grammar\"\n",
    "#     ])\n",
    "# stylist_quality_reviewer = PromptReviewAgent(\"stylist\", stylist_quality_principals)\n",
    "\n",
    "# constraint_quality_principals = PromptReviewPrincipals([\n",
    "#     \"Always define necessary constraints\",\n",
    "#     \"Always explain why the constraints are necessary\",\n",
    "#     ])\n",
    "# constraint_quality_reviewer = PromptReviewAgent(\"constraint\", constraint_quality_principals)\n",
    "\n",
    "sequential_prompt_review = SequentialPromptReview(prompt_agent)\n",
    "sequential_prompt_review.register_approver(code_quality_reviewer)\n",
    "sequential_prompt_review.register_approver(architecture_quality_reviewer)\n",
    "sequential_prompt_review.register_approver(writer_quality_reviewer)\n",
    "# sequential_prompt_review.register_approver(instructor_quality_reviewer)\n",
    "# sequential_prompt_review.register_approver(context_quality_reviewer)\n",
    "# sequential_prompt_review.register_approver(examplar_quality_reviewer)\n",
    "# sequential_prompt_review.register_approver(stylist_quality_reviewer)\n",
    "# sequential_prompt_review.register_approver(constraint_quality_reviewer)\n",
    "final_prompt = await sequential_prompt_review.review()\n",
    "\n",
    "# with open(\"prompt_before.txt\", \"w\") as f:\n",
    "#     f.write(base_prompt)\n",
    "\n",
    "# with open(\"prompt_after.txt\", \"w\") as f:\n",
    "#     f.write(final_prompt)\n",
    "    \n",
    "print(len(base_prompt),len(final_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Updated Prompt:**\n",
      "\n",
      "Write a function in Python that outputs the Fibonacci sequence up to a given number. Ensure the function adheres to the following guidelines:\n",
      "\n",
      "1. **Clean Code:**\n",
      "   - Use meaningful variable names.\n",
      "   - Properly indent and structure the code.\n",
      "   - Handle edge cases, such as non-integer inputs and negative numbers.\n",
      "   - Avoid hard-coded values.\n",
      "\n",
      "2. **Testing:**\n",
      "   - Write unit tests to verify the function's behavior with various inputs, including edge cases and typical use cases.\n",
      "\n",
      "3. **Documentation:**\n",
      "   - Include docstrings or comments to explain the function's purpose, input parameters, and expected output.\n",
      "   - Provide examples of how to use the function.\n",
      "\n",
      "Here is an outline to get you started:\n",
      "\n",
      "```python\n",
      "def fibonacci_sequence(n):\n",
      "    \"\"\"\n",
      "    Generate the Fibonacci sequence up to a given number n.\n",
      "\n",
      "    Parameters:\n",
      "    n (int): The upper bound for the Fibonacci sequence. Must be a non-negative integer.\n",
      "\n",
      "    Returns:\n",
      "    list: A list containing the Fibonacci sequence up to n.\n",
      "    \n",
      "    Raises:\n",
      "    ValueError: If the input is not a non-negative integer.\n",
      "    \"\"\"\n",
      "    # Your implementation here\n",
      "\n",
      "# Example usage:\n",
      "# print(fibonacci_sequence(10))  # Output: [0, 1, 1, 2, 3, 5, 8]\n",
      "\n",
      "# Unit tests\n",
      "import unittest\n",
      "\n",
      "class TestFibonacciSequence(unittest.TestCase):\n",
      "    def test_positive_numbers(self):\n",
      "        self.assertEqual(fibonacci_sequence(10), [0, 1, 1, 2, 3, 5, 8])\n",
      "        self.assertEqual(fibonacci_sequence(1), [0, 1])\n",
      "        \n",
      "    def test_zero(self):\n",
      "        self.assertEqual(fibonacci_sequence(0), [0])\n",
      "        \n",
      "    def test_negative_number(self):\n",
      "        with self.assertRaises(ValueError):\n",
      "            fibonacci_sequence(-1)\n",
      "    \n",
      "    def test_non_integer_input(self):\n",
      "        with self.assertRaises(ValueError):\n",
      "            fibonacci_sequence(\"10\")\n",
      "        with self.assertRaises(ValueError):\n",
      "            fibonacci_sequence(10.5)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    unittest.main()\n",
      "```\n",
      "\n",
      "Make sure the function is clean, well-tested, and thoroughly documented.\n"
     ]
    }
   ],
   "source": [
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def generate(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message\n",
    "\n",
    "base_response=generate(base_prompt)\n",
    "final_response=generate(final_prompt)\n",
    "\n",
    "with open(\"response_before.txt\", \"w\") as f:\n",
    "    f.write(base_response.content)\n",
    "    \n",
    "with open(\"response_after.txt\", \"w\") as f:\n",
    "    f.write(final_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

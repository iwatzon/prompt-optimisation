{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Reflection Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.prompts.chat import SystemMessage, _convert_to_message\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "from langgraph.graph import END, StateGraph, MessageGraph\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import List, Sequence, TypedDict, Annotated\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = \"Authoritarian Optimisation\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import Client\n",
    "\n",
    "# client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=1.0, model=\"gpt-4o\")\n",
    "# llm = ChatAnthropic(temperature=1.0, model=\"claude-3-haiku-20240307\")\n",
    "\n",
    "def self_reflection_graph(criteria) -> MessageGraph:\n",
    "    \"\"\"\n",
    "    Constructs a graph for self-reflection and improvement of prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    system_message = f\"\"\"You are an experienced: AI Prompt Engineer. Your core principles are:\n",
    "- Always write clear and concise prompts.\n",
    "- Always write contextually relevant prompts.\n",
    "- Always write task aligned prompts.\n",
    "- Always write example demonstrations in prompts.\n",
    "- Always format and structure prompts to be easily understood by the model.\"\"\"\n",
    "\n",
    "    def generation_node(state: Sequence[BaseMessage]):\n",
    "        prompt_text = f\"\"\"Your task is to review the conversation above and improve the prompt in light of your core principles.\n",
    "If you recieve feedback and recommendations for the prompt, respond with a revised version of your previous attempts actioning the feedback.\n",
    "\n",
    "The success criteria for the prompt are as follows:\n",
    "{criteria}\n",
    "You will be penalized if the prompt does not meet this criteria.\n",
    "\n",
    "Below are strict guidelines that you MUST follow if making changes to the prompt:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces.\n",
    "- ALWAYS treat placeholders as the actual content.\n",
    "You will be penalized if you do not follow these guidelines.\n",
    "\n",
    "Your update process should be as follows:\n",
    "1. Review the conversation carefully as an expert AI Prompt Engineer.\n",
    "2. Think carefully about how you can implement the user's feedback (if any) to improve the prompt.\n",
    "3. Revise the prompt in light of your core principles and the feedback you have received (if any).\n",
    "4. Submit your revised prompt.\n",
    "\"\"\"\n",
    "        messages = [\n",
    "            (\"system\", system_message),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\"system\", prompt_text),\n",
    "        ]\n",
    "        prompt = ChatPromptTemplate.from_messages(messages)\n",
    "        chain = prompt | llm\n",
    "        return chain.invoke({\"messages\": state})\n",
    "        \n",
    "    def reflection_node(state: Sequence[BaseMessage]):\n",
    "        prompt_text = f\"\"\"Your task is to review the conversation above and think outside the box to provide feedback on the prompt.\n",
    "Offer creative recommendations on how to improve it in light of your core principles.\n",
    "\n",
    "The success criteria for the updated prompt are as follows:\n",
    "{criteria}\n",
    "Use this information to inform your feedback.\n",
    "\n",
    "Below are strict guidelines that MUST be followed if making changes to the prompt:\n",
    "- DO NOT modify existing restrictions.\n",
    "- DO NOT modify or remove negations.\n",
    "- DO NOT add, modify or remove placeholders denoted by curly braces.\n",
    "- ALWAYS treat placeholders as the actual content.\n",
    "Check that that the prompt adheres to these guidelines.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the conversation carefully as an expert AI Prompt Engineer.\n",
    "2. Explcitly go through each success criteria and ensure the prompt meets them. If not, mention the criteria that was not met in your feedback.\n",
    "3. Explicitly go through each guideline and ensure the changes adhere to them. If not, mention the guideline that was not followed in your feedback.\n",
    "4. Explicitly list the creative recommendations you have for improving the most critical aspects of the prompt.\n",
    "5. Submit your feedback.\n",
    "\"\"\"\n",
    "        messages = [\n",
    "            (\"system\", system_message),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\"system\", prompt_text),\n",
    "        ]\n",
    "        prompt = ChatPromptTemplate.from_messages(messages)\n",
    "        chain = prompt | llm\n",
    "        result = chain.invoke({\"messages\": state})\n",
    "        return HumanMessage(content=result.content)\n",
    "\n",
    "    builder = MessageGraph()\n",
    "    builder.add_node(\"generate\", generation_node)\n",
    "    builder.add_node(\"reflect\", reflection_node)\n",
    "    builder.set_entry_point(\"generate\")\n",
    "\n",
    "    def approval(state: Sequence[BaseMessage], criteria: str):\n",
    "        \"\"\"\n",
    "        Agent to approve or reject the prompt.\n",
    "        \"\"\"\n",
    "        function_def = {\n",
    "        \"name\": \"approval\",\n",
    "        \"description\": \"Submit approval decision for the prompt.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"decision\": {\"type\": \"string\", \"enum\": [\"True\", \"False\"]},\n",
    "            },\n",
    "            \"required\": [\"decision\"],\n",
    "        },\n",
    "        }\n",
    "        prompt_text = f\"\"\"Your task is to review the conversation above and decide if the prompt is optimal in light of your core principles and the success criteria.\n",
    "\n",
    "The success criteria for the prompt are as follows:\n",
    "{criteria}\n",
    "You must use this information to inform your decision.\n",
    "\n",
    "If you think the prompt sufficiently meets the success criteria, return True. \n",
    "If you think the prompt needs improvements in light of your core principles to better meet the success criteria, return False.\n",
    "\n",
    "Your reviewal process should be as follows:\n",
    "1. Read the prompt carefully as an expert AI Prompt Engineer.\n",
    "2. Determine whether the prompt needs improvements or meets the success criteria.\n",
    "3. Submit your decision.\n",
    "\"\"\"\n",
    "        messages = [\n",
    "            (\"system\", system_message),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\"system\", prompt_text),\n",
    "        ]\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "        chain = (\n",
    "            prompt\n",
    "            | llm.bind_functions(functions=[function_def], function_call=\"approval\")\n",
    "            | JsonOutputFunctionsParser()\n",
    "        )\n",
    "        result = chain.invoke({\"messages\": state})\n",
    "        return result\n",
    "\n",
    "    def should_continue(state: List[BaseMessage]):\n",
    "        approval_result = approval(state, criteria)\n",
    "        print(approval_result)\n",
    "        if approval_result[\"decision\"] == \"True\" or len(state) > 12:\n",
    "            return END\n",
    "        return \"reflect\"\n",
    "\n",
    "    builder.add_conditional_edges(\"generate\", should_continue)\n",
    "    builder.add_edge(\"reflect\", \"generate\")\n",
    "\n",
    "    memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "    graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "    return graph\n",
    "\n",
    "def update_prompt(base_prompt: str, criteria: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses self_reflection_graph to iteratively act on feedback and update prompt\n",
    "    \"\"\"\n",
    "    graph = self_reflection_graph(criteria)\n",
    "    input = HumanMessage(content=base_prompt, name=\"User\")\n",
    "    n = random.randint(0, 1000)\n",
    "    config = {\n",
    "        \"configurable\": {\"thread_id\": n},\n",
    "        \"recursion_limit\": 50,\n",
    "        }    \n",
    "\n",
    "    # Run the graph\n",
    "    for s in graph.stream(\n",
    "        input,\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "        ):\n",
    "        if \"__end__\" not in s:\n",
    "            if len(s) > 1:\n",
    "                s[-1].pretty_print()\n",
    "            continue\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'decision': 'True'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is the improved prompt following the core principles and considering the guidelines provided:\n",
      "\n",
      "\"Please review the following object tracking problem presented in {content}. Analyze the information and determine the correct solution to the problem. Output your answer at the end in the format: ##<answer (among A through C)>, ensuring there are no spaces between the ## and the answer.\"\n",
      "\n",
      "This version ensures clarity, concise instruction, and adheres to all the specified requirements.\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"{content}\\nPlease output your answer at the end as ##<your answer (among A through C)>.\"\n",
    "criteria = \"\"\"- The prompt MUST instruct the LLM to solve the object tracking problem.\n",
    "- The prompt MUST include the content placeholder (this is where the object tracking problem will be).\n",
    "- The prompt MUST instruct the LLM to provide the answer at the end of the output exactly as ##<answer (among A through C)>.\n",
    "- The prompt MUST instruct the LLM to provide the answer with no spaces between the ## and the answer.\"\"\"\n",
    "\n",
    "result = update_prompt(base_prompt, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is the improved prompt following the core principles and considering the guidelines provided:\n",
      "\n",
      "\"Please review the following object tracking problem presented in {content}. Analyze the information and determine the correct solution to the problem. Output your answer at the end in the format: ##<answer (among A through C)>, ensuring there are no spaces between the ## and the answer.\"\n",
      "\n",
      "This version ensures clarity, concise instruction, and adheres to all the specified requirements.\n"
     ]
    }
   ],
   "source": [
    "result[-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
